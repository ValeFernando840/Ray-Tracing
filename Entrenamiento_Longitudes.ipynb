{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos todas las librerias necesarias.\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el Dataset\n",
    "file_path = \"dataset/dataset.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listamos columnas para X y con drop separamos como un filter\n",
    "X_columns = [\n",
    "    'latitude_pos_tx', 'longitude_pos_tx', 'elevation_pos_tx', 'fc', 'elevation', \n",
    "    'azimuth', 'year', 'mmdd', 'UTI', 'hour', 'delay', 'terrestrial_range', \n",
    "    'slant_range', 'final_latitude', 'final_longitude', 'final_elevation'\n",
    "]\n",
    "X = df[X_columns]\n",
    "Y = df.drop(columns=X_columns)\n",
    "#Parametros del dataset que no corresponden al X de entrenamiento.\n",
    "X = X.drop(columns=['final_latitude','final_longitude','final_elevation'])\n",
    "\n",
    "# Como solo vamos a observar las longitudes procedo a quitar el resto de columnas (latitudes y alturas.)\n",
    "lat_columns = [f'lat_{i}' for i in range(1,101)]\n",
    "long_columns = [f'long_{i}' for i in range(1,101)]\n",
    "heights_columns = [f'elev_{i}' for i in range(1,101)]\n",
    "\n",
    "Y = Y.drop(columns= lat_columns)\n",
    "Y = Y.drop(columns = heights_columns)\n",
    "# Otras columnas que no tendré en cuenta para la predicción son \n",
    "# \"delay\", \"terrestrial_range\", \"slant_range\", por lo que las quito\n",
    "unwanted_columns = [\"delay\",\"terrestrial_range\",\"slant_range\"]\n",
    "X = X.drop(columns=unwanted_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos la Frecuencia de los X \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
