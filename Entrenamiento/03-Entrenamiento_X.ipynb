{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a realizar una prueba solo son la prediccion de latitudes\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau \n",
    "from tensorflow.keras.regularizers import l2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Utils import utils_nn as utlnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_excel(\"../Train_Test/Dataset_Separado/x_test_new.xlsx\")\n",
    "x_train = pd.read_excel(\"../Train_Test/Dataset_Separado/x_train_new.xlsx\")\n",
    "y_test = pd.read_excel(\"../Train_Test/Dataset_Separado/y_test_new.xlsx\")\n",
    "y_train = pd.read_excel(\"../Train_Test/Dataset_Separado/y_train_new.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos el radio Ro = 6.371E6\n",
    "R0= 6.371E6 # [m]\n",
    "\n",
    "out_x_coord = [f'x_{i}' for i in range(1,101)]\n",
    "\n",
    "y_train_x=y_train[out_x_coord]/R0\n",
    "y_test_x = y_test[out_x_coord]/R0\n",
    "\n",
    "# Nota: 'y_test_x' posee 1026 lineas con [x_1 ... x_100] columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de x_train: (4104, 9)\n",
      "Columna 0 (latitude_pos_tx): min=-42.2800, max=-42.2800, mean=-42.2800, std=0.0000\n",
      "Columna 1 (longitude_pos_tx): min=-63.4000, max=-63.4000, mean=-63.4000, std=0.0000\n",
      "Columna 2 (elevation_pos_tx): min=0.0000, max=0.0000, mean=0.0000, std=0.0000\n",
      "Columna 3 (fc [Mhz]): min=3.0000, max=30.0000, mean=13.7032, std=6.9191\n",
      "Columna 4 (elevation): min=0.0000, max=40.0000, mean=13.6659, std=11.8820\n",
      "Columna 5 (azimuth): min=87.0000, max=98.0000, mean=92.8209, std=4.5824\n",
      "Columna 6 (year): min=2010.0000, max=2010.0000, mean=2010.0000, std=0.0000\n",
      "Columna 7 (mmdd): min=101.0000, max=1231.0000, mean=985.1394, std=348.8719\n",
      "Columna 8 (hour): min=0.0000, max=20.0000, mean=11.1647, std=4.5880\n"
     ]
    }
   ],
   "source": [
    "print(\"Forma de x_train:\", x_train.shape)\n",
    "\n",
    "for i, col_name in enumerate(x_train.columns):\n",
    "    col = x_train[col_name]\n",
    "    print(f\"Columna {i} ({col_name}): min={col.min():.4f}, max={col.max():.4f}, mean={col.mean():.4f}, std={col.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(columns = ['latitude_pos_tx', 'longitude_pos_tx', 'elevation_pos_tx', 'year'])\n",
    "x_test = x_test.drop(columns =['latitude_pos_tx', 'longitude_pos_tx', 'elevation_pos_tx', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch = 1200\n",
    "# b_s = 70\n",
    "\n",
    "# while epoch <= 1500:\n",
    "#   while b_s <= 130:\n",
    "#     l2_reg = 0.00\n",
    "#     inputs = Input(shape=(9,))\n",
    "#     encoded = Dense(9, activation='relu',kernel_regularizer=l2(l2_reg))(inputs)  # Compresión 8 V3 16 n \n",
    "#     encoded = Dense(16, activation='relu',kernel_regularizer=l2(l2_reg))(encoded)\n",
    "#     encoded = Dense(32, activation='relu',kernel_regularizer=l2(l2_reg))(encoded)\n",
    "#     encoded = Dense(64, activation = 'relu',kernel_regularizer=l2(l2_reg))(encoded)\n",
    "#     encoded = Dense(80, activation = 'relu',kernel_regularizer=l2(l2_reg))(encoded)\n",
    "#     encoded = Dense(90, activation = 'relu',kernel_regularizer=l2(l2_reg))(encoded)\n",
    "#     decoded = Dense(100, activation='linear',kernel_regularizer=l2(l2_reg), name = 'x_output')(encoded)  # Reconstrucción a 100 puntos\n",
    "#     autoencoder_x = Model(inputs, decoded)\n",
    "#     autoencoder_x.compile(optimizer = 'adam', loss='mse')\n",
    "#     autoencoder_x.summary()\n",
    "\n",
    "#     history = autoencoder_x.fit(x_train,y_train_x,\n",
    "#                           epochs = epoch,\n",
    "#                           batch_size = b_s, \n",
    "#                           validation_split = 0.1)\n",
    "\n",
    "#     loss = autoencoder_x.evaluate(x_test, y_test_x)\n",
    "    \n",
    "#     if loss <= 35:\n",
    "#       autoencoder_x.save(f'../modelos_entrenamiento/modelos_x/mod_x_{epoch}_{b_s}_vs10_Adam_loss_{round(loss)}.keras')\n",
    "#     print(f'Pérdida en datos de Test: {loss} epoch: {epoch}, batch_size: {b_s}')\n",
    "#     b_s += 20  \n",
    "#   b_s = 80\n",
    "#   epoch +=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "\n",
    "y_train_x_scaled = scaler_x.fit_transform(y_train_x)\n",
    "y_test_x_scaled = scaler_x.transform(y_test_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "  monitor = 'val_loss',\t#monitoriamos la pérdida en validación\n",
    "  patience = 30, # Si no mejora en 10->20 epochs, detenemos el entrenamiento.\n",
    "  restore_best_weights = True # Restaura los mejores pesos encontrados.\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "  monitor = 'val_loss',\n",
    "  patience = 20,\n",
    "  factor = 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m2,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m10,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_output (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m25,700\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,924</span> (280.95 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m71,924\u001b[0m (280.95 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,924</span> (280.95 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m71,924\u001b[0m (280.95 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 6.1524 - val_loss: 0.4763 - learning_rate: 0.0010\n",
      "Epoch 2/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4252 - val_loss: 0.3702 - learning_rate: 0.0010\n",
      "Epoch 3/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3823 - val_loss: 0.2835 - learning_rate: 0.0010\n",
      "Epoch 4/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2832 - val_loss: 0.2976 - learning_rate: 0.0010\n",
      "Epoch 5/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2864 - val_loss: 0.2865 - learning_rate: 0.0010\n",
      "Epoch 6/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2739 - val_loss: 0.3041 - learning_rate: 0.0010\n",
      "Epoch 7/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2662 - val_loss: 0.2686 - learning_rate: 0.0010\n",
      "Epoch 8/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2502 - val_loss: 0.2378 - learning_rate: 0.0010\n",
      "Epoch 9/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2364 - val_loss: 0.2179 - learning_rate: 0.0010\n",
      "Epoch 10/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2375 - val_loss: 0.2211 - learning_rate: 0.0010\n",
      "Epoch 11/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2279 - val_loss: 0.2066 - learning_rate: 0.0010\n",
      "Epoch 12/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2138 - val_loss: 0.2293 - learning_rate: 0.0010\n",
      "Epoch 13/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2118 - val_loss: 0.1987 - learning_rate: 0.0010\n",
      "Epoch 14/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2026 - val_loss: 0.2017 - learning_rate: 0.0010\n",
      "Epoch 15/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2083 - val_loss: 0.1987 - learning_rate: 0.0010\n",
      "Epoch 16/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2016 - val_loss: 0.1884 - learning_rate: 0.0010\n",
      "Epoch 17/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1910 - val_loss: 0.1844 - learning_rate: 0.0010\n",
      "Epoch 18/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1862 - val_loss: 0.1915 - learning_rate: 0.0010\n",
      "Epoch 19/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1894 - val_loss: 0.1934 - learning_rate: 0.0010\n",
      "Epoch 20/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1843 - val_loss: 0.1944 - learning_rate: 0.0010\n",
      "Epoch 21/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1879 - val_loss: 0.1772 - learning_rate: 0.0010\n",
      "Epoch 22/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1802 - val_loss: 0.1835 - learning_rate: 0.0010\n",
      "Epoch 23/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1823 - val_loss: 0.1734 - learning_rate: 0.0010\n",
      "Epoch 24/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1740 - val_loss: 0.1687 - learning_rate: 0.0010\n",
      "Epoch 25/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1689 - val_loss: 0.1935 - learning_rate: 0.0010\n",
      "Epoch 26/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1785 - val_loss: 0.1696 - learning_rate: 0.0010\n",
      "Epoch 27/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1646 - val_loss: 0.1709 - learning_rate: 0.0010\n",
      "Epoch 28/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1624 - val_loss: 0.1599 - learning_rate: 0.0010\n",
      "Epoch 29/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1604 - val_loss: 0.1673 - learning_rate: 0.0010\n",
      "Epoch 30/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1606 - val_loss: 0.1566 - learning_rate: 0.0010\n",
      "Epoch 31/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1573 - val_loss: 0.1555 - learning_rate: 0.0010\n",
      "Epoch 32/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1535 - val_loss: 0.1488 - learning_rate: 0.0010\n",
      "Epoch 33/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1520 - val_loss: 0.1507 - learning_rate: 0.0010\n",
      "Epoch 34/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1477 - val_loss: 0.1454 - learning_rate: 0.0010\n",
      "Epoch 35/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1447 - val_loss: 0.1423 - learning_rate: 0.0010\n",
      "Epoch 36/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1426 - val_loss: 0.1461 - learning_rate: 0.0010\n",
      "Epoch 37/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1432 - val_loss: 0.1569 - learning_rate: 0.0010\n",
      "Epoch 38/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1440 - val_loss: 0.1450 - learning_rate: 0.0010\n",
      "Epoch 39/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1413 - val_loss: 0.1361 - learning_rate: 0.0010\n",
      "Epoch 40/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1375 - val_loss: 0.1344 - learning_rate: 0.0010\n",
      "Epoch 41/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1361 - val_loss: 0.1393 - learning_rate: 0.0010\n",
      "Epoch 42/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1379 - val_loss: 0.1313 - learning_rate: 0.0010\n",
      "Epoch 43/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1299 - val_loss: 0.1343 - learning_rate: 0.0010\n",
      "Epoch 44/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1312 - val_loss: 0.1339 - learning_rate: 0.0010\n",
      "Epoch 45/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1303 - val_loss: 0.1246 - learning_rate: 0.0010\n",
      "Epoch 46/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1252 - val_loss: 0.1231 - learning_rate: 0.0010\n",
      "Epoch 47/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1234 - val_loss: 0.1224 - learning_rate: 0.0010\n",
      "Epoch 48/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1223 - val_loss: 0.1224 - learning_rate: 0.0010\n",
      "Epoch 49/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1200 - val_loss: 0.1199 - learning_rate: 0.0010\n",
      "Epoch 50/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1208 - val_loss: 0.1167 - learning_rate: 0.0010\n",
      "Epoch 51/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1158 - val_loss: 0.1176 - learning_rate: 0.0010\n",
      "Epoch 52/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1163 - val_loss: 0.1191 - learning_rate: 0.0010\n",
      "Epoch 53/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1167 - val_loss: 0.1188 - learning_rate: 0.0010\n",
      "Epoch 54/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1148 - val_loss: 0.1100 - learning_rate: 0.0010\n",
      "Epoch 55/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1090 - val_loss: 0.1110 - learning_rate: 0.0010\n",
      "Epoch 56/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1123 - val_loss: 0.1061 - learning_rate: 0.0010\n",
      "Epoch 57/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1078 - val_loss: 0.1060 - learning_rate: 0.0010\n",
      "Epoch 58/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1058 - val_loss: 0.1164 - learning_rate: 0.0010\n",
      "Epoch 59/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1135 - val_loss: 0.1037 - learning_rate: 0.0010\n",
      "Epoch 60/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1041 - val_loss: 0.1123 - learning_rate: 0.0010\n",
      "Epoch 61/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1048 - val_loss: 0.1059 - learning_rate: 0.0010\n",
      "Epoch 62/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1036 - val_loss: 0.1064 - learning_rate: 0.0010\n",
      "Epoch 63/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1025 - val_loss: 0.1068 - learning_rate: 0.0010\n",
      "Epoch 64/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1044 - val_loss: 0.1004 - learning_rate: 0.0010\n",
      "Epoch 65/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1009 - val_loss: 0.0967 - learning_rate: 0.0010\n",
      "Epoch 66/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0968 - val_loss: 0.0947 - learning_rate: 0.0010\n",
      "Epoch 67/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0963 - val_loss: 0.0972 - learning_rate: 0.0010\n",
      "Epoch 68/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0942 - val_loss: 0.0980 - learning_rate: 0.0010\n",
      "Epoch 69/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0967 - val_loss: 0.0937 - learning_rate: 0.0010\n",
      "Epoch 70/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0930 - val_loss: 0.0967 - learning_rate: 0.0010\n",
      "Epoch 71/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0941 - val_loss: 0.0939 - learning_rate: 0.0010\n",
      "Epoch 72/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0890 - val_loss: 0.0874 - learning_rate: 0.0010\n",
      "Epoch 73/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0904 - val_loss: 0.0923 - learning_rate: 0.0010\n",
      "Epoch 74/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0919 - val_loss: 0.0912 - learning_rate: 0.0010\n",
      "Epoch 75/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0863 - val_loss: 0.0876 - learning_rate: 0.0010\n",
      "Epoch 76/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0891 - val_loss: 0.0974 - learning_rate: 0.0010\n",
      "Epoch 77/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0904 - val_loss: 0.0844 - learning_rate: 0.0010\n",
      "Epoch 78/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0856 - val_loss: 0.0806 - learning_rate: 0.0010\n",
      "Epoch 79/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0854 - val_loss: 0.0813 - learning_rate: 0.0010\n",
      "Epoch 80/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0821 - val_loss: 0.0904 - learning_rate: 0.0010\n",
      "Epoch 81/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0840 - val_loss: 0.0921 - learning_rate: 0.0010\n",
      "Epoch 82/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0843 - val_loss: 0.0828 - learning_rate: 0.0010\n",
      "Epoch 83/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0822 - val_loss: 0.0884 - learning_rate: 0.0010\n",
      "Epoch 84/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0795 - val_loss: 0.0765 - learning_rate: 0.0010\n",
      "Epoch 85/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0800 - val_loss: 0.0866 - learning_rate: 0.0010\n",
      "Epoch 86/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0806 - val_loss: 0.0808 - learning_rate: 0.0010\n",
      "Epoch 87/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0791 - val_loss: 0.0897 - learning_rate: 0.0010\n",
      "Epoch 88/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0814 - val_loss: 0.0792 - learning_rate: 0.0010\n",
      "Epoch 89/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0768 - val_loss: 0.0712 - learning_rate: 0.0010\n",
      "Epoch 90/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0754 - val_loss: 0.0793 - learning_rate: 0.0010\n",
      "Epoch 91/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0778 - val_loss: 0.0762 - learning_rate: 0.0010\n",
      "Epoch 92/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0769 - val_loss: 0.0696 - learning_rate: 0.0010\n",
      "Epoch 93/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0695 - val_loss: 0.0818 - learning_rate: 0.0010\n",
      "Epoch 94/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0738 - val_loss: 0.0718 - learning_rate: 0.0010\n",
      "Epoch 95/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0691 - val_loss: 0.0671 - learning_rate: 0.0010\n",
      "Epoch 96/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0717 - val_loss: 0.0684 - learning_rate: 0.0010\n",
      "Epoch 97/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0702 - val_loss: 0.0688 - learning_rate: 0.0010\n",
      "Epoch 98/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0713 - val_loss: 0.0675 - learning_rate: 0.0010\n",
      "Epoch 99/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0679 - val_loss: 0.0661 - learning_rate: 0.0010\n",
      "Epoch 100/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0678 - val_loss: 0.0671 - learning_rate: 0.0010\n",
      "Epoch 101/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0684 - val_loss: 0.0795 - learning_rate: 0.0010\n",
      "Epoch 102/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0682 - val_loss: 0.0617 - learning_rate: 0.0010\n",
      "Epoch 103/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0648 - val_loss: 0.0626 - learning_rate: 0.0010\n",
      "Epoch 104/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0639 - val_loss: 0.0664 - learning_rate: 0.0010\n",
      "Epoch 105/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0636 - val_loss: 0.0657 - learning_rate: 0.0010\n",
      "Epoch 106/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0621 - val_loss: 0.0696 - learning_rate: 0.0010\n",
      "Epoch 107/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0644 - val_loss: 0.0631 - learning_rate: 0.0010\n",
      "Epoch 108/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0619 - val_loss: 0.0599 - learning_rate: 0.0010\n",
      "Epoch 109/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0621 - val_loss: 0.0574 - learning_rate: 0.0010\n",
      "Epoch 110/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0632 - val_loss: 0.0581 - learning_rate: 0.0010\n",
      "Epoch 111/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0568 - learning_rate: 0.0010\n",
      "Epoch 112/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0561 - val_loss: 0.0736 - learning_rate: 0.0010\n",
      "Epoch 113/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0632 - val_loss: 0.0647 - learning_rate: 0.0010\n",
      "Epoch 114/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0603 - val_loss: 0.0584 - learning_rate: 0.0010\n",
      "Epoch 115/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0621 - val_loss: 0.0596 - learning_rate: 0.0010\n",
      "Epoch 116/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0598 - val_loss: 0.0587 - learning_rate: 0.0010\n",
      "Epoch 117/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0589 - val_loss: 0.0572 - learning_rate: 0.0010\n",
      "Epoch 118/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0587 - val_loss: 0.0588 - learning_rate: 0.0010\n",
      "Epoch 119/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0613 - val_loss: 0.0579 - learning_rate: 0.0010\n",
      "Epoch 120/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0586 - val_loss: 0.0532 - learning_rate: 0.0010\n",
      "Epoch 121/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0633 - learning_rate: 0.0010\n",
      "Epoch 122/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0536 - learning_rate: 0.0010\n",
      "Epoch 123/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0559 - val_loss: 0.0566 - learning_rate: 0.0010\n",
      "Epoch 124/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0572 - val_loss: 0.0526 - learning_rate: 0.0010\n",
      "Epoch 125/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0578 - val_loss: 0.0600 - learning_rate: 0.0010\n",
      "Epoch 126/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0556 - val_loss: 0.0572 - learning_rate: 0.0010\n",
      "Epoch 127/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0570 - val_loss: 0.0525 - learning_rate: 0.0010\n",
      "Epoch 128/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0545 - val_loss: 0.0498 - learning_rate: 0.0010\n",
      "Epoch 129/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0522 - val_loss: 0.0615 - learning_rate: 0.0010\n",
      "Epoch 130/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0554 - val_loss: 0.0518 - learning_rate: 0.0010\n",
      "Epoch 131/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0539 - val_loss: 0.0495 - learning_rate: 0.0010\n",
      "Epoch 132/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0529 - val_loss: 0.0581 - learning_rate: 0.0010\n",
      "Epoch 133/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0521 - val_loss: 0.0580 - learning_rate: 0.0010\n",
      "Epoch 134/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0531 - val_loss: 0.0609 - learning_rate: 0.0010\n",
      "Epoch 135/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0556 - val_loss: 0.0547 - learning_rate: 0.0010\n",
      "Epoch 136/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0556 - val_loss: 0.0491 - learning_rate: 0.0010\n",
      "Epoch 137/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0513 - val_loss: 0.0545 - learning_rate: 0.0010\n",
      "Epoch 138/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0519 - val_loss: 0.0517 - learning_rate: 0.0010\n",
      "Epoch 139/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0545 - val_loss: 0.0633 - learning_rate: 0.0010\n",
      "Epoch 140/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0527 - val_loss: 0.0513 - learning_rate: 0.0010\n",
      "Epoch 141/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0556 - val_loss: 0.0497 - learning_rate: 0.0010\n",
      "Epoch 142/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0539 - val_loss: 0.0497 - learning_rate: 0.0010\n",
      "Epoch 143/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0509 - val_loss: 0.0477 - learning_rate: 0.0010\n",
      "Epoch 144/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0467 - val_loss: 0.0502 - learning_rate: 0.0010\n",
      "Epoch 145/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0494 - val_loss: 0.0472 - learning_rate: 0.0010\n",
      "Epoch 146/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0491 - val_loss: 0.0459 - learning_rate: 0.0010\n",
      "Epoch 147/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0463 - val_loss: 0.0540 - learning_rate: 0.0010\n",
      "Epoch 148/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0482 - val_loss: 0.0555 - learning_rate: 0.0010\n",
      "Epoch 149/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0530 - val_loss: 0.0460 - learning_rate: 0.0010\n",
      "Epoch 150/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0507 - val_loss: 0.0490 - learning_rate: 0.0010\n",
      "Epoch 151/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0489 - val_loss: 0.0511 - learning_rate: 0.0010\n",
      "Epoch 152/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0467 - val_loss: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 153/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0519 - val_loss: 0.0503 - learning_rate: 0.0010\n",
      "Epoch 154/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0487 - val_loss: 0.0449 - learning_rate: 0.0010\n",
      "Epoch 155/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0473 - val_loss: 0.0531 - learning_rate: 0.0010\n",
      "Epoch 156/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0462 - val_loss: 0.0510 - learning_rate: 0.0010\n",
      "Epoch 157/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0464 - val_loss: 0.0435 - learning_rate: 0.0010\n",
      "Epoch 158/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0477 - val_loss: 0.0460 - learning_rate: 0.0010\n",
      "Epoch 159/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0481 - val_loss: 0.0462 - learning_rate: 0.0010\n",
      "Epoch 160/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0461 - val_loss: 0.0473 - learning_rate: 0.0010\n",
      "Epoch 161/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0444 - val_loss: 0.0453 - learning_rate: 0.0010\n",
      "Epoch 162/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0465 - val_loss: 0.0442 - learning_rate: 0.0010\n",
      "Epoch 163/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0467 - val_loss: 0.0466 - learning_rate: 0.0010\n",
      "Epoch 164/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0446 - val_loss: 0.0509 - learning_rate: 0.0010\n",
      "Epoch 165/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0459 - val_loss: 0.0501 - learning_rate: 0.0010\n",
      "Epoch 166/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0457 - val_loss: 0.0473 - learning_rate: 0.0010\n",
      "Epoch 167/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0459 - val_loss: 0.0434 - learning_rate: 0.0010\n",
      "Epoch 168/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0475 - val_loss: 0.0531 - learning_rate: 0.0010\n",
      "Epoch 169/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0465 - val_loss: 0.0411 - learning_rate: 0.0010\n",
      "Epoch 170/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0447 - val_loss: 0.0496 - learning_rate: 0.0010\n",
      "Epoch 171/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0492 - val_loss: 0.0454 - learning_rate: 0.0010\n",
      "Epoch 172/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0451 - val_loss: 0.0456 - learning_rate: 0.0010\n",
      "Epoch 173/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0466 - val_loss: 0.0413 - learning_rate: 0.0010\n",
      "Epoch 174/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0455 - val_loss: 0.0464 - learning_rate: 0.0010\n",
      "Epoch 175/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0416 - val_loss: 0.0485 - learning_rate: 0.0010\n",
      "Epoch 176/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0466 - val_loss: 0.0459 - learning_rate: 0.0010\n",
      "Epoch 177/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0450 - val_loss: 0.0432 - learning_rate: 0.0010\n",
      "Epoch 178/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0476 - val_loss: 0.0547 - learning_rate: 0.0010\n",
      "Epoch 179/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0442 - val_loss: 0.0444 - learning_rate: 0.0010\n",
      "Epoch 180/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0442 - val_loss: 0.0431 - learning_rate: 0.0010\n",
      "Epoch 181/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0440 - val_loss: 0.0537 - learning_rate: 0.0010\n",
      "Epoch 182/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0461 - val_loss: 0.0426 - learning_rate: 0.0010\n",
      "Epoch 183/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0442 - val_loss: 0.0436 - learning_rate: 0.0010\n",
      "Epoch 184/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0435 - val_loss: 0.0569 - learning_rate: 0.0010\n",
      "Epoch 185/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0475 - val_loss: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 186/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0426 - val_loss: 0.0451 - learning_rate: 0.0010\n",
      "Epoch 187/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0435 - val_loss: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 188/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0447 - val_loss: 0.0435 - learning_rate: 0.0010\n",
      "Epoch 189/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0433 - val_loss: 0.0457 - learning_rate: 0.0010\n",
      "Epoch 190/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0416 - val_loss: 0.0395 - learning_rate: 5.0000e-04\n",
      "Epoch 191/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0405 - val_loss: 0.0449 - learning_rate: 5.0000e-04\n",
      "Epoch 192/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0404 - val_loss: 0.0377 - learning_rate: 5.0000e-04\n",
      "Epoch 193/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0388 - val_loss: 0.0399 - learning_rate: 5.0000e-04\n",
      "Epoch 194/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0388 - val_loss: 0.0400 - learning_rate: 5.0000e-04\n",
      "Epoch 195/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0411 - val_loss: 0.0385 - learning_rate: 5.0000e-04\n",
      "Epoch 196/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0381 - val_loss: 0.0387 - learning_rate: 5.0000e-04\n",
      "Epoch 197/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0409 - val_loss: 0.0406 - learning_rate: 5.0000e-04\n",
      "Epoch 198/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0397 - val_loss: 0.0380 - learning_rate: 5.0000e-04\n",
      "Epoch 199/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0397 - val_loss: 0.0462 - learning_rate: 5.0000e-04\n",
      "Epoch 200/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0402 - val_loss: 0.0377 - learning_rate: 5.0000e-04\n",
      "Epoch 201/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0388 - val_loss: 0.0390 - learning_rate: 5.0000e-04\n",
      "Epoch 202/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0387 - val_loss: 0.0401 - learning_rate: 5.0000e-04\n",
      "Epoch 203/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0387 - val_loss: 0.0383 - learning_rate: 5.0000e-04\n",
      "Epoch 204/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0403 - val_loss: 0.0370 - learning_rate: 5.0000e-04\n",
      "Epoch 205/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0383 - val_loss: 0.0385 - learning_rate: 5.0000e-04\n",
      "Epoch 206/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0394 - val_loss: 0.0487 - learning_rate: 5.0000e-04\n",
      "Epoch 207/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0394 - val_loss: 0.0377 - learning_rate: 5.0000e-04\n",
      "Epoch 208/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0395 - val_loss: 0.0399 - learning_rate: 5.0000e-04\n",
      "Epoch 209/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0387 - val_loss: 0.0372 - learning_rate: 5.0000e-04\n",
      "Epoch 210/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0383 - val_loss: 0.0381 - learning_rate: 5.0000e-04\n",
      "Epoch 211/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0381 - val_loss: 0.0383 - learning_rate: 5.0000e-04\n",
      "Epoch 212/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0396 - val_loss: 0.0389 - learning_rate: 5.0000e-04\n",
      "Epoch 213/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0409 - val_loss: 0.0373 - learning_rate: 5.0000e-04\n",
      "Epoch 214/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0393 - val_loss: 0.0385 - learning_rate: 5.0000e-04\n",
      "Epoch 215/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0384 - val_loss: 0.0396 - learning_rate: 5.0000e-04\n",
      "Epoch 216/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0386 - val_loss: 0.0381 - learning_rate: 5.0000e-04\n",
      "Epoch 217/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0387 - val_loss: 0.0389 - learning_rate: 5.0000e-04\n",
      "Epoch 218/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0393 - val_loss: 0.0378 - learning_rate: 5.0000e-04\n",
      "Epoch 219/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0382 - val_loss: 0.0382 - learning_rate: 5.0000e-04\n",
      "Epoch 220/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0375 - val_loss: 0.0389 - learning_rate: 5.0000e-04\n",
      "Epoch 221/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0373 - val_loss: 0.0384 - learning_rate: 5.0000e-04\n",
      "Epoch 222/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0377 - val_loss: 0.0367 - learning_rate: 5.0000e-04\n",
      "Epoch 223/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0377 - val_loss: 0.0370 - learning_rate: 5.0000e-04\n",
      "Epoch 224/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0398 - val_loss: 0.0373 - learning_rate: 5.0000e-04\n",
      "Epoch 225/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0386 - val_loss: 0.0367 - learning_rate: 5.0000e-04\n",
      "Epoch 226/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0379 - val_loss: 0.0384 - learning_rate: 5.0000e-04\n",
      "Epoch 227/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0383 - val_loss: 0.0383 - learning_rate: 5.0000e-04\n",
      "Epoch 228/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0381 - val_loss: 0.0369 - learning_rate: 5.0000e-04\n",
      "Epoch 229/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0384 - val_loss: 0.0379 - learning_rate: 5.0000e-04\n",
      "Epoch 230/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0363 - val_loss: 0.0444 - learning_rate: 5.0000e-04\n",
      "Epoch 231/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0382 - val_loss: 0.0360 - learning_rate: 5.0000e-04\n",
      "Epoch 232/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0373 - val_loss: 0.0401 - learning_rate: 5.0000e-04\n",
      "Epoch 233/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0408 - val_loss: 0.0430 - learning_rate: 5.0000e-04\n",
      "Epoch 234/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0391 - val_loss: 0.0372 - learning_rate: 5.0000e-04\n",
      "Epoch 235/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0383 - val_loss: 0.0378 - learning_rate: 5.0000e-04\n",
      "Epoch 236/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0369 - val_loss: 0.0360 - learning_rate: 5.0000e-04\n",
      "Epoch 237/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0387 - val_loss: 0.0380 - learning_rate: 5.0000e-04\n",
      "Epoch 238/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0366 - val_loss: 0.0363 - learning_rate: 5.0000e-04\n",
      "Epoch 239/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0377 - val_loss: 0.0368 - learning_rate: 5.0000e-04\n",
      "Epoch 240/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0369 - val_loss: 0.0365 - learning_rate: 5.0000e-04\n",
      "Epoch 241/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0374 - val_loss: 0.0376 - learning_rate: 5.0000e-04\n",
      "Epoch 242/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0371 - val_loss: 0.0381 - learning_rate: 5.0000e-04\n",
      "Epoch 243/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0376 - val_loss: 0.0411 - learning_rate: 5.0000e-04\n",
      "Epoch 244/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0381 - val_loss: 0.0391 - learning_rate: 5.0000e-04\n",
      "Epoch 245/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0376 - val_loss: 0.0370 - learning_rate: 5.0000e-04\n",
      "Epoch 246/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.0359 - learning_rate: 5.0000e-04\n",
      "Epoch 247/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0364 - val_loss: 0.0372 - learning_rate: 5.0000e-04\n",
      "Epoch 248/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0376 - val_loss: 0.0357 - learning_rate: 5.0000e-04\n",
      "Epoch 249/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0356 - val_loss: 0.0381 - learning_rate: 5.0000e-04\n",
      "Epoch 250/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0385 - val_loss: 0.0428 - learning_rate: 5.0000e-04\n",
      "Epoch 251/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0384 - val_loss: 0.0376 - learning_rate: 5.0000e-04\n",
      "Epoch 252/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0377 - val_loss: 0.0364 - learning_rate: 5.0000e-04\n",
      "Epoch 253/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0374 - val_loss: 0.0400 - learning_rate: 5.0000e-04\n",
      "Epoch 254/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0384 - val_loss: 0.0384 - learning_rate: 5.0000e-04\n",
      "Epoch 255/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0386 - val_loss: 0.0374 - learning_rate: 5.0000e-04\n",
      "Epoch 256/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0367 - val_loss: 0.0389 - learning_rate: 5.0000e-04\n",
      "Epoch 257/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0360 - val_loss: 0.0356 - learning_rate: 5.0000e-04\n",
      "Epoch 258/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0359 - val_loss: 0.0404 - learning_rate: 5.0000e-04\n",
      "Epoch 259/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0388 - val_loss: 0.0399 - learning_rate: 5.0000e-04\n",
      "Epoch 260/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0367 - val_loss: 0.0351 - learning_rate: 5.0000e-04\n",
      "Epoch 261/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0373 - val_loss: 0.0395 - learning_rate: 5.0000e-04\n",
      "Epoch 262/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0371 - val_loss: 0.0384 - learning_rate: 5.0000e-04\n",
      "Epoch 263/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0358 - val_loss: 0.0390 - learning_rate: 5.0000e-04\n",
      "Epoch 264/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0391 - val_loss: 0.0351 - learning_rate: 5.0000e-04\n",
      "Epoch 265/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0370 - val_loss: 0.0394 - learning_rate: 5.0000e-04\n",
      "Epoch 266/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0362 - val_loss: 0.0371 - learning_rate: 5.0000e-04\n",
      "Epoch 267/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0360 - val_loss: 0.0352 - learning_rate: 5.0000e-04\n",
      "Epoch 268/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0376 - learning_rate: 5.0000e-04\n",
      "Epoch 269/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0366 - val_loss: 0.0365 - learning_rate: 5.0000e-04\n",
      "Epoch 270/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0355 - val_loss: 0.0349 - learning_rate: 5.0000e-04\n",
      "Epoch 271/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0352 - val_loss: 0.0363 - learning_rate: 5.0000e-04\n",
      "Epoch 272/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0366 - val_loss: 0.0342 - learning_rate: 5.0000e-04\n",
      "Epoch 273/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0353 - val_loss: 0.0387 - learning_rate: 5.0000e-04\n",
      "Epoch 274/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0379 - val_loss: 0.0355 - learning_rate: 5.0000e-04\n",
      "Epoch 275/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0360 - val_loss: 0.0358 - learning_rate: 5.0000e-04\n",
      "Epoch 276/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0366 - val_loss: 0.0356 - learning_rate: 5.0000e-04\n",
      "Epoch 277/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0374 - val_loss: 0.0363 - learning_rate: 5.0000e-04\n",
      "Epoch 278/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0362 - val_loss: 0.0347 - learning_rate: 5.0000e-04\n",
      "Epoch 279/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0383 - val_loss: 0.0359 - learning_rate: 5.0000e-04\n",
      "Epoch 280/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0374 - val_loss: 0.0358 - learning_rate: 5.0000e-04\n",
      "Epoch 281/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0366 - val_loss: 0.0350 - learning_rate: 5.0000e-04\n",
      "Epoch 282/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0357 - val_loss: 0.0351 - learning_rate: 5.0000e-04\n",
      "Epoch 283/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0353 - val_loss: 0.0368 - learning_rate: 5.0000e-04\n",
      "Epoch 284/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0353 - val_loss: 0.0379 - learning_rate: 5.0000e-04\n",
      "Epoch 285/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0368 - val_loss: 0.0345 - learning_rate: 5.0000e-04\n",
      "Epoch 286/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0339 - val_loss: 0.0361 - learning_rate: 5.0000e-04\n",
      "Epoch 287/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0368 - val_loss: 0.0339 - learning_rate: 5.0000e-04\n",
      "Epoch 288/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0352 - val_loss: 0.0361 - learning_rate: 5.0000e-04\n",
      "Epoch 289/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0354 - val_loss: 0.0367 - learning_rate: 5.0000e-04\n",
      "Epoch 290/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0354 - val_loss: 0.0353 - learning_rate: 5.0000e-04\n",
      "Epoch 291/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0366 - val_loss: 0.0376 - learning_rate: 5.0000e-04\n",
      "Epoch 292/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0390 - val_loss: 0.0365 - learning_rate: 5.0000e-04\n",
      "Epoch 293/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0350 - val_loss: 0.0350 - learning_rate: 5.0000e-04\n",
      "Epoch 294/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0355 - val_loss: 0.0362 - learning_rate: 5.0000e-04\n",
      "Epoch 295/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0368 - val_loss: 0.0351 - learning_rate: 5.0000e-04\n",
      "Epoch 296/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0377 - val_loss: 0.0378 - learning_rate: 5.0000e-04\n",
      "Epoch 297/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0358 - learning_rate: 5.0000e-04\n",
      "Epoch 298/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0382 - val_loss: 0.0382 - learning_rate: 5.0000e-04\n",
      "Epoch 299/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0370 - val_loss: 0.0354 - learning_rate: 5.0000e-04\n",
      "Epoch 300/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0342 - val_loss: 0.0355 - learning_rate: 5.0000e-04\n",
      "Epoch 301/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0371 - val_loss: 0.0364 - learning_rate: 5.0000e-04\n",
      "Epoch 302/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0336 - val_loss: 0.0361 - learning_rate: 5.0000e-04\n",
      "Epoch 303/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0369 - val_loss: 0.0347 - learning_rate: 5.0000e-04\n",
      "Epoch 304/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0351 - val_loss: 0.0366 - learning_rate: 5.0000e-04\n",
      "Epoch 305/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0371 - val_loss: 0.0372 - learning_rate: 5.0000e-04\n",
      "Epoch 306/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0356 - val_loss: 0.0366 - learning_rate: 5.0000e-04\n",
      "Epoch 307/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0351 - val_loss: 0.0349 - learning_rate: 5.0000e-04\n",
      "Epoch 308/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0346 - val_loss: 0.0340 - learning_rate: 2.5000e-04\n",
      "Epoch 309/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0331 - val_loss: 0.0343 - learning_rate: 2.5000e-04\n",
      "Epoch 310/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.0343 - learning_rate: 2.5000e-04\n",
      "Epoch 311/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0349 - val_loss: 0.0341 - learning_rate: 2.5000e-04\n",
      "Epoch 312/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0334 - val_loss: 0.0361 - learning_rate: 2.5000e-04\n",
      "Epoch 313/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0343 - val_loss: 0.0373 - learning_rate: 2.5000e-04\n",
      "Epoch 314/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0335 - val_loss: 0.0387 - learning_rate: 2.5000e-04\n",
      "Epoch 315/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0345 - val_loss: 0.0331 - learning_rate: 2.5000e-04\n",
      "Epoch 316/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0331 - val_loss: 0.0336 - learning_rate: 2.5000e-04\n",
      "Epoch 317/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0342 - val_loss: 0.0354 - learning_rate: 2.5000e-04\n",
      "Epoch 318/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0348 - val_loss: 0.0329 - learning_rate: 2.5000e-04\n",
      "Epoch 319/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0349 - val_loss: 0.0340 - learning_rate: 2.5000e-04\n",
      "Epoch 320/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0342 - val_loss: 0.0325 - learning_rate: 2.5000e-04\n",
      "Epoch 321/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0334 - val_loss: 0.0354 - learning_rate: 2.5000e-04\n",
      "Epoch 322/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0342 - val_loss: 0.0347 - learning_rate: 2.5000e-04\n",
      "Epoch 323/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0332 - val_loss: 0.0328 - learning_rate: 2.5000e-04\n",
      "Epoch 324/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0336 - val_loss: 0.0335 - learning_rate: 2.5000e-04\n",
      "Epoch 325/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0339 - val_loss: 0.0346 - learning_rate: 2.5000e-04\n",
      "Epoch 326/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0330 - val_loss: 0.0332 - learning_rate: 2.5000e-04\n",
      "Epoch 327/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0343 - val_loss: 0.0344 - learning_rate: 2.5000e-04\n",
      "Epoch 328/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0333 - val_loss: 0.0344 - learning_rate: 2.5000e-04\n",
      "Epoch 329/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0347 - val_loss: 0.0328 - learning_rate: 2.5000e-04\n",
      "Epoch 330/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0328 - val_loss: 0.0363 - learning_rate: 2.5000e-04\n",
      "Epoch 331/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0332 - val_loss: 0.0344 - learning_rate: 2.5000e-04\n",
      "Epoch 332/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0344 - val_loss: 0.0334 - learning_rate: 2.5000e-04\n",
      "Epoch 333/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0327 - val_loss: 0.0325 - learning_rate: 2.5000e-04\n",
      "Epoch 334/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0334 - val_loss: 0.0338 - learning_rate: 2.5000e-04\n",
      "Epoch 335/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0327 - val_loss: 0.0334 - learning_rate: 2.5000e-04\n",
      "Epoch 336/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0326 - val_loss: 0.0331 - learning_rate: 2.5000e-04\n",
      "Epoch 337/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0343 - val_loss: 0.0331 - learning_rate: 2.5000e-04\n",
      "Epoch 338/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0326 - val_loss: 0.0339 - learning_rate: 2.5000e-04\n",
      "Epoch 339/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0341 - val_loss: 0.0361 - learning_rate: 2.5000e-04\n",
      "Epoch 340/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0350 - val_loss: 0.0332 - learning_rate: 2.5000e-04\n",
      "Epoch 341/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0327 - learning_rate: 1.2500e-04\n",
      "Epoch 342/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0327 - val_loss: 0.0334 - learning_rate: 1.2500e-04\n",
      "Epoch 343/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0330 - val_loss: 0.0331 - learning_rate: 1.2500e-04\n",
      "Epoch 344/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0325 - val_loss: 0.0331 - learning_rate: 1.2500e-04\n",
      "Epoch 345/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0320 - val_loss: 0.0324 - learning_rate: 1.2500e-04\n",
      "Epoch 346/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0318 - val_loss: 0.0327 - learning_rate: 1.2500e-04\n",
      "Epoch 347/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0334 - val_loss: 0.0327 - learning_rate: 1.2500e-04\n",
      "Epoch 348/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0313 - val_loss: 0.0328 - learning_rate: 1.2500e-04\n",
      "Epoch 349/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0327 - val_loss: 0.0328 - learning_rate: 1.2500e-04\n",
      "Epoch 350/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0322 - val_loss: 0.0331 - learning_rate: 1.2500e-04\n",
      "Epoch 351/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0329 - val_loss: 0.0334 - learning_rate: 1.2500e-04\n",
      "Epoch 352/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0326 - val_loss: 0.0321 - learning_rate: 1.2500e-04\n",
      "Epoch 353/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0328 - val_loss: 0.0324 - learning_rate: 1.2500e-04\n",
      "Epoch 354/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0320 - val_loss: 0.0335 - learning_rate: 1.2500e-04\n",
      "Epoch 355/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0329 - val_loss: 0.0323 - learning_rate: 1.2500e-04\n",
      "Epoch 356/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0321 - val_loss: 0.0325 - learning_rate: 1.2500e-04\n",
      "Epoch 357/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0334 - val_loss: 0.0328 - learning_rate: 1.2500e-04\n",
      "Epoch 358/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0317 - val_loss: 0.0325 - learning_rate: 1.2500e-04\n",
      "Epoch 359/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0317 - val_loss: 0.0336 - learning_rate: 1.2500e-04\n",
      "Epoch 360/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0330 - val_loss: 0.0330 - learning_rate: 1.2500e-04\n",
      "Epoch 361/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0328 - val_loss: 0.0328 - learning_rate: 1.2500e-04\n",
      "Epoch 362/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0323 - val_loss: 0.0335 - learning_rate: 1.2500e-04\n",
      "Epoch 363/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0328 - val_loss: 0.0327 - learning_rate: 1.2500e-04\n",
      "Epoch 364/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0326 - val_loss: 0.0324 - learning_rate: 1.2500e-04\n",
      "Epoch 365/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0329 - val_loss: 0.0329 - learning_rate: 1.2500e-04\n",
      "Epoch 366/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0324 - val_loss: 0.0329 - learning_rate: 1.2500e-04\n",
      "Epoch 367/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0321 - val_loss: 0.0321 - learning_rate: 1.2500e-04\n",
      "Epoch 368/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0319 - val_loss: 0.0324 - learning_rate: 1.2500e-04\n",
      "Epoch 369/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0312 - val_loss: 0.0327 - learning_rate: 1.2500e-04\n",
      "Epoch 370/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0327 - val_loss: 0.0324 - learning_rate: 1.2500e-04\n",
      "Epoch 371/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0321 - val_loss: 0.0323 - learning_rate: 1.2500e-04\n",
      "Epoch 372/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0314 - val_loss: 0.0322 - learning_rate: 1.2500e-04\n",
      "Epoch 373/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0318 - val_loss: 0.0320 - learning_rate: 6.2500e-05\n",
      "Epoch 374/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0320 - val_loss: 0.0324 - learning_rate: 6.2500e-05\n",
      "Epoch 375/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0322 - val_loss: 0.0322 - learning_rate: 6.2500e-05\n",
      "Epoch 376/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0323 - val_loss: 0.0324 - learning_rate: 6.2500e-05\n",
      "Epoch 377/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0317 - val_loss: 0.0323 - learning_rate: 6.2500e-05\n",
      "Epoch 378/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0320 - val_loss: 0.0325 - learning_rate: 6.2500e-05\n",
      "Epoch 379/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0330 - val_loss: 0.0325 - learning_rate: 6.2500e-05\n",
      "Epoch 380/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0319 - val_loss: 0.0321 - learning_rate: 6.2500e-05\n",
      "Epoch 381/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0316 - val_loss: 0.0321 - learning_rate: 6.2500e-05\n",
      "Epoch 382/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0316 - val_loss: 0.0319 - learning_rate: 6.2500e-05\n",
      "Epoch 383/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0315 - val_loss: 0.0322 - learning_rate: 6.2500e-05\n",
      "Epoch 384/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0326 - val_loss: 0.0320 - learning_rate: 6.2500e-05\n",
      "Epoch 385/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0323 - val_loss: 0.0322 - learning_rate: 6.2500e-05\n",
      "Epoch 386/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0311 - val_loss: 0.0318 - learning_rate: 6.2500e-05\n",
      "Epoch 387/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0321 - val_loss: 0.0321 - learning_rate: 6.2500e-05\n",
      "Epoch 388/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0316 - val_loss: 0.0323 - learning_rate: 6.2500e-05\n",
      "Epoch 389/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0309 - val_loss: 0.0327 - learning_rate: 6.2500e-05\n",
      "Epoch 390/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0313 - val_loss: 0.0318 - learning_rate: 6.2500e-05\n",
      "Epoch 391/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0317 - val_loss: 0.0319 - learning_rate: 6.2500e-05\n",
      "Epoch 392/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0315 - val_loss: 0.0319 - learning_rate: 6.2500e-05\n",
      "Epoch 393/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0312 - val_loss: 0.0318 - learning_rate: 6.2500e-05\n",
      "Epoch 394/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0317 - val_loss: 0.0321 - learning_rate: 6.2500e-05\n",
      "Epoch 395/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0322 - val_loss: 0.0323 - learning_rate: 6.2500e-05\n",
      "Epoch 396/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0323 - val_loss: 0.0321 - learning_rate: 6.2500e-05\n",
      "Epoch 397/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0314 - val_loss: 0.0317 - learning_rate: 6.2500e-05\n",
      "Epoch 398/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0318 - val_loss: 0.0325 - learning_rate: 6.2500e-05\n",
      "Epoch 399/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0324 - val_loss: 0.0322 - learning_rate: 6.2500e-05\n",
      "Epoch 400/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0314 - val_loss: 0.0318 - learning_rate: 6.2500e-05\n",
      "Epoch 401/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0318 - val_loss: 0.0323 - learning_rate: 6.2500e-05\n",
      "Epoch 402/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0315 - val_loss: 0.0320 - learning_rate: 6.2500e-05\n",
      "Epoch 403/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0319 - val_loss: 0.0317 - learning_rate: 6.2500e-05\n",
      "Epoch 404/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0317 - val_loss: 0.0317 - learning_rate: 6.2500e-05\n",
      "Epoch 405/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0317 - val_loss: 0.0326 - learning_rate: 6.2500e-05\n",
      "Epoch 406/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0311 - val_loss: 0.0323 - learning_rate: 6.2500e-05\n",
      "Epoch 407/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0315 - val_loss: 0.0322 - learning_rate: 6.2500e-05\n",
      "Epoch 408/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0319 - learning_rate: 6.2500e-05\n",
      "Epoch 409/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0316 - val_loss: 0.0319 - learning_rate: 6.2500e-05\n",
      "Epoch 410/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0316 - val_loss: 0.0320 - learning_rate: 6.2500e-05\n",
      "Epoch 411/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0326 - val_loss: 0.0319 - learning_rate: 6.2500e-05\n",
      "Epoch 412/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0321 - val_loss: 0.0322 - learning_rate: 6.2500e-05\n",
      "Epoch 413/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0311 - val_loss: 0.0321 - learning_rate: 6.2500e-05\n",
      "Epoch 414/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0321 - val_loss: 0.0320 - learning_rate: 6.2500e-05\n",
      "Epoch 415/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0321 - val_loss: 0.0316 - learning_rate: 6.2500e-05\n",
      "Epoch 416/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0316 - val_loss: 0.0318 - learning_rate: 6.2500e-05\n",
      "Epoch 417/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0317 - val_loss: 0.0317 - learning_rate: 6.2500e-05\n",
      "Epoch 418/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0321 - val_loss: 0.0317 - learning_rate: 3.1250e-05\n",
      "Epoch 419/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0309 - val_loss: 0.0316 - learning_rate: 3.1250e-05\n",
      "Epoch 420/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0317 - val_loss: 0.0316 - learning_rate: 3.1250e-05\n",
      "Epoch 421/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0317 - learning_rate: 3.1250e-05\n",
      "Epoch 422/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0307 - val_loss: 0.0320 - learning_rate: 3.1250e-05\n",
      "Epoch 423/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0316 - learning_rate: 3.1250e-05\n",
      "Epoch 424/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0306 - val_loss: 0.0319 - learning_rate: 3.1250e-05\n",
      "Epoch 425/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0317 - val_loss: 0.0317 - learning_rate: 3.1250e-05\n",
      "Epoch 426/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0314 - val_loss: 0.0317 - learning_rate: 3.1250e-05\n",
      "Epoch 427/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0311 - val_loss: 0.0317 - learning_rate: 3.1250e-05\n",
      "Epoch 428/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0315 - val_loss: 0.0318 - learning_rate: 3.1250e-05\n",
      "Epoch 429/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0319 - val_loss: 0.0318 - learning_rate: 3.1250e-05\n",
      "Epoch 430/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0303 - val_loss: 0.0316 - learning_rate: 3.1250e-05\n",
      "Epoch 431/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0314 - val_loss: 0.0316 - learning_rate: 3.1250e-05\n",
      "Epoch 432/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0317 - val_loss: 0.0317 - learning_rate: 3.1250e-05\n",
      "Epoch 433/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0319 - val_loss: 0.0316 - learning_rate: 3.1250e-05\n",
      "Epoch 434/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0310 - val_loss: 0.0314 - learning_rate: 3.1250e-05\n",
      "Epoch 435/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0314 - val_loss: 0.0318 - learning_rate: 3.1250e-05\n",
      "Epoch 436/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0319 - val_loss: 0.0315 - learning_rate: 3.1250e-05\n",
      "Epoch 437/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0311 - val_loss: 0.0320 - learning_rate: 3.1250e-05\n",
      "Epoch 438/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0314 - val_loss: 0.0316 - learning_rate: 3.1250e-05\n",
      "Epoch 439/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0308 - val_loss: 0.0320 - learning_rate: 3.1250e-05\n",
      "Epoch 440/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0323 - val_loss: 0.0315 - learning_rate: 3.1250e-05\n",
      "Epoch 441/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0310 - val_loss: 0.0317 - learning_rate: 3.1250e-05\n",
      "Epoch 442/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0314 - val_loss: 0.0318 - learning_rate: 3.1250e-05\n",
      "Epoch 443/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0304 - val_loss: 0.0319 - learning_rate: 3.1250e-05\n",
      "Epoch 444/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0320 - learning_rate: 3.1250e-05\n",
      "Epoch 445/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0315 - val_loss: 0.0318 - learning_rate: 3.1250e-05\n",
      "Epoch 446/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: 0.0319 - learning_rate: 3.1250e-05\n",
      "Epoch 447/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0311 - val_loss: 0.0318 - learning_rate: 3.1250e-05\n",
      "Epoch 448/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0307 - val_loss: 0.0318 - learning_rate: 3.1250e-05\n",
      "Epoch 449/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0308 - val_loss: 0.0319 - learning_rate: 3.1250e-05\n",
      "Epoch 450/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: 0.0317 - learning_rate: 3.1250e-05\n",
      "Epoch 451/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0314 - val_loss: 0.0316 - learning_rate: 3.1250e-05\n",
      "Epoch 452/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0311 - val_loss: 0.0319 - learning_rate: 3.1250e-05\n",
      "Epoch 453/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0313 - val_loss: 0.0317 - learning_rate: 3.1250e-05\n",
      "Epoch 454/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0316 - val_loss: 0.0321 - learning_rate: 3.1250e-05\n",
      "Epoch 455/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0306 - val_loss: 0.0316 - learning_rate: 1.5625e-05\n",
      "Epoch 456/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0311 - val_loss: 0.0315 - learning_rate: 1.5625e-05\n",
      "Epoch 457/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0310 - val_loss: 0.0316 - learning_rate: 1.5625e-05\n",
      "Epoch 458/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0302 - val_loss: 0.0315 - learning_rate: 1.5625e-05\n",
      "Epoch 459/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0321 - val_loss: 0.0315 - learning_rate: 1.5625e-05\n",
      "Epoch 460/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0308 - val_loss: 0.0315 - learning_rate: 1.5625e-05\n",
      "Epoch 461/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0318 - val_loss: 0.0317 - learning_rate: 1.5625e-05\n",
      "Epoch 462/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.0316 - learning_rate: 1.5625e-05\n",
      "Epoch 463/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: 0.0315 - learning_rate: 1.5625e-05\n",
      "Epoch 464/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0305 - val_loss: 0.0316 - learning_rate: 1.5625e-05\n",
      "Epoch 465/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0316 - learning_rate: 1.5625e-05\n",
      "Epoch 466/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0308 - val_loss: 0.0316 - learning_rate: 1.5625e-05\n",
      "Epoch 467/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0317 - val_loss: 0.0315 - learning_rate: 1.5625e-05\n",
      "Epoch 468/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0313 - val_loss: 0.0316 - learning_rate: 1.5625e-05\n",
      "Epoch 469/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0308 - val_loss: 0.0315 - learning_rate: 1.5625e-05\n",
      "Epoch 470/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0309 - val_loss: 0.0316 - learning_rate: 1.5625e-05\n",
      "Epoch 471/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0319 - val_loss: 0.0314 - learning_rate: 1.5625e-05\n",
      "Epoch 472/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0319 - val_loss: 0.0315 - learning_rate: 1.5625e-05\n",
      "Epoch 473/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0310 - val_loss: 0.0315 - learning_rate: 1.5625e-05\n",
      "Epoch 474/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0307 - val_loss: 0.0317 - learning_rate: 1.5625e-05\n",
      "Epoch 475/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0315 - val_loss: 0.0315 - learning_rate: 7.8125e-06\n",
      "Epoch 476/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0303 - val_loss: 0.0315 - learning_rate: 7.8125e-06\n",
      "Epoch 477/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0322 - val_loss: 0.0315 - learning_rate: 7.8125e-06\n",
      "Epoch 478/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0309 - val_loss: 0.0315 - learning_rate: 7.8125e-06\n",
      "Epoch 479/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0304 - val_loss: 0.0315 - learning_rate: 7.8125e-06\n",
      "Epoch 480/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0313 - val_loss: 0.0315 - learning_rate: 7.8125e-06\n",
      "Epoch 481/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0309 - val_loss: 0.0315 - learning_rate: 7.8125e-06\n",
      "Epoch 482/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0303 - val_loss: 0.0315 - learning_rate: 7.8125e-06\n",
      "Epoch 483/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0311 - val_loss: 0.0315 - learning_rate: 7.8125e-06\n",
      "Epoch 484/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0316 - val_loss: 0.0315 - learning_rate: 7.8125e-06\n",
      "Epoch 485/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0314 - val_loss: 0.0315 - learning_rate: 7.8125e-06\n",
      "Epoch 486/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0316 - val_loss: 0.0315 - learning_rate: 7.8125e-06\n",
      "Epoch 487/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 7.8125e-06\n",
      "Epoch 488/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 7.8125e-06\n",
      "Epoch 489/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0315 - learning_rate: 7.8125e-06\n",
      "Epoch 490/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0304 - val_loss: 0.0315 - learning_rate: 7.8125e-06\n",
      "Epoch 491/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0314 - learning_rate: 7.8125e-06\n",
      "Epoch 492/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0306 - val_loss: 0.0315 - learning_rate: 7.8125e-06\n",
      "Epoch 493/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 7.8125e-06\n",
      "Epoch 494/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0314 - val_loss: 0.0314 - learning_rate: 7.8125e-06\n",
      "Epoch 495/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0315 - val_loss: 0.0314 - learning_rate: 3.9063e-06\n",
      "Epoch 496/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0316 - val_loss: 0.0315 - learning_rate: 3.9063e-06\n",
      "Epoch 497/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0306 - val_loss: 0.0315 - learning_rate: 3.9063e-06\n",
      "Epoch 498/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0305 - val_loss: 0.0315 - learning_rate: 3.9063e-06\n",
      "Epoch 499/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0315 - learning_rate: 3.9063e-06\n",
      "Epoch 500/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0313 - val_loss: 0.0315 - learning_rate: 3.9063e-06\n",
      "Epoch 501/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0314 - learning_rate: 3.9063e-06\n",
      "Epoch 502/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0310 - val_loss: 0.0314 - learning_rate: 3.9063e-06\n",
      "Epoch 503/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.0314 - learning_rate: 3.9063e-06\n",
      "Epoch 504/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0314 - learning_rate: 3.9063e-06\n",
      "Epoch 505/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0316 - val_loss: 0.0315 - learning_rate: 3.9063e-06\n",
      "Epoch 506/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 3.9063e-06\n",
      "Epoch 507/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0306 - val_loss: 0.0314 - learning_rate: 3.9063e-06\n",
      "Epoch 508/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0311 - val_loss: 0.0314 - learning_rate: 3.9063e-06\n",
      "Epoch 509/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0322 - val_loss: 0.0314 - learning_rate: 3.9063e-06\n",
      "Epoch 510/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0314 - val_loss: 0.0314 - learning_rate: 3.9063e-06\n",
      "Epoch 511/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0306 - val_loss: 0.0315 - learning_rate: 3.9063e-06\n",
      "Epoch 512/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 3.9063e-06\n",
      "Epoch 513/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0319 - val_loss: 0.0314 - learning_rate: 3.9063e-06\n",
      "Epoch 514/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 3.9063e-06\n",
      "Epoch 515/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0316 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 516/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0311 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 517/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0309 - val_loss: 0.0315 - learning_rate: 1.9531e-06\n",
      "Epoch 518/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0315 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 519/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0306 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 520/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 521/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0314 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 522/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0315 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 523/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0306 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 524/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0301 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 525/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 526/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.0315 - learning_rate: 1.9531e-06\n",
      "Epoch 527/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0310 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 528/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0313 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 529/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0317 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 530/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 531/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 532/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 533/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 534/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0301 - val_loss: 0.0314 - learning_rate: 1.9531e-06\n",
      "Epoch 535/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 536/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0298 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 537/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 538/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 539/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0304 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 540/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0304 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 541/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0315 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 542/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0311 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 543/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0314 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 544/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 545/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0313 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 546/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 547/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0310 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 548/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 549/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 550/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0314 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 551/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 552/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 553/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0314 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 554/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0316 - val_loss: 0.0314 - learning_rate: 9.7656e-07\n",
      "Epoch 555/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0313 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 556/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 557/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 558/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 559/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 560/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0319 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 561/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0303 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 562/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0310 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 563/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0314 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 564/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0300 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 565/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 566/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0300 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 567/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0314 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 568/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 569/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 570/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 571/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0313 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 572/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0310 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 573/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 574/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 4.8828e-07\n",
      "Epoch 575/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0302 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 576/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 577/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0306 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 578/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0312 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 579/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 580/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 581/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0303 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 582/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0316 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 583/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0311 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 584/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 585/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 586/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0313 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 587/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 588/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0306 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 589/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0306 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 590/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 591/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0301 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 592/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 593/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 594/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0314 - learning_rate: 2.4414e-07\n",
      "Epoch 595/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0302 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 596/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0303 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 597/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 598/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 599/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 600/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 601/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0312 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 602/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0311 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 603/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0303 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 604/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 605/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0318 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 606/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0313 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 607/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0313 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 608/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0313 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 609/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 610/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0311 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 611/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0313 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 612/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0298 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 613/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 614/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0314 - val_loss: 0.0314 - learning_rate: 1.2207e-07\n",
      "Epoch 615/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0317 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 616/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0301 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 617/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0302 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 618/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 619/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0311 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 620/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0313 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 621/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0306 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 622/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0304 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 623/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 624/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 625/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 626/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 627/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0310 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 628/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 629/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0301 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 630/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0304 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 631/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0302 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 632/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 633/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 634/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0312 - val_loss: 0.0314 - learning_rate: 6.1035e-08\n",
      "Epoch 635/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 636/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0311 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 637/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0306 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 638/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 639/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0319 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 640/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0311 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 641/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0301 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 642/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 643/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0311 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 644/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 645/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 646/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 647/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0313 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 648/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 649/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 650/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0310 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 651/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 652/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0306 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 653/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 654/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 3.0518e-08\n",
      "Epoch 655/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 656/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 657/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0311 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 658/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 659/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 660/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 661/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0312 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 662/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0301 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 663/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0314 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 664/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 665/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 666/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0315 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 667/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 668/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 669/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0306 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 670/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0315 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 671/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 672/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0315 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 673/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0307 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 674/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0300 - val_loss: 0.0314 - learning_rate: 1.5259e-08\n",
      "Epoch 675/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 676/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0306 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 677/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0312 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 678/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0300 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 679/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0304 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 680/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 681/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 682/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0310 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 683/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0312 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 684/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0309 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 685/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0316 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 686/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0306 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 687/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 688/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0302 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 689/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 690/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 691/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0315 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 692/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0308 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 693/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 694/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0306 - val_loss: 0.0314 - learning_rate: 7.6294e-09\n",
      "Epoch 695/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 3.8147e-09\n",
      "Epoch 696/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0306 - val_loss: 0.0314 - learning_rate: 3.8147e-09\n",
      "Epoch 697/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0312 - val_loss: 0.0314 - learning_rate: 3.8147e-09\n",
      "Epoch 698/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0305 - val_loss: 0.0314 - learning_rate: 3.8147e-09\n",
      "Epoch 699/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0303 - val_loss: 0.0314 - learning_rate: 3.8147e-09\n",
      "Epoch 700/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0312 - val_loss: 0.0314 - learning_rate: 3.8147e-09\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam, AdamW, RMSprop, Nadam,SGD\n",
    "\n",
    "#definiciones \n",
    "act_name = \"relu\"\n",
    "l2_reg = 0.0007 #0.0001\n",
    "epoch = 700\n",
    "b_s = 64 \n",
    "optimizer_name = Adam(learning_rate=1e-3)\n",
    "# optimizer_name = RMSprop(learning_rate=1e-3)\n",
    "\n",
    "inputs = Input(shape=(5,))\n",
    "# encoded = Dense(8, activation='relu',kernel_regularizer=l2(l2_reg))(inputs)  # Compresión 8 V3 16 n \n",
    "# encoded = Dense(16, activation='relu',kernel_regularizer=l2(l2_reg))(encoded) #V3\n",
    "encoded = Dense(32, activation='relu',kernel_regularizer=l2(l2_reg))(inputs)\n",
    "# encoded = Dense(64, activation = 'relu',kernel_regularizer=l2(l2_reg))(encoded)\n",
    "encoded = Dense(80, activation = 'relu',kernel_regularizer=l2(l2_reg))(encoded)\n",
    "# encoded = Dense(90, activation = 'relu',kernel_regularizer=l2(l2_reg))(encoded)\n",
    "# encoded = Dense(100, activation = 'relu',kernel_regularizer=l2(l2_reg))(encoded)\n",
    "encoded = Dense(128, activation=act_name, kernel_regularizer=l2(l2_reg))(encoded)\n",
    "encoded = Dense(256, activation=act_name, kernel_regularizer=l2(l2_reg))(encoded)\n",
    "decoded = Dense(100, activation='linear',kernel_regularizer=l2(l2_reg), name = 'x_output')(encoded)  # Reconstrucción a 100 puntos\n",
    "\n",
    "# Definición del modelo\n",
    "autoencoder_x = Model(inputs, decoded)\n",
    "autoencoder_x.compile(optimizer = optimizer_name, loss='mae') #, metrics=['mae']\n",
    "autoencoder_x.summary()\n",
    "\n",
    "history = autoencoder_x.fit(x_train,y_train_x_scaled,\n",
    "                          epochs = epoch, \n",
    "                          batch_size = b_s,\n",
    "                          validation_split = 0.1,\n",
    "                          callbacks=[reduce_lr]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0301\n",
      "Pérdida en datos de Test: 0.02991759404540062\n"
     ]
    }
   ],
   "source": [
    "loss = autoencoder_x.evaluate(x_test, y_test_x_scaled)\n",
    "print(f'Pérdida en datos de Test: {loss}')\n",
    "\n",
    "# nota: 0.00032 \n",
    "# [0.003203689120709896, 0.032577596604824066]\n",
    "# [0.0031841585878282785, 0.031963370740413666]\n",
    "# [0.00023003153910394758, 0.008729767054319382] Esto me muestra sin L2(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n"
     ]
    }
   ],
   "source": [
    "idx = 10 \n",
    "\n",
    "# print(x_test.iloc[idx])\n",
    " # Elegir una muestra para comparar (observar luego la muestra 30)\n",
    "\n",
    "# Predicción de una muestra \n",
    "y_pred_scaled = autoencoder_x.predict(np.expand_dims(x_test.iloc[idx], axis=0))\n",
    "###############################################\n",
    "y_true = y_test_x.iloc[idx].to_numpy() # Se obtine Algo de tipo Serie y se lo pasa a numpy\n",
    "#Desnormalizamos \n",
    "y_pred = scaler_x.inverse_transform(y_pred_scaled)\n",
    "y_pred = y_pred.flatten() # [[...,...,...,....,]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "luego ver las graficas de la num 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Graficamos \n",
    "# Buscamos los máximos y mínimos \n",
    "y_true_max = np.max(y_true)\n",
    "y_true_min = np.min(y_true)\n",
    "\n",
    "y_pred_max = np.max(y_pred)\n",
    "y_pred_min = np.min(y_pred)\n",
    "\n",
    "# Pos x\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(y_true*R0, label='Posiciones X reales', linestyle='None', marker='.')\n",
    "plt.plot(y_pred*R0, label='Posiciones X predichas', linestyle = 'None',marker='o')\n",
    "# Dibujamos los max y min\n",
    "plt.axhline(y = y_true_max, color = 'red', linestyle = '-.', label=f'Máx_true: {y_true_max:.3f}')\n",
    "plt.axhline(y = y_pred_max, color = 'red', linestyle = ':', label= f'Máx_pred: {y_pred_max:.3f}')\n",
    "plt.axhline(y = y_true_min, color = 'blue', linestyle ='-.', label=f'Mín_true: {y_true_min:.3f}')\n",
    "plt.axhline(y = y_pred_min, color = 'blue', linestyle = ':',label= f'Mín_pred:{y_pred_min: .3f}')\n",
    "\n",
    "# plt.ylim(-35,-50) ##(-60,-30)\n",
    "plt.title('Comparación de Posiciones X')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cuadratico Medio:9.660377738272337e-06, Raiz del Error Cuadratico Medio:0.0031081148206384425 [Km]\n"
     ]
    }
   ],
   "source": [
    "ecm, recm = utlnn.calculate_ECM_RECM(y_true,y_pred)\n",
    "print(f'Error Cuadratico Medio:{ecm}, Raiz del Error Cuadratico Medio:{recm} [Km]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "\n",
    "if save_model == True:\n",
    "  autoencoder_x.save('../modelos_entrenamiento/mod_x_R0/mod_x_400_32_vs10_Nadam_l2_0.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pérdida en datos de Test: 30.48688316345215  / mod_x_800_130_vs10 (Despues de 55 pasadas)\n",
    "# Pérdida en datos de Test: 112.4796371459961 / mod_x_700_80_vs10\n",
    "# Pérdida en datos de Test: 93.09298706054688 / mod_x_800_90_vs10\n",
    "# Pérdida en datos de Test: 36.03205490112305 / mod_x_800_160_vs10_AdamW_l2_0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opciones de Optimizadores Utilizados\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "optimizer = RMSprop(learning_rate=1e-3, rho=0.9)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
