{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Utils import utils_nn as utlnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_excel(\"../Train_Test/Dataset_Separado/x_test_new.xlsx\")\n",
    "x_train = pd.read_excel(\"../Train_Test/Dataset_Separado/x_train_new.xlsx\")\n",
    "y_test = pd.read_excel(\"../Train_Test/Dataset_Separado/y_test_new.xlsx\")\n",
    "y_train = pd.read_excel(\"../Train_Test/Dataset_Separado/y_train_new.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## De mi y_train y y_test solo quiero las coordenadas Z\n",
    "R0 = 6.371E6\n",
    "out_z_coord = [f'z_{i}' for i in range(1,101)]\n",
    "y_train_z = y_train[out_z_coord]/R0\n",
    "y_test_z = y_test[out_z_coord]/R0\n",
    "# 'y_test_z son las columnas filtradas de las 3 coordenadas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de x_train: (4104, 9)\n",
      "Columna 0 (latitude_pos_tx): min=-42.2800, max=-42.2800, mean=-42.2800, std=0.0000\n",
      "Columna 1 (longitude_pos_tx): min=-63.4000, max=-63.4000, mean=-63.4000, std=0.0000\n",
      "Columna 2 (elevation_pos_tx): min=0.0000, max=0.0000, mean=0.0000, std=0.0000\n",
      "Columna 3 (fc [Mhz]): min=3.0000, max=30.0000, mean=13.7032, std=6.9191\n",
      "Columna 4 (elevation): min=0.0000, max=40.0000, mean=13.6659, std=11.8820\n",
      "Columna 5 (azimuth): min=87.0000, max=98.0000, mean=92.8209, std=4.5824\n",
      "Columna 6 (year): min=2010.0000, max=2010.0000, mean=2010.0000, std=0.0000\n",
      "Columna 7 (mmdd): min=101.0000, max=1231.0000, mean=985.1394, std=348.8719\n",
      "Columna 8 (hour): min=0.0000, max=20.0000, mean=11.1647, std=4.5880\n"
     ]
    }
   ],
   "source": [
    "print(\"Forma de x_train:\", x_train.shape)\n",
    "\n",
    "for i, col_name in enumerate(x_train.columns):\n",
    "    col = x_train[col_name]\n",
    "    print(f\"Columna {i} ({col_name}): min={col.min():.4f}, max={col.max():.4f}, mean={col.mean():.4f}, std={col.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De toda la Información anterior observo que las columnas como.\n",
    "latitude_pos_tx: -42.28 (valor único y constante)\n",
    "longitude_pos_tx: -63.40 (valor único y constante)\n",
    "elevation_pos_tx: 0.0 (valor único y constante)\n",
    "year: 2010 (valor único y constante)\n",
    "\n",
    "Estas 4 columnas tienen desviacion estándar 0, es decir, no aportan nada al aprendizaje del modelo.\\\n",
    "**Nota**: Los modelos de ML aprenden de las variaciones, y esas columnas no tienen ninguna.\\\n",
    "Procedemos a quitarlos del x_train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(columns = ['latitude_pos_tx', 'longitude_pos_tx', 'elevation_pos_tx', 'year'])\n",
    "x_test = x_test.drop(columns =['latitude_pos_tx', 'longitude_pos_tx', 'elevation_pos_tx', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizamos la salida\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_z = MinMaxScaler()\n",
    "y_train_z_scaled = scaler_z.fit_transform(y_train_z)\n",
    "y_test_z_scaled = scaler_z.transform(y_test_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch = 1160 #1160\n",
    "# b_s = 70\n",
    "# act_name = 'relu'\n",
    "# l2_reg = 0.003\n",
    "# optimizer_name= 'adamW'\n",
    "# while epoch <= 1500:\n",
    "#   while b_s <= 130:\n",
    "    \n",
    "#     inputs = Input(shape=(9,))\n",
    "#     encoded = Dense(9, activation= act_name, kernel_regularizer= l2(l2_reg))(inputs)\n",
    "#     encoded = Dense(16, activation= act_name)(encoded) #, kernel_regularizer= l2(l2_reg)\n",
    "#     encoded = Dense(32, activation= act_name, kernel_regularizer= l2(l2_reg))(encoded)\n",
    "#     encoded = Dense(64, activation= act_name)(encoded) # , kernel_regularizer= l2(l2_reg)\n",
    "#     encoded = Dense(80, activation= act_name, kernel_regularizer= l2(l2_reg))(encoded)\n",
    "#     encoded = Dense(90, activation= act_name)(encoded) #, kernel_regularizer= l2(l2_reg)\n",
    "#     decoded = Dense(100, activation= 'linear', kernel_regularizer= l2(l2_reg), name ='z_output')(encoded)\n",
    "\n",
    "#     autoencoder_y = Model(inputs, decoded)\n",
    "#     autoencoder_y.compile(optimizer = optimizer_name, loss= 'mse')\n",
    "#     autoencoder_y.summary()\n",
    "\n",
    "#     history = autoencoder_y.fit(x_train,y_train_z,\n",
    "#                                 epochs = epoch,\n",
    "#                                 batch_size = b_s,\n",
    "#                                 validation_split = 0.1)\n",
    "    \n",
    "#     loss = autoencoder_y.evaluate(x_test,y_test_z)\n",
    "\n",
    "#     if loss <= 60: # 35\n",
    "#       autoencoder_y.save(f'../modelos_entrenamiento/modelos_z/mod_z_{epoch}_{b_s}_vs10_{optimizer_name}_loss_{round(loss)}.keras')\n",
    "#     print(f'Pérdida en datos de Test: {loss} epoch: {epoch}, batch_size: {b_s}')\n",
    "#     b_s +=20\n",
    "#   b_s = 80\n",
    "#   epoch +=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "  monitor = 'val_loss',\t#monitoriamos la pérdida en validación\n",
    "  patience = 30, # Si no mejora en 10->20 epochs, detenemos el entrenamiento.\n",
    "  restore_best_weights = True # Restaura los mejores pesos encontrados.\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "  monitor = 'val_loss',\n",
    "  patience = 20,\n",
    "  factor = 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ z_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,500</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ z_output (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m6,500\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,804</span> (34.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,804\u001b[0m (34.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,804</span> (34.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,804\u001b[0m (34.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 1893.3698 - mae: 24.8960 - val_loss: 1.6348 - val_mae: 0.9359 - learning_rate: 0.0010\n",
      "Epoch 2/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0514 - mae: 0.7431 - val_loss: 0.4842 - val_mae: 0.5331 - learning_rate: 0.0010\n",
      "Epoch 3/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4447 - mae: 0.5042 - val_loss: 0.3382 - val_mae: 0.4438 - learning_rate: 0.0010\n",
      "Epoch 4/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3167 - mae: 0.4249 - val_loss: 0.2415 - val_mae: 0.3690 - learning_rate: 0.0010\n",
      "Epoch 5/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2283 - mae: 0.3543 - val_loss: 0.1804 - val_mae: 0.3143 - learning_rate: 0.0010\n",
      "Epoch 6/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1749 - mae: 0.3076 - val_loss: 0.1461 - val_mae: 0.2825 - learning_rate: 0.0010\n",
      "Epoch 7/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1408 - mae: 0.2740 - val_loss: 0.1153 - val_mae: 0.2471 - learning_rate: 0.0010\n",
      "Epoch 8/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1132 - mae: 0.2425 - val_loss: 0.0896 - val_mae: 0.2164 - learning_rate: 0.0010\n",
      "Epoch 9/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0907 - mae: 0.2152 - val_loss: 0.0774 - val_mae: 0.1966 - learning_rate: 0.0010\n",
      "Epoch 10/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0726 - mae: 0.1905 - val_loss: 0.0772 - val_mae: 0.2012 - learning_rate: 0.0010\n",
      "Epoch 11/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0662 - mae: 0.1818 - val_loss: 0.0600 - val_mae: 0.1760 - learning_rate: 0.0010\n",
      "Epoch 12/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0521 - mae: 0.1576 - val_loss: 0.0442 - val_mae: 0.1438 - learning_rate: 0.0010\n",
      "Epoch 13/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0409 - mae: 0.1359 - val_loss: 0.0401 - val_mae: 0.1344 - learning_rate: 0.0010\n",
      "Epoch 14/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0390 - mae: 0.1324 - val_loss: 0.0359 - val_mae: 0.1280 - learning_rate: 0.0010\n",
      "Epoch 15/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0319 - mae: 0.1162 - val_loss: 0.0278 - val_mae: 0.1032 - learning_rate: 0.0010\n",
      "Epoch 16/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - mae: 0.0999 - val_loss: 0.0322 - val_mae: 0.1194 - learning_rate: 0.0010\n",
      "Epoch 17/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - mae: 0.0996 - val_loss: 0.0228 - val_mae: 0.0929 - learning_rate: 0.0010\n",
      "Epoch 18/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0208 - mae: 0.0861 - val_loss: 0.0193 - val_mae: 0.0807 - learning_rate: 0.0010\n",
      "Epoch 19/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0199 - mae: 0.0839 - val_loss: 0.0284 - val_mae: 0.1090 - learning_rate: 0.0010\n",
      "Epoch 20/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0222 - mae: 0.0910 - val_loss: 0.0157 - val_mae: 0.0678 - learning_rate: 0.0010\n",
      "Epoch 21/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0174 - mae: 0.0751 - val_loss: 0.0298 - val_mae: 0.1143 - learning_rate: 0.0010\n",
      "Epoch 22/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - mae: 0.0756 - val_loss: 0.0140 - val_mae: 0.0609 - learning_rate: 0.0010\n",
      "Epoch 23/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0154 - mae: 0.0682 - val_loss: 0.0136 - val_mae: 0.0597 - learning_rate: 0.0010\n",
      "Epoch 24/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0138 - mae: 0.0619 - val_loss: 0.0143 - val_mae: 0.0645 - learning_rate: 0.0010\n",
      "Epoch 25/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0594 - val_loss: 0.0123 - val_mae: 0.0542 - learning_rate: 0.0010\n",
      "Epoch 26/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0572 - val_loss: 0.0128 - val_mae: 0.0573 - learning_rate: 0.0010\n",
      "Epoch 27/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0131 - mae: 0.0587 - val_loss: 0.0121 - val_mae: 0.0529 - learning_rate: 0.0010\n",
      "Epoch 28/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0130 - mae: 0.0580 - val_loss: 0.0117 - val_mae: 0.0511 - learning_rate: 0.0010\n",
      "Epoch 29/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0534 - val_loss: 0.0117 - val_mae: 0.0514 - learning_rate: 0.0010\n",
      "Epoch 30/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0541 - val_loss: 0.0129 - val_mae: 0.0586 - learning_rate: 0.0010\n",
      "Epoch 31/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0143 - mae: 0.0645 - val_loss: 0.0145 - val_mae: 0.0664 - learning_rate: 0.0010\n",
      "Epoch 32/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0545 - val_loss: 0.0127 - val_mae: 0.0570 - learning_rate: 0.0010\n",
      "Epoch 33/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0132 - mae: 0.0599 - val_loss: 0.0112 - val_mae: 0.0484 - learning_rate: 0.0010\n",
      "Epoch 34/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0531 - val_loss: 0.0127 - val_mae: 0.0576 - learning_rate: 0.0010\n",
      "Epoch 35/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0563 - val_loss: 0.0228 - val_mae: 0.0974 - learning_rate: 0.0010\n",
      "Epoch 36/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0141 - mae: 0.0630 - val_loss: 0.0107 - val_mae: 0.0456 - learning_rate: 0.0010\n",
      "Epoch 37/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0140 - mae: 0.0634 - val_loss: 0.0177 - val_mae: 0.0803 - learning_rate: 0.0010\n",
      "Epoch 38/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - mae: 0.0737 - val_loss: 0.0109 - val_mae: 0.0480 - learning_rate: 0.0010\n",
      "Epoch 39/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0115 - mae: 0.0513 - val_loss: 0.0109 - val_mae: 0.0477 - learning_rate: 0.0010\n",
      "Epoch 40/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0514 - val_loss: 0.0112 - val_mae: 0.0498 - learning_rate: 0.0010\n",
      "Epoch 41/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0538 - val_loss: 0.0134 - val_mae: 0.0617 - learning_rate: 0.0010\n",
      "Epoch 42/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0141 - mae: 0.0637 - val_loss: 0.0133 - val_mae: 0.0610 - learning_rate: 0.0010\n",
      "Epoch 43/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0542 - val_loss: 0.0125 - val_mae: 0.0573 - learning_rate: 0.0010\n",
      "Epoch 44/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0550 - val_loss: 0.0190 - val_mae: 0.0862 - learning_rate: 0.0010\n",
      "Epoch 45/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0589 - val_loss: 0.0124 - val_mae: 0.0577 - learning_rate: 0.0010\n",
      "Epoch 46/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0608 - val_loss: 0.0127 - val_mae: 0.0592 - learning_rate: 0.0010\n",
      "Epoch 47/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0583 - val_loss: 0.0192 - val_mae: 0.0823 - learning_rate: 0.0010\n",
      "Epoch 48/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0142 - mae: 0.0639 - val_loss: 0.0129 - val_mae: 0.0605 - learning_rate: 0.0010\n",
      "Epoch 49/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0582 - val_loss: 0.0119 - val_mae: 0.0547 - learning_rate: 0.0010\n",
      "Epoch 50/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0546 - val_loss: 0.0130 - val_mae: 0.0594 - learning_rate: 0.0010\n",
      "Epoch 51/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0564 - val_loss: 0.0209 - val_mae: 0.0895 - learning_rate: 0.0010\n",
      "Epoch 52/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0175 - mae: 0.0766 - val_loss: 0.0163 - val_mae: 0.0754 - learning_rate: 0.0010\n",
      "Epoch 53/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0153 - mae: 0.0702 - val_loss: 0.0126 - val_mae: 0.0583 - learning_rate: 0.0010\n",
      "Epoch 54/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0598 - val_loss: 0.0316 - val_mae: 0.1219 - learning_rate: 0.0010\n",
      "Epoch 55/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0226 - mae: 0.0910 - val_loss: 0.0119 - val_mae: 0.0563 - learning_rate: 0.0010\n",
      "Epoch 56/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0140 - mae: 0.0648 - val_loss: 0.0113 - val_mae: 0.0530 - learning_rate: 0.0010\n",
      "Epoch 57/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0448 - val_loss: 0.0105 - val_mae: 0.0458 - learning_rate: 5.0000e-04\n",
      "Epoch 58/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0443 - val_loss: 0.0100 - val_mae: 0.0442 - learning_rate: 5.0000e-04\n",
      "Epoch 59/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0439 - val_loss: 0.0098 - val_mae: 0.0425 - learning_rate: 5.0000e-04\n",
      "Epoch 60/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0099 - mae: 0.0438 - val_loss: 0.0099 - val_mae: 0.0436 - learning_rate: 5.0000e-04\n",
      "Epoch 61/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0440 - val_loss: 0.0100 - val_mae: 0.0434 - learning_rate: 5.0000e-04\n",
      "Epoch 62/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0099 - mae: 0.0430 - val_loss: 0.0100 - val_mae: 0.0440 - learning_rate: 5.0000e-04\n",
      "Epoch 63/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0451 - val_loss: 0.0098 - val_mae: 0.0428 - learning_rate: 5.0000e-04\n",
      "Epoch 64/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0443 - val_loss: 0.0099 - val_mae: 0.0438 - learning_rate: 5.0000e-04\n",
      "Epoch 65/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0467 - val_loss: 0.0096 - val_mae: 0.0413 - learning_rate: 5.0000e-04\n",
      "Epoch 66/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0445 - val_loss: 0.0096 - val_mae: 0.0419 - learning_rate: 5.0000e-04\n",
      "Epoch 67/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0451 - val_loss: 0.0098 - val_mae: 0.0436 - learning_rate: 5.0000e-04\n",
      "Epoch 68/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0446 - val_loss: 0.0097 - val_mae: 0.0423 - learning_rate: 5.0000e-04\n",
      "Epoch 69/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0453 - val_loss: 0.0104 - val_mae: 0.0474 - learning_rate: 5.0000e-04\n",
      "Epoch 70/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0104 - mae: 0.0476 - val_loss: 0.0100 - val_mae: 0.0447 - learning_rate: 5.0000e-04\n",
      "Epoch 71/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0503 - val_loss: 0.0118 - val_mae: 0.0568 - learning_rate: 5.0000e-04\n",
      "Epoch 72/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0525 - val_loss: 0.0124 - val_mae: 0.0594 - learning_rate: 5.0000e-04\n",
      "Epoch 73/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0109 - mae: 0.0510 - val_loss: 0.0106 - val_mae: 0.0479 - learning_rate: 5.0000e-04\n",
      "Epoch 74/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0106 - mae: 0.0488 - val_loss: 0.0104 - val_mae: 0.0472 - learning_rate: 5.0000e-04\n",
      "Epoch 75/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0105 - mae: 0.0488 - val_loss: 0.0106 - val_mae: 0.0482 - learning_rate: 5.0000e-04\n",
      "Epoch 76/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0109 - mae: 0.0509 - val_loss: 0.0125 - val_mae: 0.0599 - learning_rate: 5.0000e-04\n",
      "Epoch 77/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0550 - val_loss: 0.0130 - val_mae: 0.0629 - learning_rate: 5.0000e-04\n",
      "Epoch 78/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0586 - val_loss: 0.0138 - val_mae: 0.0671 - learning_rate: 5.0000e-04\n",
      "Epoch 79/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0576 - val_loss: 0.0111 - val_mae: 0.0521 - learning_rate: 5.0000e-04\n",
      "Epoch 80/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0523 - val_loss: 0.0113 - val_mae: 0.0538 - learning_rate: 5.0000e-04\n",
      "Epoch 81/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0551 - val_loss: 0.0100 - val_mae: 0.0453 - learning_rate: 5.0000e-04\n",
      "Epoch 82/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0106 - mae: 0.0494 - val_loss: 0.0162 - val_mae: 0.0779 - learning_rate: 5.0000e-04\n",
      "Epoch 83/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0143 - mae: 0.0673 - val_loss: 0.0125 - val_mae: 0.0611 - learning_rate: 5.0000e-04\n",
      "Epoch 84/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0550 - val_loss: 0.0128 - val_mae: 0.0619 - learning_rate: 5.0000e-04\n",
      "Epoch 85/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0605 - val_loss: 0.0222 - val_mae: 0.0984 - learning_rate: 5.0000e-04\n",
      "Epoch 86/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0580 - val_loss: 0.0094 - val_mae: 0.0417 - learning_rate: 2.5000e-04\n",
      "Epoch 87/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0094 - mae: 0.0413 - val_loss: 0.0094 - val_mae: 0.0414 - learning_rate: 2.5000e-04\n",
      "Epoch 88/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - mae: 0.0426 - val_loss: 0.0096 - val_mae: 0.0431 - learning_rate: 2.5000e-04\n",
      "Epoch 89/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0097 - mae: 0.0435 - val_loss: 0.0107 - val_mae: 0.0496 - learning_rate: 2.5000e-04\n",
      "Epoch 90/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0452 - val_loss: 0.0095 - val_mae: 0.0422 - learning_rate: 2.5000e-04\n",
      "Epoch 91/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - mae: 0.0428 - val_loss: 0.0094 - val_mae: 0.0421 - learning_rate: 2.5000e-04\n",
      "Epoch 92/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - mae: 0.0442 - val_loss: 0.0097 - val_mae: 0.0437 - learning_rate: 2.5000e-04\n",
      "Epoch 93/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0096 - mae: 0.0430 - val_loss: 0.0094 - val_mae: 0.0418 - learning_rate: 2.5000e-04\n",
      "Epoch 94/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0427 - val_loss: 0.0099 - val_mae: 0.0463 - learning_rate: 2.5000e-04\n",
      "Epoch 95/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0441 - val_loss: 0.0098 - val_mae: 0.0449 - learning_rate: 2.5000e-04\n",
      "Epoch 96/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0438 - val_loss: 0.0104 - val_mae: 0.0494 - learning_rate: 2.5000e-04\n",
      "Epoch 97/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0458 - val_loss: 0.0099 - val_mae: 0.0459 - learning_rate: 2.5000e-04\n",
      "Epoch 98/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0451 - val_loss: 0.0095 - val_mae: 0.0423 - learning_rate: 2.5000e-04\n",
      "Epoch 99/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0438 - val_loss: 0.0098 - val_mae: 0.0452 - learning_rate: 2.5000e-04\n",
      "Epoch 100/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0468 - val_loss: 0.0099 - val_mae: 0.0463 - learning_rate: 2.5000e-04\n",
      "Epoch 101/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0098 - mae: 0.0451 - val_loss: 0.0102 - val_mae: 0.0487 - learning_rate: 2.5000e-04\n",
      "Epoch 102/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - mae: 0.0451 - val_loss: 0.0097 - val_mae: 0.0450 - learning_rate: 2.5000e-04\n",
      "Epoch 103/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0099 - mae: 0.0460 - val_loss: 0.0104 - val_mae: 0.0504 - learning_rate: 2.5000e-04\n",
      "Epoch 104/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0482 - val_loss: 0.0114 - val_mae: 0.0553 - learning_rate: 2.5000e-04\n",
      "Epoch 105/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0109 - mae: 0.0523 - val_loss: 0.0098 - val_mae: 0.0454 - learning_rate: 2.5000e-04\n",
      "Epoch 106/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0480 - val_loss: 0.0108 - val_mae: 0.0514 - learning_rate: 2.5000e-04\n",
      "Epoch 107/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0096 - mae: 0.0441 - val_loss: 0.0089 - val_mae: 0.0390 - learning_rate: 1.2500e-04\n",
      "Epoch 108/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0424 - val_loss: 0.0089 - val_mae: 0.0390 - learning_rate: 1.2500e-04\n",
      "Epoch 109/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0093 - mae: 0.0423 - val_loss: 0.0091 - val_mae: 0.0407 - learning_rate: 1.2500e-04\n",
      "Epoch 110/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0414 - val_loss: 0.0095 - val_mae: 0.0435 - learning_rate: 1.2500e-04\n",
      "Epoch 111/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0434 - val_loss: 0.0090 - val_mae: 0.0394 - learning_rate: 1.2500e-04\n",
      "Epoch 112/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0407 - val_loss: 0.0092 - val_mae: 0.0418 - learning_rate: 1.2500e-04\n",
      "Epoch 113/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0428 - val_loss: 0.0090 - val_mae: 0.0400 - learning_rate: 1.2500e-04\n",
      "Epoch 114/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0091 - mae: 0.0409 - val_loss: 0.0093 - val_mae: 0.0423 - learning_rate: 1.2500e-04\n",
      "Epoch 115/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0431 - val_loss: 0.0090 - val_mae: 0.0403 - learning_rate: 1.2500e-04\n",
      "Epoch 116/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0416 - val_loss: 0.0093 - val_mae: 0.0423 - learning_rate: 1.2500e-04\n",
      "Epoch 117/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0427 - val_loss: 0.0103 - val_mae: 0.0492 - learning_rate: 1.2500e-04\n",
      "Epoch 118/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0095 - mae: 0.0437 - val_loss: 0.0093 - val_mae: 0.0428 - learning_rate: 1.2500e-04\n",
      "Epoch 119/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0437 - val_loss: 0.0098 - val_mae: 0.0455 - learning_rate: 1.2500e-04\n",
      "Epoch 120/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0447 - val_loss: 0.0100 - val_mae: 0.0464 - learning_rate: 1.2500e-04\n",
      "Epoch 121/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0096 - mae: 0.0452 - val_loss: 0.0091 - val_mae: 0.0413 - learning_rate: 1.2500e-04\n",
      "Epoch 122/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0094 - mae: 0.0428 - val_loss: 0.0100 - val_mae: 0.0469 - learning_rate: 1.2500e-04\n",
      "Epoch 123/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0438 - val_loss: 0.0092 - val_mae: 0.0415 - learning_rate: 1.2500e-04\n",
      "Epoch 124/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0093 - mae: 0.0430 - val_loss: 0.0093 - val_mae: 0.0431 - learning_rate: 1.2500e-04\n",
      "Epoch 125/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - mae: 0.0441 - val_loss: 0.0100 - val_mae: 0.0474 - learning_rate: 1.2500e-04\n",
      "Epoch 126/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0096 - mae: 0.0449 - val_loss: 0.0092 - val_mae: 0.0426 - learning_rate: 1.2500e-04\n",
      "Epoch 127/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0093 - mae: 0.0429 - val_loss: 0.0098 - val_mae: 0.0455 - learning_rate: 1.2500e-04\n",
      "Epoch 128/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0414 - val_loss: 0.0088 - val_mae: 0.0389 - learning_rate: 6.2500e-05\n",
      "Epoch 129/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0403 - val_loss: 0.0088 - val_mae: 0.0387 - learning_rate: 6.2500e-05\n",
      "Epoch 130/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0412 - val_loss: 0.0089 - val_mae: 0.0398 - learning_rate: 6.2500e-05\n",
      "Epoch 131/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0407 - val_loss: 0.0089 - val_mae: 0.0395 - learning_rate: 6.2500e-05\n",
      "Epoch 132/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0400 - val_loss: 0.0088 - val_mae: 0.0390 - learning_rate: 6.2500e-05\n",
      "Epoch 133/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0415 - val_loss: 0.0093 - val_mae: 0.0416 - learning_rate: 6.2500e-05\n",
      "Epoch 134/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0407 - val_loss: 0.0088 - val_mae: 0.0392 - learning_rate: 6.2500e-05\n",
      "Epoch 135/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0406 - val_loss: 0.0088 - val_mae: 0.0388 - learning_rate: 6.2500e-05\n",
      "Epoch 136/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0406 - val_loss: 0.0092 - val_mae: 0.0410 - learning_rate: 6.2500e-05\n",
      "Epoch 137/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0409 - val_loss: 0.0088 - val_mae: 0.0390 - learning_rate: 6.2500e-05\n",
      "Epoch 138/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0410 - val_loss: 0.0102 - val_mae: 0.0485 - learning_rate: 6.2500e-05\n",
      "Epoch 139/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0429 - val_loss: 0.0092 - val_mae: 0.0423 - learning_rate: 6.2500e-05\n",
      "Epoch 140/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0415 - val_loss: 0.0089 - val_mae: 0.0401 - learning_rate: 6.2500e-05\n",
      "Epoch 141/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0409 - val_loss: 0.0089 - val_mae: 0.0397 - learning_rate: 6.2500e-05\n",
      "Epoch 142/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0405 - val_loss: 0.0087 - val_mae: 0.0389 - learning_rate: 6.2500e-05\n",
      "Epoch 143/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0090 - mae: 0.0406 - val_loss: 0.0090 - val_mae: 0.0410 - learning_rate: 6.2500e-05\n",
      "Epoch 144/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0091 - mae: 0.0419 - val_loss: 0.0090 - val_mae: 0.0410 - learning_rate: 6.2500e-05\n",
      "Epoch 145/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0091 - mae: 0.0420 - val_loss: 0.0091 - val_mae: 0.0412 - learning_rate: 6.2500e-05\n",
      "Epoch 146/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0416 - val_loss: 0.0094 - val_mae: 0.0437 - learning_rate: 6.2500e-05\n",
      "Epoch 147/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0092 - mae: 0.0424 - val_loss: 0.0090 - val_mae: 0.0406 - learning_rate: 6.2500e-05\n",
      "Epoch 148/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0424 - val_loss: 0.0091 - val_mae: 0.0415 - learning_rate: 6.2500e-05\n",
      "Epoch 149/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0402 - val_loss: 0.0088 - val_mae: 0.0394 - learning_rate: 3.1250e-05\n",
      "Epoch 150/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0406 - val_loss: 0.0087 - val_mae: 0.0382 - learning_rate: 3.1250e-05\n",
      "Epoch 151/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0400 - val_loss: 0.0087 - val_mae: 0.0387 - learning_rate: 3.1250e-05\n",
      "Epoch 152/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0090 - mae: 0.0406 - val_loss: 0.0088 - val_mae: 0.0395 - learning_rate: 3.1250e-05\n",
      "Epoch 153/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0397 - val_loss: 0.0087 - val_mae: 0.0384 - learning_rate: 3.1250e-05\n",
      "Epoch 154/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0400 - val_loss: 0.0086 - val_mae: 0.0380 - learning_rate: 3.1250e-05\n",
      "Epoch 155/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - mae: 0.0393 - val_loss: 0.0088 - val_mae: 0.0394 - learning_rate: 3.1250e-05\n",
      "Epoch 156/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - mae: 0.0394 - val_loss: 0.0087 - val_mae: 0.0390 - learning_rate: 3.1250e-05\n",
      "Epoch 157/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - mae: 0.0399 - val_loss: 0.0090 - val_mae: 0.0417 - learning_rate: 3.1250e-05\n",
      "Epoch 158/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0402 - val_loss: 0.0086 - val_mae: 0.0380 - learning_rate: 3.1250e-05\n",
      "Epoch 159/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0406 - val_loss: 0.0088 - val_mae: 0.0393 - learning_rate: 3.1250e-05\n",
      "Epoch 160/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0089 - mae: 0.0404 - val_loss: 0.0087 - val_mae: 0.0383 - learning_rate: 3.1250e-05\n",
      "Epoch 161/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0408 - val_loss: 0.0089 - val_mae: 0.0400 - learning_rate: 3.1250e-05\n",
      "Epoch 162/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - mae: 0.0401 - val_loss: 0.0087 - val_mae: 0.0390 - learning_rate: 3.1250e-05\n",
      "Epoch 163/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - mae: 0.0395 - val_loss: 0.0088 - val_mae: 0.0400 - learning_rate: 3.1250e-05\n",
      "Epoch 164/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0410 - val_loss: 0.0088 - val_mae: 0.0397 - learning_rate: 3.1250e-05\n",
      "Epoch 165/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0407 - val_loss: 0.0087 - val_mae: 0.0390 - learning_rate: 3.1250e-05\n",
      "Epoch 166/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0088 - mae: 0.0399 - val_loss: 0.0087 - val_mae: 0.0390 - learning_rate: 3.1250e-05\n",
      "Epoch 167/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0089 - mae: 0.0402 - val_loss: 0.0086 - val_mae: 0.0381 - learning_rate: 3.1250e-05\n",
      "Epoch 168/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0089 - mae: 0.0407 - val_loss: 0.0090 - val_mae: 0.0419 - learning_rate: 3.1250e-05\n",
      "Epoch 169/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0089 - mae: 0.0403 - val_loss: 0.0086 - val_mae: 0.0383 - learning_rate: 3.1250e-05\n",
      "Epoch 170/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - mae: 0.0406 - val_loss: 0.0088 - val_mae: 0.0399 - learning_rate: 3.1250e-05\n",
      "Epoch 171/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 - mae: 0.0390 - val_loss: 0.0086 - val_mae: 0.0381 - learning_rate: 1.5625e-05\n",
      "Epoch 172/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - mae: 0.0393 - val_loss: 0.0086 - val_mae: 0.0380 - learning_rate: 1.5625e-05\n",
      "Epoch 173/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - mae: 0.0400 - val_loss: 0.0086 - val_mae: 0.0379 - learning_rate: 1.5625e-05\n",
      "Epoch 174/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0087 - mae: 0.0393 - val_loss: 0.0085 - val_mae: 0.0375 - learning_rate: 1.5625e-05\n",
      "Epoch 175/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0387 - val_loss: 0.0086 - val_mae: 0.0385 - learning_rate: 1.5625e-05\n",
      "Epoch 176/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0395 - val_loss: 0.0085 - val_mae: 0.0377 - learning_rate: 1.5625e-05\n",
      "Epoch 177/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0397 - val_loss: 0.0085 - val_mae: 0.0375 - learning_rate: 1.5625e-05\n",
      "Epoch 178/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0392 - val_loss: 0.0087 - val_mae: 0.0394 - learning_rate: 1.5625e-05\n",
      "Epoch 179/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0088 - mae: 0.0398 - val_loss: 0.0085 - val_mae: 0.0379 - learning_rate: 1.5625e-05\n",
      "Epoch 180/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - mae: 0.0395 - val_loss: 0.0085 - val_mae: 0.0377 - learning_rate: 1.5625e-05\n",
      "Epoch 181/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - mae: 0.0390 - val_loss: 0.0085 - val_mae: 0.0378 - learning_rate: 1.5625e-05\n",
      "Epoch 182/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - mae: 0.0387 - val_loss: 0.0086 - val_mae: 0.0386 - learning_rate: 1.5625e-05\n",
      "Epoch 183/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 - mae: 0.0390 - val_loss: 0.0085 - val_mae: 0.0380 - learning_rate: 1.5625e-05\n",
      "Epoch 184/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0088 - mae: 0.0401 - val_loss: 0.0086 - val_mae: 0.0387 - learning_rate: 1.5625e-05\n",
      "Epoch 185/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 - mae: 0.0394 - val_loss: 0.0085 - val_mae: 0.0379 - learning_rate: 1.5625e-05\n",
      "Epoch 186/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 - mae: 0.0396 - val_loss: 0.0086 - val_mae: 0.0380 - learning_rate: 1.5625e-05\n",
      "Epoch 187/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 - mae: 0.0388 - val_loss: 0.0087 - val_mae: 0.0399 - learning_rate: 1.5625e-05\n",
      "Epoch 188/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 - mae: 0.0396 - val_loss: 0.0085 - val_mae: 0.0379 - learning_rate: 1.5625e-05\n",
      "Epoch 189/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0087 - mae: 0.0394 - val_loss: 0.0085 - val_mae: 0.0381 - learning_rate: 1.5625e-05\n",
      "Epoch 190/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0087 - mae: 0.0393 - val_loss: 0.0085 - val_mae: 0.0376 - learning_rate: 1.5625e-05\n",
      "Epoch 191/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0087 - mae: 0.0398 - val_loss: 0.0085 - val_mae: 0.0381 - learning_rate: 1.5625e-05\n",
      "Epoch 192/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - mae: 0.0399 - val_loss: 0.0086 - val_mae: 0.0391 - learning_rate: 1.5625e-05\n",
      "Epoch 193/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0401 - val_loss: 0.0085 - val_mae: 0.0377 - learning_rate: 1.5625e-05\n",
      "Epoch 194/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - mae: 0.0386 - val_loss: 0.0085 - val_mae: 0.0376 - learning_rate: 7.8125e-06\n",
      "Epoch 195/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - mae: 0.0386 - val_loss: 0.0086 - val_mae: 0.0380 - learning_rate: 7.8125e-06\n",
      "Epoch 196/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0087 - mae: 0.0389 - val_loss: 0.0085 - val_mae: 0.0374 - learning_rate: 7.8125e-06\n",
      "Epoch 197/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0086 - mae: 0.0385 - val_loss: 0.0086 - val_mae: 0.0384 - learning_rate: 7.8125e-06\n",
      "Epoch 198/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0392 - val_loss: 0.0085 - val_mae: 0.0377 - learning_rate: 7.8125e-06\n",
      "Epoch 199/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0086 - mae: 0.0386 - val_loss: 0.0085 - val_mae: 0.0378 - learning_rate: 7.8125e-06\n",
      "Epoch 200/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - mae: 0.0391 - val_loss: 0.0085 - val_mae: 0.0374 - learning_rate: 7.8125e-06\n",
      "Epoch 201/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0390 - val_loss: 0.0084 - val_mae: 0.0372 - learning_rate: 7.8125e-06\n",
      "Epoch 202/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0086 - mae: 0.0387 - val_loss: 0.0085 - val_mae: 0.0375 - learning_rate: 7.8125e-06\n",
      "Epoch 203/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0087 - mae: 0.0392 - val_loss: 0.0084 - val_mae: 0.0372 - learning_rate: 7.8125e-06\n",
      "Epoch 204/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - mae: 0.0389 - val_loss: 0.0084 - val_mae: 0.0374 - learning_rate: 7.8125e-06\n",
      "Epoch 205/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0086 - mae: 0.0385 - val_loss: 0.0084 - val_mae: 0.0373 - learning_rate: 7.8125e-06\n",
      "Epoch 206/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - mae: 0.0386 - val_loss: 0.0085 - val_mae: 0.0380 - learning_rate: 7.8125e-06\n",
      "Epoch 207/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - mae: 0.0390 - val_loss: 0.0084 - val_mae: 0.0375 - learning_rate: 7.8125e-06\n",
      "Epoch 208/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - mae: 0.0387 - val_loss: 0.0084 - val_mae: 0.0375 - learning_rate: 7.8125e-06\n",
      "Epoch 209/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0086 - mae: 0.0386 - val_loss: 0.0084 - val_mae: 0.0375 - learning_rate: 7.8125e-06\n",
      "Epoch 210/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0086 - mae: 0.0393 - val_loss: 0.0084 - val_mae: 0.0372 - learning_rate: 7.8125e-06\n",
      "Epoch 211/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0085 - mae: 0.0384 - val_loss: 0.0085 - val_mae: 0.0383 - learning_rate: 7.8125e-06\n",
      "Epoch 212/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - mae: 0.0395 - val_loss: 0.0085 - val_mae: 0.0376 - learning_rate: 7.8125e-06\n",
      "Epoch 213/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - mae: 0.0393 - val_loss: 0.0084 - val_mae: 0.0374 - learning_rate: 7.8125e-06\n",
      "Epoch 214/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - mae: 0.0383 - val_loss: 0.0084 - val_mae: 0.0374 - learning_rate: 7.8125e-06\n",
      "Epoch 215/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - mae: 0.0383 - val_loss: 0.0084 - val_mae: 0.0375 - learning_rate: 7.8125e-06\n",
      "Epoch 216/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0086 - mae: 0.0387 - val_loss: 0.0084 - val_mae: 0.0372 - learning_rate: 7.8125e-06\n",
      "Epoch 217/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0385 - val_loss: 0.0084 - val_mae: 0.0374 - learning_rate: 3.9063e-06\n",
      "Epoch 218/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0382 - val_loss: 0.0084 - val_mae: 0.0374 - learning_rate: 3.9063e-06\n",
      "Epoch 219/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - mae: 0.0387 - val_loss: 0.0084 - val_mae: 0.0372 - learning_rate: 3.9063e-06\n",
      "Epoch 220/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0086 - mae: 0.0392 - val_loss: 0.0084 - val_mae: 0.0373 - learning_rate: 3.9063e-06\n",
      "Epoch 221/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0388 - val_loss: 0.0084 - val_mae: 0.0373 - learning_rate: 3.9063e-06\n",
      "Epoch 222/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0387 - val_loss: 0.0084 - val_mae: 0.0373 - learning_rate: 3.9063e-06\n",
      "Epoch 223/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0382 - val_loss: 0.0084 - val_mae: 0.0373 - learning_rate: 3.9063e-06\n",
      "Epoch 224/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0382 - val_loss: 0.0084 - val_mae: 0.0376 - learning_rate: 3.9063e-06\n",
      "Epoch 225/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0085 - mae: 0.0384 - val_loss: 0.0084 - val_mae: 0.0372 - learning_rate: 3.9063e-06\n",
      "Epoch 226/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0085 - mae: 0.0387 - val_loss: 0.0084 - val_mae: 0.0374 - learning_rate: 3.9063e-06\n",
      "Epoch 227/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0086 - mae: 0.0393 - val_loss: 0.0084 - val_mae: 0.0375 - learning_rate: 3.9063e-06\n",
      "Epoch 228/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - mae: 0.0386 - val_loss: 0.0083 - val_mae: 0.0372 - learning_rate: 3.9063e-06\n",
      "Epoch 229/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0085 - mae: 0.0387 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 3.9063e-06\n",
      "Epoch 230/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0086 - mae: 0.0389 - val_loss: 0.0084 - val_mae: 0.0373 - learning_rate: 3.9063e-06\n",
      "Epoch 231/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0085 - mae: 0.0385 - val_loss: 0.0084 - val_mae: 0.0373 - learning_rate: 3.9063e-06\n",
      "Epoch 232/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0383 - val_loss: 0.0084 - val_mae: 0.0374 - learning_rate: 3.9063e-06\n",
      "Epoch 233/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0086 - mae: 0.0389 - val_loss: 0.0084 - val_mae: 0.0372 - learning_rate: 3.9063e-06\n",
      "Epoch 234/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0383 - val_loss: 0.0084 - val_mae: 0.0375 - learning_rate: 3.9063e-06\n",
      "Epoch 235/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0379 - val_loss: 0.0083 - val_mae: 0.0372 - learning_rate: 3.9063e-06\n",
      "Epoch 236/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0379 - val_loss: 0.0084 - val_mae: 0.0377 - learning_rate: 3.9063e-06\n",
      "Epoch 237/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0383 - val_loss: 0.0084 - val_mae: 0.0374 - learning_rate: 3.9063e-06\n",
      "Epoch 238/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0086 - mae: 0.0388 - val_loss: 0.0083 - val_mae: 0.0372 - learning_rate: 3.9063e-06\n",
      "Epoch 239/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0389 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 3.9063e-06\n",
      "Epoch 240/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0386 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 3.9063e-06\n",
      "Epoch 241/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0083 - val_mae: 0.0373 - learning_rate: 3.9063e-06\n",
      "Epoch 242/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0383 - val_loss: 0.0083 - val_mae: 0.0372 - learning_rate: 3.9063e-06\n",
      "Epoch 243/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - mae: 0.0387 - val_loss: 0.0083 - val_mae: 0.0372 - learning_rate: 3.9063e-06\n",
      "Epoch 244/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0385 - val_loss: 0.0084 - val_mae: 0.0377 - learning_rate: 3.9063e-06\n",
      "Epoch 245/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - mae: 0.0387 - val_loss: 0.0084 - val_mae: 0.0377 - learning_rate: 3.9063e-06\n",
      "Epoch 246/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0388 - val_loss: 0.0083 - val_mae: 0.0373 - learning_rate: 3.9063e-06\n",
      "Epoch 247/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0385 - val_loss: 0.0083 - val_mae: 0.0373 - learning_rate: 3.9063e-06\n",
      "Epoch 248/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - mae: 0.0384 - val_loss: 0.0083 - val_mae: 0.0375 - learning_rate: 3.9063e-06\n",
      "Epoch 249/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 1.9531e-06\n",
      "Epoch 250/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0380 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 1.9531e-06\n",
      "Epoch 251/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0378 - val_loss: 0.0083 - val_mae: 0.0372 - learning_rate: 1.9531e-06\n",
      "Epoch 252/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0384 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 1.9531e-06\n",
      "Epoch 253/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0085 - mae: 0.0386 - val_loss: 0.0083 - val_mae: 0.0372 - learning_rate: 1.9531e-06\n",
      "Epoch 254/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - mae: 0.0385 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 1.9531e-06\n",
      "Epoch 255/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0083 - val_mae: 0.0376 - learning_rate: 1.9531e-06\n",
      "Epoch 256/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - mae: 0.0385 - val_loss: 0.0083 - val_mae: 0.0374 - learning_rate: 1.9531e-06\n",
      "Epoch 257/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - mae: 0.0385 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 1.9531e-06\n",
      "Epoch 258/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0380 - val_loss: 0.0083 - val_mae: 0.0372 - learning_rate: 1.9531e-06\n",
      "Epoch 259/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0379 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 1.9531e-06\n",
      "Epoch 260/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - mae: 0.0387 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 1.9531e-06\n",
      "Epoch 261/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0386 - val_loss: 0.0083 - val_mae: 0.0373 - learning_rate: 1.9531e-06\n",
      "Epoch 262/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 1.9531e-06\n",
      "Epoch 263/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0380 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 1.9531e-06\n",
      "Epoch 264/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0385 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 1.9531e-06\n",
      "Epoch 265/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0085 - mae: 0.0383 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 1.9531e-06\n",
      "Epoch 266/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0388 - val_loss: 0.0083 - val_mae: 0.0370 - learning_rate: 1.9531e-06\n",
      "Epoch 267/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0380 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 1.9531e-06\n",
      "Epoch 268/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0083 - val_mae: 0.0373 - learning_rate: 1.9531e-06\n",
      "Epoch 269/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0379 - val_loss: 0.0083 - val_mae: 0.0372 - learning_rate: 9.7656e-07\n",
      "Epoch 270/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0384 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 9.7656e-07\n",
      "Epoch 271/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0376 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 9.7656e-07\n",
      "Epoch 272/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0386 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 9.7656e-07\n",
      "Epoch 273/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0386 - val_loss: 0.0083 - val_mae: 0.0372 - learning_rate: 9.7656e-07\n",
      "Epoch 274/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0382 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 9.7656e-07\n",
      "Epoch 275/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0384 - val_loss: 0.0083 - val_mae: 0.0370 - learning_rate: 9.7656e-07\n",
      "Epoch 276/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - mae: 0.0387 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 9.7656e-07\n",
      "Epoch 277/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0386 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 9.7656e-07\n",
      "Epoch 278/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0083 - val_mae: 0.0370 - learning_rate: 9.7656e-07\n",
      "Epoch 279/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0083 - val_mae: 0.0372 - learning_rate: 9.7656e-07\n",
      "Epoch 280/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - mae: 0.0384 - val_loss: 0.0083 - val_mae: 0.0370 - learning_rate: 9.7656e-07\n",
      "Epoch 281/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - mae: 0.0380 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 9.7656e-07\n",
      "Epoch 282/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - mae: 0.0379 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 9.7656e-07\n",
      "Epoch 283/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0386 - val_loss: 0.0083 - val_mae: 0.0372 - learning_rate: 9.7656e-07\n",
      "Epoch 284/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0385 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 9.7656e-07\n",
      "Epoch 285/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0083 - val_mae: 0.0370 - learning_rate: 9.7656e-07\n",
      "Epoch 286/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0379 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 9.7656e-07\n",
      "Epoch 287/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 9.7656e-07\n",
      "Epoch 288/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0380 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 9.7656e-07\n",
      "Epoch 289/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0382 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 4.8828e-07\n",
      "Epoch 290/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0378 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 4.8828e-07\n",
      "Epoch 291/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 4.8828e-07\n",
      "Epoch 292/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 4.8828e-07\n",
      "Epoch 293/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0083 - mae: 0.0375 - val_loss: 0.0082 - val_mae: 0.0371 - learning_rate: 4.8828e-07\n",
      "Epoch 294/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 4.8828e-07\n",
      "Epoch 295/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0384 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 4.8828e-07\n",
      "Epoch 296/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0382 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 4.8828e-07\n",
      "Epoch 297/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - mae: 0.0387 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 4.8828e-07\n",
      "Epoch 298/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0384 - val_loss: 0.0082 - val_mae: 0.0371 - learning_rate: 4.8828e-07\n",
      "Epoch 299/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - mae: 0.0377 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 4.8828e-07\n",
      "Epoch 300/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0379 - val_loss: 0.0082 - val_mae: 0.0371 - learning_rate: 4.8828e-07\n",
      "Epoch 301/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0386 - val_loss: 0.0082 - val_mae: 0.0371 - learning_rate: 4.8828e-07\n",
      "Epoch 302/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0377 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 4.8828e-07\n",
      "Epoch 303/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0379 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 4.8828e-07\n",
      "Epoch 304/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0387 - val_loss: 0.0082 - val_mae: 0.0371 - learning_rate: 4.8828e-07\n",
      "Epoch 305/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 4.8828e-07\n",
      "Epoch 306/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0382 - val_loss: 0.0083 - val_mae: 0.0373 - learning_rate: 4.8828e-07\n",
      "Epoch 307/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0385 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 4.8828e-07\n",
      "Epoch 308/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0082 - val_mae: 0.0371 - learning_rate: 4.8828e-07\n",
      "Epoch 309/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0389 - val_loss: 0.0082 - val_mae: 0.0371 - learning_rate: 4.8828e-07\n",
      "Epoch 310/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0082 - val_mae: 0.0371 - learning_rate: 2.4414e-07\n",
      "Epoch 311/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 2.4414e-07\n",
      "Epoch 312/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 2.4414e-07\n",
      "Epoch 313/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0382 - val_loss: 0.0083 - val_mae: 0.0371 - learning_rate: 2.4414e-07\n",
      "Epoch 314/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0387 - val_loss: 0.0082 - val_mae: 0.0371 - learning_rate: 2.4414e-07\n",
      "Epoch 315/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0083 - mae: 0.0376 - val_loss: 0.0082 - val_mae: 0.0371 - learning_rate: 2.4414e-07\n",
      "Epoch 316/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0382 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 2.4414e-07\n",
      "Epoch 317/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - mae: 0.0379 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 2.4414e-07\n",
      "Epoch 318/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0386 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 2.4414e-07\n",
      "Epoch 319/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0385 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 2.4414e-07\n",
      "Epoch 320/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0386 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 2.4414e-07\n",
      "Epoch 321/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0380 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 2.4414e-07\n",
      "Epoch 322/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0382 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 2.4414e-07\n",
      "Epoch 323/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 2.4414e-07\n",
      "Epoch 324/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0386 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 2.4414e-07\n",
      "Epoch 325/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - mae: 0.0379 - val_loss: 0.0082 - val_mae: 0.0371 - learning_rate: 2.4414e-07\n",
      "Epoch 326/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 2.4414e-07\n",
      "Epoch 327/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - mae: 0.0378 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 2.4414e-07\n",
      "Epoch 328/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0385 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 2.4414e-07\n",
      "Epoch 329/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 2.4414e-07\n",
      "Epoch 330/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0385 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 331/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0386 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 332/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0386 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 333/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0386 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 334/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0382 - val_loss: 0.0082 - val_mae: 0.0371 - learning_rate: 1.2207e-07\n",
      "Epoch 335/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - mae: 0.0380 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 336/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0384 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 337/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0385 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 338/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0380 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 339/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0380 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 340/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 341/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0085 - mae: 0.0390 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 342/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0380 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 343/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0382 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 344/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0373 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 345/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 346/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0384 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 347/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 348/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - mae: 0.0382 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 349/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - mae: 0.0380 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.2207e-07\n",
      "Epoch 350/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0378 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 351/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - mae: 0.0380 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 352/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 353/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0390 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 354/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0379 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 355/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0379 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 356/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 357/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0382 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 358/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0387 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 359/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 360/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0382 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 361/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0384 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 362/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - mae: 0.0385 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 363/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0385 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 364/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0375 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 365/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0384 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 366/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0379 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 367/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0379 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 368/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 369/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - mae: 0.0379 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 6.1035e-08\n",
      "Epoch 370/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0380 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 371/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - mae: 0.0377 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 372/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - mae: 0.0382 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 373/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 374/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 375/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 376/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 377/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 378/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0380 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 379/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0382 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 380/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - mae: 0.0387 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 381/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0384 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 382/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - mae: 0.0380 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 383/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0383 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 384/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - mae: 0.0386 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 385/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - mae: 0.0380 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 386/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0384 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 387/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0380 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 388/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 389/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0378 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 3.0518e-08\n",
      "Epoch 390/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - mae: 0.0383 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.5259e-08\n",
      "Epoch 391/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.5259e-08\n",
      "Epoch 392/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.5259e-08\n",
      "Epoch 393/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.5259e-08\n",
      "Epoch 394/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0385 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.5259e-08\n",
      "Epoch 395/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0384 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.5259e-08\n",
      "Epoch 396/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.5259e-08\n",
      "Epoch 397/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.5259e-08\n",
      "Epoch 398/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0385 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.5259e-08\n",
      "Epoch 399/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0379 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.5259e-08\n",
      "Epoch 400/400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0380 - val_loss: 0.0082 - val_mae: 0.0370 - learning_rate: 1.5259e-08\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0382\n"
     ]
    }
   ],
   "source": [
    "act_name = \"relu\"\n",
    "l2_reg = 0.0001\n",
    "epoch = 400\n",
    "b_s= 38\n",
    "optimizer_name = \"adamW\"\n",
    "\n",
    "inputs = Input(shape=(5,))\n",
    "# encoded = Dense(5, activation= act_name, kernel_regularizer= l2(l2_reg))(inputs)\n",
    "# encoded = Dense(16, activation= act_name, kernel_regularizer= l2(l2_reg))(encoded) #, \n",
    "encoded = Dense(32, activation= act_name, kernel_regularizer= l2(l2_reg))(inputs)\n",
    "encoded = Dense(64, activation= act_name, kernel_regularizer= l2(l2_reg))(encoded) # , kernel_regularizer= l2(l2_reg)\n",
    "# encoded = Dense(80, activation= act_name, kernel_regularizer= l2(l2_reg))(encoded)\n",
    "# encoded = Dense(90, activation= act_name, kernel_regularizer= l2(l2_reg))(encoded) #, kernel_regularizer= l2(l2_reg)\n",
    "decoded = Dense(100, activation= 'linear', kernel_regularizer= l2(l2_reg), name ='z_output')(encoded)\n",
    "\n",
    "autoencoder_z = Model(inputs, decoded)\n",
    "autoencoder_z.compile(optimizer = optimizer_name, loss= 'mse',metrics = ['mae'])\n",
    "autoencoder_z.summary()\n",
    "\n",
    "history = autoencoder_z.fit(x_train,y_train_z,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tepochs = epoch,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tbatch_size = b_s,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tvalidation_split = 0.1,\n",
    "                            callbacks = [early_stopping, reduce_lr]\n",
    "                            )\n",
    "\n",
    "loss = autoencoder_z.evaluate(x_test,y_test_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - mae: 0.0382\n",
      "Pérdida en datos de Test: [0.008351358585059643, 0.03841249644756317]\n",
      "mae:244726.01486742496[m]\n"
     ]
    }
   ],
   "source": [
    "loss = autoencoder_z.evaluate(x_test,y_test_z)\n",
    "print(f'Pérdida en datos de Test: {loss}')\n",
    "\n",
    "mae_in_m = loss[1]*R0\n",
    "print(f'mae:{mae_in_m}[m]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n"
     ]
    }
   ],
   "source": [
    "idx = 11\n",
    "\n",
    " # Elegir una muestra para comparar (observar luego la muestra 30)\n",
    "\n",
    "# Predicción de una muestra \n",
    "y_pred_scaled = autoencoder_z.predict(np.expand_dims(x_test.iloc[idx], axis=0))\n",
    "###############################################\n",
    "y_true = y_test_z.iloc[idx] # Se obtine Algo de tipo Serie\n",
    "y_true=y_true.to_numpy() # Transform a Numpy array\n",
    "\n",
    "#Desnormalizamos\n",
    "y_pred = scaler_z.inverse_transform(y_pred_scaled)\n",
    "\n",
    "y_pred = y_pred.flatten() # [[...,...,...,....,]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Graficamos \n",
    "# Buscamos los máximos y mínimos \n",
    "y_true_max = np.max(y_true)\n",
    "y_true_min = np.min(y_true)\n",
    "\n",
    "y_pred_max = np.max(y_pred)\n",
    "y_pred_min = np.min(y_pred)\n",
    "\n",
    "# Pos z\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(y_true, label='Posiciones Z reales', linestyle='None', marker='.')\n",
    "plt.plot(y_pred, label='Posiciones Z predichas', linestyle = 'None',marker='o')\n",
    "# Dibujamos los max y min\n",
    "plt.axhline(y = y_true_max, color = 'red', linestyle = '-.', label=f'Máx_true: {y_true_max:.3f}')\n",
    "plt.axhline(y = y_pred_max, color = 'red', linestyle = ':', label= f'Máx_pred: {y_pred_max:.3f}')\n",
    "plt.axhline(y = y_true_min, color = 'blue', linestyle ='-.', label=f'Mín_true: {y_true_min:.3f}')\n",
    "# plt.axhline(y = y_pred_min, color = 'blue', linestyle = ':',label= f'Mín_pred:{y_pred_min: .3f}')\n",
    "\n",
    "# plt.ylim(-35,-50) ##(-60,-30)\n",
    "plt.title('Comparación de Posiciones Z')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
