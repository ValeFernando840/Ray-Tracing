{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Utils import utils_nn as utlnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_excel(\"../Train_Test/Dataset_Separado/x_test.xlsx\")\n",
    "x_train = pd.read_excel(\"../Train_Test/Dataset_Separado/x_train.xlsx\")\n",
    "y_test = pd.read_excel(\"../Train_Test/Dataset_Separado/y_test.xlsx\")\n",
    "y_train = pd.read_excel(\"../Train_Test/Dataset_Separado/y_train.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## De mi y_train y y_test solo quiero las coordenadas Z\n",
    "R0 = 6.371E6\n",
    "out_z_coord = [f'z_{i}' for i in range(1,101)]\n",
    "y_train_z = y_train[out_z_coord]\n",
    "y_test_z = y_test[out_z_coord]\n",
    "# 'y_test_z son las columnas filtradas de las 3 coordenadas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de x_train: (4104, 9)\n",
      "Columna 0 (latitude_pos_tx): min=-42.2800, max=-42.2800, mean=-42.2800, std=0.0000\n",
      "Columna 1 (longitude_pos_tx): min=-63.4000, max=-63.4000, mean=-63.4000, std=0.0000\n",
      "Columna 2 (elevation_pos_tx): min=0.0000, max=0.0000, mean=0.0000, std=0.0000\n",
      "Columna 3 (fc [Mhz]): min=3.0000, max=30.0000, mean=13.7032, std=6.9191\n",
      "Columna 4 (elevation): min=0.0000, max=40.0000, mean=13.6659, std=11.8820\n",
      "Columna 5 (azimuth): min=87.0000, max=98.0000, mean=92.8209, std=4.5824\n",
      "Columna 6 (year): min=2010.0000, max=2010.0000, mean=2010.0000, std=0.0000\n",
      "Columna 7 (mmdd): min=101.0000, max=1231.0000, mean=985.1394, std=348.8719\n",
      "Columna 8 (hour): min=0.0000, max=20.0000, mean=11.1647, std=4.5880\n"
     ]
    }
   ],
   "source": [
    "print(\"Forma de x_train:\", x_train.shape)\n",
    "\n",
    "for i, col_name in enumerate(x_train.columns):\n",
    "    col = x_train[col_name]\n",
    "    print(f\"Columna {i} ({col_name}): min={col.min():.4f}, max={col.max():.4f}, mean={col.mean():.4f}, std={col.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De toda la Información anterior observo que las columnas como.\n",
    "latitude_pos_tx: -42.28 (valor único y constante)\n",
    "longitude_pos_tx: -63.40 (valor único y constante)\n",
    "elevation_pos_tx: 0.0 (valor único y constante)\n",
    "year: 2010 (valor único y constante)\n",
    "\n",
    "Estas 4 columnas tienen desviacion estándar 0, es decir, no aportan nada al aprendizaje del modelo.\\\n",
    "**Nota**: Los modelos de ML aprenden de las variaciones, y esas columnas no tienen ninguna.\\\n",
    "Procedemos a quitarlos del x_train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(columns = ['latitude_pos_tx', 'longitude_pos_tx', 'elevation_pos_tx', 'year'])\n",
    "x_test = x_test.drop(columns =['latitude_pos_tx', 'longitude_pos_tx', 'elevation_pos_tx', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizamos la salida\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_z = MinMaxScaler()\n",
    "y_train_z_scaled = scaler_z.fit_transform(y_train_z)\n",
    "y_test_z_scaled = scaler_z.transform(y_test_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch = 1160 #1160\n",
    "# b_s = 70\n",
    "# act_name = 'relu'\n",
    "# l2_reg = 0.003\n",
    "# optimizer_name= 'adamW'\n",
    "# while epoch <= 1500:\n",
    "#   while b_s <= 130:\n",
    "    \n",
    "#     inputs = Input(shape=(9,))\n",
    "#     encoded = Dense(9, activation= act_name, kernel_regularizer= l2(l2_reg))(inputs)\n",
    "#     encoded = Dense(16, activation= act_name)(encoded) #, kernel_regularizer= l2(l2_reg)\n",
    "#     encoded = Dense(32, activation= act_name, kernel_regularizer= l2(l2_reg))(encoded)\n",
    "#     encoded = Dense(64, activation= act_name)(encoded) # , kernel_regularizer= l2(l2_reg)\n",
    "#     encoded = Dense(80, activation= act_name, kernel_regularizer= l2(l2_reg))(encoded)\n",
    "#     encoded = Dense(90, activation= act_name)(encoded) #, kernel_regularizer= l2(l2_reg)\n",
    "#     decoded = Dense(100, activation= 'linear', kernel_regularizer= l2(l2_reg), name ='z_output')(encoded)\n",
    "\n",
    "#     autoencoder_y = Model(inputs, decoded)\n",
    "#     autoencoder_y.compile(optimizer = optimizer_name, loss= 'mse')\n",
    "#     autoencoder_y.summary()\n",
    "\n",
    "#     history = autoencoder_y.fit(x_train,y_train_z,\n",
    "#                                 epochs = epoch,\n",
    "#                                 batch_size = b_s,\n",
    "#                                 validation_split = 0.1)\n",
    "    \n",
    "#     loss = autoencoder_y.evaluate(x_test,y_test_z)\n",
    "\n",
    "#     if loss <= 60: # 35\n",
    "#       autoencoder_y.save(f'../modelos_entrenamiento/modelos_z/mod_z_{epoch}_{b_s}_vs10_{optimizer_name}_loss_{round(loss)}.keras')\n",
    "#     print(f'Pérdida en datos de Test: {loss} epoch: {epoch}, batch_size: {b_s}')\n",
    "#     b_s +=20\n",
    "#   b_s = 80\n",
    "#   epoch +=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "  monitor = 'val_loss',\t#monitoriamos la pérdida en validación\n",
    "  patience = 20, # Si no mejora en 10->20 epochs, detenemos el entrenamiento.\n",
    "  restore_best_weights = True # Restaura los mejores pesos encontrados.\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "  monitor = 'val_loss',\n",
    "  patience = 10,\n",
    "  factor = 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ z_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,500</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m30\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_56 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ z_output (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m6,500\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,834</span> (34.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,834\u001b[0m (34.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,834</span> (34.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,834\u001b[0m (34.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3815.8892 - mae: 43.0406 - val_loss: 1953.2415 - val_mae: 31.7968 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1973.1624 - mae: 31.2205 - val_loss: 1784.0580 - val_mae: 29.7742 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1807.8328 - mae: 30.2525 - val_loss: 1720.2910 - val_mae: 28.9412 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1679.0437 - mae: 29.1992 - val_loss: 1697.6031 - val_mae: 29.0831 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1637.6532 - mae: 29.1981 - val_loss: 1675.2380 - val_mae: 28.6901 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1642.3141 - mae: 29.0352 - val_loss: 1653.2371 - val_mae: 28.5876 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1598.5482 - mae: 28.5965 - val_loss: 1623.3983 - val_mae: 28.2335 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1607.5789 - mae: 28.6773 - val_loss: 1563.1079 - val_mae: 28.3338 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1515.5477 - mae: 28.0511 - val_loss: 1494.0581 - val_mae: 27.3184 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1420.1212 - mae: 27.0063 - val_loss: 1388.5302 - val_mae: 26.2778 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1342.2228 - mae: 26.0399 - val_loss: 1233.0979 - val_mae: 25.1526 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1175.4042 - mae: 24.1461 - val_loss: 1121.6375 - val_mae: 23.4166 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1059.7542 - mae: 22.5664 - val_loss: 1057.7797 - val_mae: 22.3625 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1052.1481 - mae: 22.5635 - val_loss: 1050.2562 - val_mae: 21.4366 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1027.7008 - mae: 22.0015 - val_loss: 992.4829 - val_mae: 20.7378 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 892.9515 - mae: 20.3814 - val_loss: 924.3837 - val_mae: 20.3419 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 904.2004 - mae: 20.4308 - val_loss: 884.1445 - val_mae: 19.8093 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 892.0988 - mae: 19.8558 - val_loss: 848.7838 - val_mae: 19.2554 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 857.6075 - mae: 19.5546 - val_loss: 816.3418 - val_mae: 18.6127 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 799.6523 - mae: 18.8593 - val_loss: 787.3478 - val_mae: 18.3706 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 770.4752 - mae: 18.3082 - val_loss: 774.8185 - val_mae: 17.8163 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 738.8568 - mae: 17.7991 - val_loss: 737.5152 - val_mae: 17.1472 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 694.5195 - mae: 17.1006 - val_loss: 709.7521 - val_mae: 16.9445 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 671.7439 - mae: 16.6967 - val_loss: 677.4371 - val_mae: 16.3466 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 615.7651 - mae: 15.8441 - val_loss: 655.5090 - val_mae: 15.8123 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 640.8514 - mae: 15.8093 - val_loss: 645.0912 - val_mae: 15.5310 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 602.3462 - mae: 15.1274 - val_loss: 639.7700 - val_mae: 15.4177 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 640.1716 - mae: 15.4121 - val_loss: 635.7935 - val_mae: 15.0833 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 589.5824 - mae: 14.7624 - val_loss: 614.6666 - val_mae: 14.8035 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 586.2252 - mae: 14.6788 - val_loss: 664.7931 - val_mae: 15.4091 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 610.9688 - mae: 14.9566 - val_loss: 628.0764 - val_mae: 14.7882 - learning_rate: 0.0010\n",
      "Epoch 32/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 610.7269 - mae: 14.7547 - val_loss: 630.3801 - val_mae: 14.6183 - learning_rate: 0.0010\n",
      "Epoch 33/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 572.7126 - mae: 14.1430 - val_loss: 599.6315 - val_mae: 14.4147 - learning_rate: 0.0010\n",
      "Epoch 34/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 582.0088 - mae: 14.2969 - val_loss: 602.5540 - val_mae: 14.2060 - learning_rate: 0.0010\n",
      "Epoch 35/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 563.9871 - mae: 14.0079 - val_loss: 653.4281 - val_mae: 14.8782 - learning_rate: 0.0010\n",
      "Epoch 36/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 550.3688 - mae: 13.8341 - val_loss: 587.3488 - val_mae: 13.9498 - learning_rate: 0.0010\n",
      "Epoch 37/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 550.2234 - mae: 13.7977 - val_loss: 590.4888 - val_mae: 13.9823 - learning_rate: 0.0010\n",
      "Epoch 38/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 556.2639 - mae: 13.7625 - val_loss: 584.8378 - val_mae: 13.8039 - learning_rate: 0.0010\n",
      "Epoch 39/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 548.8315 - mae: 13.7149 - val_loss: 581.1492 - val_mae: 13.7327 - learning_rate: 0.0010\n",
      "Epoch 40/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 572.3474 - mae: 13.7440 - val_loss: 595.5656 - val_mae: 14.1879 - learning_rate: 0.0010\n",
      "Epoch 41/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 575.5317 - mae: 14.0354 - val_loss: 592.7322 - val_mae: 14.0778 - learning_rate: 0.0010\n",
      "Epoch 42/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 565.2974 - mae: 13.8458 - val_loss: 578.1526 - val_mae: 13.5359 - learning_rate: 0.0010\n",
      "Epoch 43/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 575.4379 - mae: 13.8086 - val_loss: 577.1381 - val_mae: 13.5776 - learning_rate: 0.0010\n",
      "Epoch 44/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 551.3551 - mae: 13.3980 - val_loss: 586.7819 - val_mae: 14.0227 - learning_rate: 0.0010\n",
      "Epoch 45/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 540.2438 - mae: 13.4014 - val_loss: 635.4652 - val_mae: 14.2402 - learning_rate: 0.0010\n",
      "Epoch 46/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 544.6002 - mae: 13.4098 - val_loss: 585.9191 - val_mae: 13.9443 - learning_rate: 0.0010\n",
      "Epoch 47/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 560.0761 - mae: 13.6523 - val_loss: 588.1471 - val_mae: 13.5152 - learning_rate: 0.0010\n",
      "Epoch 48/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 572.3140 - mae: 13.6126 - val_loss: 577.0222 - val_mae: 13.3670 - learning_rate: 0.0010\n",
      "Epoch 49/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 529.3795 - mae: 12.9890 - val_loss: 580.4057 - val_mae: 13.4221 - learning_rate: 0.0010\n",
      "Epoch 50/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 571.1096 - mae: 13.6896 - val_loss: 573.4415 - val_mae: 13.3287 - learning_rate: 0.0010\n",
      "Epoch 51/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 522.8855 - mae: 12.9928 - val_loss: 585.1974 - val_mae: 13.5025 - learning_rate: 0.0010\n",
      "Epoch 52/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 524.7534 - mae: 12.9571 - val_loss: 568.2018 - val_mae: 13.4250 - learning_rate: 0.0010\n",
      "Epoch 53/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 547.6826 - mae: 13.2777 - val_loss: 570.8806 - val_mae: 13.1464 - learning_rate: 0.0010\n",
      "Epoch 54/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 578.2964 - mae: 13.4860 - val_loss: 585.6364 - val_mae: 13.2444 - learning_rate: 0.0010\n",
      "Epoch 55/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 524.4996 - mae: 12.9124 - val_loss: 575.2996 - val_mae: 13.1664 - learning_rate: 0.0010\n",
      "Epoch 56/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 548.5244 - mae: 12.9972 - val_loss: 594.5729 - val_mae: 13.5504 - learning_rate: 0.0010\n",
      "Epoch 57/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 521.9890 - mae: 12.7929 - val_loss: 602.2193 - val_mae: 13.5064 - learning_rate: 0.0010\n",
      "Epoch 58/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 547.9962 - mae: 13.1521 - val_loss: 569.3041 - val_mae: 12.9040 - learning_rate: 0.0010\n",
      "Epoch 59/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 541.8704 - mae: 12.7483 - val_loss: 562.0842 - val_mae: 13.0071 - learning_rate: 0.0010\n",
      "Epoch 60/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 545.5353 - mae: 13.2754 - val_loss: 587.8674 - val_mae: 13.4482 - learning_rate: 0.0010\n",
      "Epoch 61/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 495.6169 - mae: 12.5889 - val_loss: 557.0524 - val_mae: 12.9535 - learning_rate: 0.0010\n",
      "Epoch 62/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 498.9408 - mae: 12.6749 - val_loss: 570.5200 - val_mae: 13.5730 - learning_rate: 0.0010\n",
      "Epoch 63/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 510.5331 - mae: 12.6725 - val_loss: 562.8268 - val_mae: 12.8449 - learning_rate: 0.0010\n",
      "Epoch 64/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 496.5143 - mae: 12.4909 - val_loss: 559.9147 - val_mae: 13.1287 - learning_rate: 0.0010\n",
      "Epoch 65/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 561.2390 - mae: 13.1945 - val_loss: 569.8633 - val_mae: 12.9874 - learning_rate: 0.0010\n",
      "Epoch 66/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 537.5521 - mae: 12.9344 - val_loss: 559.0294 - val_mae: 12.7151 - learning_rate: 0.0010\n",
      "Epoch 67/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 521.5430 - mae: 12.6486 - val_loss: 577.8071 - val_mae: 13.0378 - learning_rate: 0.0010\n",
      "Epoch 68/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 517.5405 - mae: 12.8280 - val_loss: 564.5706 - val_mae: 13.0737 - learning_rate: 0.0010\n",
      "Epoch 69/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 540.3238 - mae: 13.0088 - val_loss: 553.2466 - val_mae: 12.9549 - learning_rate: 0.0010\n",
      "Epoch 70/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 529.1194 - mae: 12.9309 - val_loss: 570.5179 - val_mae: 13.0173 - learning_rate: 0.0010\n",
      "Epoch 71/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 562.6090 - mae: 13.2676 - val_loss: 563.9542 - val_mae: 13.0089 - learning_rate: 0.0010\n",
      "Epoch 72/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 519.2944 - mae: 12.5560 - val_loss: 553.4671 - val_mae: 12.7898 - learning_rate: 0.0010\n",
      "Epoch 73/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 517.6257 - mae: 12.7372 - val_loss: 557.1291 - val_mae: 12.5973 - learning_rate: 0.0010\n",
      "Epoch 74/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 518.9891 - mae: 12.6743 - val_loss: 555.4205 - val_mae: 12.6998 - learning_rate: 0.0010\n",
      "Epoch 75/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 567.1660 - mae: 13.1459 - val_loss: 570.7802 - val_mae: 12.7961 - learning_rate: 0.0010\n",
      "Epoch 76/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 546.9992 - mae: 12.9064 - val_loss: 566.2053 - val_mae: 13.5855 - learning_rate: 0.0010\n",
      "Epoch 77/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 539.2260 - mae: 12.9884 - val_loss: 552.4388 - val_mae: 12.8437 - learning_rate: 0.0010\n",
      "Epoch 78/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 508.7729 - mae: 12.6022 - val_loss: 550.0178 - val_mae: 12.7993 - learning_rate: 0.0010\n",
      "Epoch 79/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 536.7767 - mae: 12.9158 - val_loss: 559.3177 - val_mae: 12.6139 - learning_rate: 0.0010\n",
      "Epoch 80/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 526.2627 - mae: 12.5889 - val_loss: 562.0504 - val_mae: 12.8956 - learning_rate: 0.0010\n",
      "Epoch 81/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 551.0912 - mae: 13.0561 - val_loss: 547.2878 - val_mae: 12.4039 - learning_rate: 0.0010\n",
      "Epoch 82/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 507.0158 - mae: 12.4027 - val_loss: 556.4036 - val_mae: 12.6847 - learning_rate: 0.0010\n",
      "Epoch 83/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 512.1426 - mae: 12.3859 - val_loss: 546.0318 - val_mae: 12.8264 - learning_rate: 0.0010\n",
      "Epoch 84/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 493.9019 - mae: 12.4419 - val_loss: 571.7053 - val_mae: 13.2249 - learning_rate: 0.0010\n",
      "Epoch 85/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 516.3987 - mae: 12.6723 - val_loss: 552.2378 - val_mae: 12.6298 - learning_rate: 0.0010\n",
      "Epoch 86/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 488.2892 - mae: 12.2929 - val_loss: 555.8976 - val_mae: 12.5581 - learning_rate: 0.0010\n",
      "Epoch 87/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 529.8345 - mae: 12.7676 - val_loss: 537.7294 - val_mae: 12.5527 - learning_rate: 0.0010\n",
      "Epoch 88/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 523.2824 - mae: 12.4389 - val_loss: 548.6321 - val_mae: 12.5396 - learning_rate: 0.0010\n",
      "Epoch 89/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 481.6254 - mae: 12.0841 - val_loss: 552.9645 - val_mae: 12.9919 - learning_rate: 0.0010\n",
      "Epoch 90/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 490.2390 - mae: 12.4443 - val_loss: 549.4056 - val_mae: 12.5738 - learning_rate: 0.0010\n",
      "Epoch 91/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 526.6160 - mae: 12.6820 - val_loss: 562.7642 - val_mae: 12.6971 - learning_rate: 0.0010\n",
      "Epoch 92/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 509.6027 - mae: 12.3792 - val_loss: 542.2046 - val_mae: 12.3246 - learning_rate: 0.0010\n",
      "Epoch 93/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 527.3495 - mae: 12.6866 - val_loss: 539.2433 - val_mae: 12.4557 - learning_rate: 0.0010\n",
      "Epoch 94/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 500.6549 - mae: 12.4623 - val_loss: 556.3153 - val_mae: 12.7177 - learning_rate: 0.0010\n",
      "Epoch 95/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 514.4325 - mae: 12.3485 - val_loss: 532.8163 - val_mae: 12.2572 - learning_rate: 0.0010\n",
      "Epoch 96/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 514.1631 - mae: 12.3315 - val_loss: 591.8702 - val_mae: 13.2559 - learning_rate: 0.0010\n",
      "Epoch 97/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 508.9473 - mae: 12.4139 - val_loss: 534.2707 - val_mae: 12.3465 - learning_rate: 0.0010\n",
      "Epoch 98/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 480.5539 - mae: 12.1001 - val_loss: 549.4955 - val_mae: 12.5564 - learning_rate: 0.0010\n",
      "Epoch 99/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 487.4615 - mae: 12.0877 - val_loss: 543.3420 - val_mae: 12.4329 - learning_rate: 0.0010\n",
      "Epoch 100/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 522.5172 - mae: 12.4772 - val_loss: 549.5062 - val_mae: 12.4222 - learning_rate: 0.0010\n",
      "Epoch 101/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 476.8464 - mae: 12.1213 - val_loss: 534.5207 - val_mae: 12.3689 - learning_rate: 0.0010\n",
      "Epoch 102/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 505.9161 - mae: 12.2554 - val_loss: 535.3866 - val_mae: 12.2023 - learning_rate: 0.0010\n",
      "Epoch 103/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 472.8141 - mae: 11.8521 - val_loss: 544.6343 - val_mae: 12.5494 - learning_rate: 0.0010\n",
      "Epoch 104/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 493.7433 - mae: 12.1553 - val_loss: 533.4025 - val_mae: 12.8050 - learning_rate: 0.0010\n",
      "Epoch 105/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 495.9118 - mae: 12.2968 - val_loss: 537.3126 - val_mae: 12.2920 - learning_rate: 0.0010\n",
      "Epoch 106/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 504.8897 - mae: 12.3279 - val_loss: 540.2051 - val_mae: 12.4667 - learning_rate: 5.0000e-04\n",
      "Epoch 107/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 517.7428 - mae: 12.4366 - val_loss: 537.2012 - val_mae: 12.1432 - learning_rate: 5.0000e-04\n",
      "Epoch 108/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 516.8340 - mae: 12.4451 - val_loss: 532.7148 - val_mae: 12.2375 - learning_rate: 5.0000e-04\n",
      "Epoch 109/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 498.8521 - mae: 12.0488 - val_loss: 527.5838 - val_mae: 12.0893 - learning_rate: 5.0000e-04\n",
      "Epoch 110/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 489.8527 - mae: 11.9044 - val_loss: 537.0190 - val_mae: 12.3005 - learning_rate: 5.0000e-04\n",
      "Epoch 111/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 538.0115 - mae: 12.4126 - val_loss: 548.7571 - val_mae: 12.2981 - learning_rate: 5.0000e-04\n",
      "Epoch 112/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 517.9926 - mae: 12.4022 - val_loss: 525.5762 - val_mae: 12.2021 - learning_rate: 5.0000e-04\n",
      "Epoch 113/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 496.9225 - mae: 12.0628 - val_loss: 524.8101 - val_mae: 12.0544 - learning_rate: 5.0000e-04\n",
      "Epoch 114/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 524.6188 - mae: 12.2658 - val_loss: 528.6295 - val_mae: 12.1975 - learning_rate: 5.0000e-04\n",
      "Epoch 115/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 510.6039 - mae: 12.2804 - val_loss: 538.7883 - val_mae: 12.2813 - learning_rate: 5.0000e-04\n",
      "Epoch 116/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 517.4865 - mae: 12.4194 - val_loss: 529.8796 - val_mae: 12.1008 - learning_rate: 5.0000e-04\n",
      "Epoch 117/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 523.6409 - mae: 12.3667 - val_loss: 527.1140 - val_mae: 12.0304 - learning_rate: 5.0000e-04\n",
      "Epoch 118/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 512.3113 - mae: 12.2892 - val_loss: 524.7586 - val_mae: 11.9843 - learning_rate: 5.0000e-04\n",
      "Epoch 119/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 485.8732 - mae: 11.9230 - val_loss: 559.0415 - val_mae: 12.5752 - learning_rate: 5.0000e-04\n",
      "Epoch 120/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 554.9812 - mae: 12.6382 - val_loss: 526.6993 - val_mae: 11.9925 - learning_rate: 5.0000e-04\n",
      "Epoch 121/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 522.4789 - mae: 12.3013 - val_loss: 523.2031 - val_mae: 12.0906 - learning_rate: 5.0000e-04\n",
      "Epoch 122/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 488.6184 - mae: 11.8554 - val_loss: 536.4541 - val_mae: 12.3712 - learning_rate: 5.0000e-04\n",
      "Epoch 123/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 550.8644 - mae: 12.6232 - val_loss: 528.5405 - val_mae: 12.0008 - learning_rate: 5.0000e-04\n",
      "Epoch 124/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 487.3687 - mae: 11.8889 - val_loss: 532.3340 - val_mae: 12.1453 - learning_rate: 5.0000e-04\n",
      "Epoch 125/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 512.6900 - mae: 12.2554 - val_loss: 528.4377 - val_mae: 11.9237 - learning_rate: 5.0000e-04\n",
      "Epoch 126/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 484.0476 - mae: 11.8720 - val_loss: 522.6048 - val_mae: 11.9782 - learning_rate: 5.0000e-04\n",
      "Epoch 127/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 533.1056 - mae: 12.4029 - val_loss: 527.5187 - val_mae: 12.2428 - learning_rate: 5.0000e-04\n",
      "Epoch 128/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 473.9474 - mae: 11.8568 - val_loss: 522.1144 - val_mae: 11.9858 - learning_rate: 5.0000e-04\n",
      "Epoch 129/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 527.7646 - mae: 12.2176 - val_loss: 527.7975 - val_mae: 11.9205 - learning_rate: 5.0000e-04\n",
      "Epoch 130/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 527.1370 - mae: 12.3213 - val_loss: 521.1949 - val_mae: 11.8849 - learning_rate: 5.0000e-04\n",
      "Epoch 131/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 506.2841 - mae: 11.8476 - val_loss: 529.0460 - val_mae: 12.1191 - learning_rate: 5.0000e-04\n",
      "Epoch 132/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 532.0491 - mae: 12.3740 - val_loss: 518.8528 - val_mae: 12.0872 - learning_rate: 5.0000e-04\n",
      "Epoch 133/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 525.9687 - mae: 12.3539 - val_loss: 519.2808 - val_mae: 11.8361 - learning_rate: 5.0000e-04\n",
      "Epoch 134/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 457.6898 - mae: 11.5470 - val_loss: 523.6638 - val_mae: 11.9943 - learning_rate: 5.0000e-04\n",
      "Epoch 135/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 494.4981 - mae: 11.8618 - val_loss: 521.1232 - val_mae: 11.8534 - learning_rate: 5.0000e-04\n",
      "Epoch 136/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 534.8474 - mae: 12.4918 - val_loss: 522.9227 - val_mae: 12.0277 - learning_rate: 5.0000e-04\n",
      "Epoch 137/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 489.2745 - mae: 11.8516 - val_loss: 518.8600 - val_mae: 11.8107 - learning_rate: 5.0000e-04\n",
      "Epoch 138/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 513.8085 - mae: 12.1883 - val_loss: 540.7919 - val_mae: 12.2489 - learning_rate: 5.0000e-04\n",
      "Epoch 139/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 535.3789 - mae: 12.3473 - val_loss: 522.3039 - val_mae: 11.8999 - learning_rate: 5.0000e-04\n",
      "Epoch 140/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 573.7457 - mae: 12.8857 - val_loss: 519.6731 - val_mae: 11.8244 - learning_rate: 5.0000e-04\n",
      "Epoch 141/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 497.2848 - mae: 11.9500 - val_loss: 520.9870 - val_mae: 11.8792 - learning_rate: 5.0000e-04\n",
      "Epoch 142/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 509.3127 - mae: 12.1095 - val_loss: 520.1253 - val_mae: 12.0844 - learning_rate: 5.0000e-04\n",
      "Epoch 143/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 452.5465 - mae: 11.5006 - val_loss: 519.3198 - val_mae: 11.8761 - learning_rate: 2.5000e-04\n",
      "Epoch 144/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 492.5155 - mae: 12.0192 - val_loss: 516.6067 - val_mae: 11.7281 - learning_rate: 2.5000e-04\n",
      "Epoch 145/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 476.9852 - mae: 11.6631 - val_loss: 523.4665 - val_mae: 11.8675 - learning_rate: 2.5000e-04\n",
      "Epoch 146/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 508.1353 - mae: 12.0604 - val_loss: 518.5563 - val_mae: 11.8015 - learning_rate: 2.5000e-04\n",
      "Epoch 147/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 463.0752 - mae: 11.4473 - val_loss: 526.5179 - val_mae: 12.0090 - learning_rate: 2.5000e-04\n",
      "Epoch 148/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 481.7355 - mae: 11.8458 - val_loss: 515.5466 - val_mae: 11.8466 - learning_rate: 2.5000e-04\n",
      "Epoch 149/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 483.5518 - mae: 11.7614 - val_loss: 538.1305 - val_mae: 12.1060 - learning_rate: 2.5000e-04\n",
      "Epoch 150/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 527.4765 - mae: 12.2722 - val_loss: 517.0108 - val_mae: 11.7260 - learning_rate: 2.5000e-04\n",
      "Epoch 151/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 475.8454 - mae: 11.5714 - val_loss: 517.4464 - val_mae: 11.8021 - learning_rate: 2.5000e-04\n",
      "Epoch 152/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 489.9067 - mae: 11.8921 - val_loss: 516.4458 - val_mae: 11.7009 - learning_rate: 2.5000e-04\n",
      "Epoch 153/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 491.4634 - mae: 11.7305 - val_loss: 525.0817 - val_mae: 11.8607 - learning_rate: 2.5000e-04\n",
      "Epoch 154/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 477.3519 - mae: 11.6629 - val_loss: 519.2508 - val_mae: 11.6960 - learning_rate: 2.5000e-04\n",
      "Epoch 155/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 509.4266 - mae: 11.8319 - val_loss: 516.4866 - val_mae: 11.7701 - learning_rate: 2.5000e-04\n",
      "Epoch 156/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 482.1427 - mae: 11.7513 - val_loss: 520.4812 - val_mae: 11.6899 - learning_rate: 2.5000e-04\n",
      "Epoch 157/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 498.0937 - mae: 11.8953 - val_loss: 515.0737 - val_mae: 11.6686 - learning_rate: 2.5000e-04\n",
      "Epoch 158/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 486.3144 - mae: 11.7475 - val_loss: 518.6155 - val_mae: 11.6868 - learning_rate: 2.5000e-04\n",
      "Epoch 159/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 519.5919 - mae: 12.1528 - val_loss: 514.2922 - val_mae: 11.6984 - learning_rate: 2.5000e-04\n",
      "Epoch 160/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 515.1017 - mae: 12.0350 - val_loss: 517.9517 - val_mae: 11.7047 - learning_rate: 2.5000e-04\n",
      "Epoch 161/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 474.4338 - mae: 11.5166 - val_loss: 529.6367 - val_mae: 11.9217 - learning_rate: 2.5000e-04\n",
      "Epoch 162/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 495.6413 - mae: 11.8165 - val_loss: 516.0552 - val_mae: 11.6638 - learning_rate: 2.5000e-04\n",
      "Epoch 163/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 506.0898 - mae: 11.9304 - val_loss: 528.4174 - val_mae: 11.9401 - learning_rate: 2.5000e-04\n",
      "Epoch 164/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 483.4839 - mae: 11.6129 - val_loss: 513.9230 - val_mae: 11.6788 - learning_rate: 2.5000e-04\n",
      "Epoch 165/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 463.4516 - mae: 11.5760 - val_loss: 515.7001 - val_mae: 11.7497 - learning_rate: 2.5000e-04\n",
      "Epoch 166/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 484.6660 - mae: 11.7814 - val_loss: 517.9334 - val_mae: 11.7373 - learning_rate: 2.5000e-04\n",
      "Epoch 167/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 484.1343 - mae: 11.6944 - val_loss: 521.6253 - val_mae: 12.1020 - learning_rate: 2.5000e-04\n",
      "Epoch 168/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 510.8057 - mae: 12.1913 - val_loss: 521.8019 - val_mae: 11.8827 - learning_rate: 2.5000e-04\n",
      "Epoch 169/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 512.3067 - mae: 11.9722 - val_loss: 512.2887 - val_mae: 11.6919 - learning_rate: 2.5000e-04\n",
      "Epoch 170/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 483.0638 - mae: 11.6970 - val_loss: 534.9325 - val_mae: 11.9758 - learning_rate: 2.5000e-04\n",
      "Epoch 171/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 466.2962 - mae: 11.6796 - val_loss: 511.0441 - val_mae: 11.6597 - learning_rate: 2.5000e-04\n",
      "Epoch 172/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 496.2149 - mae: 11.8320 - val_loss: 520.8231 - val_mae: 11.7985 - learning_rate: 2.5000e-04\n",
      "Epoch 173/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 482.9026 - mae: 11.6900 - val_loss: 512.2068 - val_mae: 11.7281 - learning_rate: 2.5000e-04\n",
      "Epoch 174/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 493.9572 - mae: 11.8501 - val_loss: 512.2070 - val_mae: 11.7310 - learning_rate: 2.5000e-04\n",
      "Epoch 175/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 490.4120 - mae: 11.6728 - val_loss: 511.0609 - val_mae: 11.6825 - learning_rate: 2.5000e-04\n",
      "Epoch 176/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 494.2232 - mae: 11.8469 - val_loss: 513.6882 - val_mae: 11.6375 - learning_rate: 2.5000e-04\n",
      "Epoch 177/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 503.5385 - mae: 11.8763 - val_loss: 515.9055 - val_mae: 11.5848 - learning_rate: 2.5000e-04\n",
      "Epoch 178/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 488.6638 - mae: 11.7394 - val_loss: 511.0239 - val_mae: 11.7995 - learning_rate: 2.5000e-04\n",
      "Epoch 179/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 501.1654 - mae: 11.7670 - val_loss: 512.7693 - val_mae: 11.5929 - learning_rate: 2.5000e-04\n",
      "Epoch 180/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 503.1381 - mae: 12.1162 - val_loss: 509.8557 - val_mae: 11.6465 - learning_rate: 2.5000e-04\n",
      "Epoch 181/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 472.4166 - mae: 11.5345 - val_loss: 526.5473 - val_mae: 11.8847 - learning_rate: 2.5000e-04\n",
      "Epoch 182/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 502.0289 - mae: 11.8376 - val_loss: 511.4339 - val_mae: 11.6711 - learning_rate: 2.5000e-04\n",
      "Epoch 183/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 500.9022 - mae: 11.8554 - val_loss: 513.3177 - val_mae: 11.7686 - learning_rate: 2.5000e-04\n",
      "Epoch 184/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 480.3806 - mae: 11.6293 - val_loss: 523.3893 - val_mae: 11.7534 - learning_rate: 2.5000e-04\n",
      "Epoch 185/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 493.7898 - mae: 11.7960 - val_loss: 518.2614 - val_mae: 11.6977 - learning_rate: 2.5000e-04\n",
      "Epoch 186/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 467.0279 - mae: 11.4847 - val_loss: 514.3654 - val_mae: 11.5827 - learning_rate: 2.5000e-04\n",
      "Epoch 187/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 491.8294 - mae: 11.8842 - val_loss: 509.9666 - val_mae: 11.6026 - learning_rate: 2.5000e-04\n",
      "Epoch 188/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 471.4917 - mae: 11.5753 - val_loss: 511.8058 - val_mae: 11.5492 - learning_rate: 2.5000e-04\n",
      "Epoch 189/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 478.5256 - mae: 11.6010 - val_loss: 509.1920 - val_mae: 11.6897 - learning_rate: 2.5000e-04\n",
      "Epoch 190/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 477.7847 - mae: 11.4948 - val_loss: 510.3651 - val_mae: 11.5469 - learning_rate: 2.5000e-04\n",
      "Epoch 191/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 498.5169 - mae: 11.7264 - val_loss: 517.4838 - val_mae: 11.6758 - learning_rate: 2.5000e-04\n",
      "Epoch 192/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 495.8015 - mae: 11.7483 - val_loss: 513.5019 - val_mae: 11.7226 - learning_rate: 2.5000e-04\n",
      "Epoch 193/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 487.2478 - mae: 11.7670 - val_loss: 512.4913 - val_mae: 11.7132 - learning_rate: 2.5000e-04\n",
      "Epoch 194/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 480.0220 - mae: 11.6838 - val_loss: 507.2108 - val_mae: 11.6150 - learning_rate: 2.5000e-04\n",
      "Epoch 195/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 538.4861 - mae: 12.2428 - val_loss: 510.1250 - val_mae: 11.4951 - learning_rate: 2.5000e-04\n",
      "Epoch 196/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 479.8601 - mae: 11.6048 - val_loss: 513.7255 - val_mae: 11.5851 - learning_rate: 2.5000e-04\n",
      "Epoch 197/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 492.4747 - mae: 11.8153 - val_loss: 513.2667 - val_mae: 11.6268 - learning_rate: 2.5000e-04\n",
      "Epoch 198/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 493.5387 - mae: 11.7516 - val_loss: 508.6529 - val_mae: 11.5322 - learning_rate: 2.5000e-04\n",
      "Epoch 199/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 483.2924 - mae: 11.6357 - val_loss: 511.2812 - val_mae: 11.6466 - learning_rate: 2.5000e-04\n",
      "Epoch 200/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 484.7300 - mae: 11.6649 - val_loss: 512.7427 - val_mae: 11.6276 - learning_rate: 2.5000e-04\n",
      "Epoch 201/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 483.7225 - mae: 11.6890 - val_loss: 513.4591 - val_mae: 11.5673 - learning_rate: 2.5000e-04\n",
      "Epoch 202/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 513.3746 - mae: 11.9366 - val_loss: 511.8978 - val_mae: 11.5738 - learning_rate: 2.5000e-04\n",
      "Epoch 203/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 484.2686 - mae: 11.6133 - val_loss: 511.5735 - val_mae: 11.5441 - learning_rate: 2.5000e-04\n",
      "Epoch 204/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 496.4692 - mae: 11.6315 - val_loss: 511.2617 - val_mae: 11.5257 - learning_rate: 2.5000e-04\n",
      "Epoch 205/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 480.3501 - mae: 11.5987 - val_loss: 508.6722 - val_mae: 11.4984 - learning_rate: 1.2500e-04\n",
      "Epoch 206/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 476.8727 - mae: 11.5770 - val_loss: 510.9108 - val_mae: 11.5399 - learning_rate: 1.2500e-04\n",
      "Epoch 207/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 494.6979 - mae: 11.7099 - val_loss: 508.0763 - val_mae: 11.5233 - learning_rate: 1.2500e-04\n",
      "Epoch 208/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 497.2384 - mae: 11.7997 - val_loss: 508.7263 - val_mae: 11.4964 - learning_rate: 1.2500e-04\n",
      "Epoch 209/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 482.9470 - mae: 11.5528 - val_loss: 509.1495 - val_mae: 11.5121 - learning_rate: 1.2500e-04\n",
      "Epoch 210/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 512.0574 - mae: 11.8098 - val_loss: 509.0910 - val_mae: 11.4930 - learning_rate: 1.2500e-04\n",
      "Epoch 211/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 506.3025 - mae: 11.8167 - val_loss: 509.4571 - val_mae: 11.5509 - learning_rate: 1.2500e-04\n",
      "Epoch 212/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 467.1610 - mae: 11.4307 - val_loss: 505.8021 - val_mae: 11.5501 - learning_rate: 1.2500e-04\n",
      "Epoch 213/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 517.6334 - mae: 11.9375 - val_loss: 514.3090 - val_mae: 11.5698 - learning_rate: 1.2500e-04\n",
      "Epoch 214/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 495.8073 - mae: 11.7616 - val_loss: 507.1615 - val_mae: 11.4662 - learning_rate: 1.2500e-04\n",
      "Epoch 215/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 483.7503 - mae: 11.5304 - val_loss: 507.1023 - val_mae: 11.5438 - learning_rate: 1.2500e-04\n",
      "Epoch 216/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 480.9859 - mae: 11.5240 - val_loss: 506.2669 - val_mae: 11.5161 - learning_rate: 1.2500e-04\n",
      "Epoch 217/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 493.5978 - mae: 11.7648 - val_loss: 509.8515 - val_mae: 11.4635 - learning_rate: 1.2500e-04\n",
      "Epoch 218/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 481.5795 - mae: 11.5368 - val_loss: 506.5059 - val_mae: 11.4537 - learning_rate: 1.2500e-04\n",
      "Epoch 219/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 514.9759 - mae: 11.8957 - val_loss: 507.1965 - val_mae: 11.4851 - learning_rate: 1.2500e-04\n",
      "Epoch 220/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 508.6344 - mae: 11.9291 - val_loss: 506.6708 - val_mae: 11.5189 - learning_rate: 1.2500e-04\n",
      "Epoch 221/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 488.1848 - mae: 11.6556 - val_loss: 507.9103 - val_mae: 11.4532 - learning_rate: 1.2500e-04\n",
      "Epoch 222/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 489.1469 - mae: 11.7698 - val_loss: 517.0369 - val_mae: 11.5986 - learning_rate: 1.2500e-04\n",
      "Epoch 223/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 490.2628 - mae: 11.6969 - val_loss: 510.3777 - val_mae: 11.4890 - learning_rate: 6.2500e-05\n",
      "Epoch 224/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 507.7648 - mae: 11.8802 - val_loss: 506.5887 - val_mae: 11.5037 - learning_rate: 6.2500e-05\n",
      "Epoch 225/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 475.2861 - mae: 11.3845 - val_loss: 506.2857 - val_mae: 11.4868 - learning_rate: 6.2500e-05\n",
      "Epoch 226/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 487.6840 - mae: 11.7000 - val_loss: 509.7719 - val_mae: 11.5052 - learning_rate: 6.2500e-05\n",
      "Epoch 227/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 495.1297 - mae: 11.6549 - val_loss: 507.1150 - val_mae: 11.4313 - learning_rate: 6.2500e-05\n",
      "Epoch 228/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 497.7539 - mae: 11.6059 - val_loss: 508.2803 - val_mae: 11.5098 - learning_rate: 6.2500e-05\n",
      "Epoch 229/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 492.6668 - mae: 11.7397 - val_loss: 506.7280 - val_mae: 11.4545 - learning_rate: 6.2500e-05\n",
      "Epoch 230/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 499.7704 - mae: 11.6142 - val_loss: 506.9074 - val_mae: 11.4986 - learning_rate: 6.2500e-05\n",
      "Epoch 231/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 469.7254 - mae: 11.5667 - val_loss: 506.0840 - val_mae: 11.4554 - learning_rate: 6.2500e-05\n",
      "Epoch 232/1000\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 517.1021 - mae: 11.8643 - val_loss: 506.2703 - val_mae: 11.4439 - learning_rate: 6.2500e-05\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 485.7858 - mae: 11.5831\n"
     ]
    }
   ],
   "source": [
    "act_name = \"relu\"\n",
    "l2_reg = 0.0\n",
    "epoch = 1000\n",
    "b_s= 48\n",
    "optimizer_name = \"adam\"\n",
    "\n",
    "inputs = Input(shape=(5,))\n",
    "encoded = Dense(5, activation= act_name, kernel_regularizer= l2(l2_reg))(inputs)\n",
    "# encoded = Dense(16, activation= act_name, kernel_regularizer= l2(l2_reg))(encoded) #, \n",
    "encoded = Dense(32, activation= act_name, kernel_regularizer= l2(l2_reg))(encoded)\n",
    "encoded = Dense(64, activation= act_name, kernel_regularizer= l2(l2_reg))(encoded) # , kernel_regularizer= l2(l2_reg)\n",
    "# encoded = Dense(80, activation= act_name, kernel_regularizer= l2(l2_reg))(encoded)\n",
    "# encoded = Dense(90, activation= act_name, kernel_regularizer= l2(l2_reg))(encoded) #, kernel_regularizer= l2(l2_reg)\n",
    "decoded = Dense(100, activation= 'linear', kernel_regularizer= l2(l2_reg), name ='z_output')(encoded)\n",
    "\n",
    "autoencoder_z = Model(inputs, decoded)\n",
    "autoencoder_z.compile(optimizer = optimizer_name, loss= 'mse',metrics = ['mae'])\n",
    "autoencoder_z.summary()\n",
    "\n",
    "history = autoencoder_z.fit(x_train,y_train_z,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tepochs = epoch,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tbatch_size = b_s,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tvalidation_split = 0.1,\n",
    "                            callbacks = [early_stopping, reduce_lr]\n",
    "                            )\n",
    "\n",
    "loss = autoencoder_z.evaluate(x_test,y_test_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 485.7858 - mae: 11.5831\n",
      "Pérdida en datos de Test: [437.19464111328125, 11.170164108276367]\n",
      "mae:71165115.53382874[m]\n"
     ]
    }
   ],
   "source": [
    "loss = autoencoder_z.evaluate(x_test,y_test_z)\n",
    "print(f'Pérdida en datos de Test: {loss}')\n",
    "\n",
    "mae_in_m = loss[1]*R0\n",
    "print(f'mae:{mae_in_m}[m]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000021ADD4A7880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "\n",
    " # Elegir una muestra para comparar (observar luego la muestra 30)\n",
    "\n",
    "# Predicción de una muestra \n",
    "y_pred_scaled = autoencoder_z.predict(np.expand_dims(x_test.iloc[idx], axis=0))\n",
    "###############################################\n",
    "y_true = y_test_z.iloc[idx] # Se obtine Algo de tipo Serie\n",
    "y_true=y_true.to_numpy() # Transform a Numpy array\n",
    "\n",
    "#Desnormalizamos\n",
    "y_pred = scaler_z.inverse_transform(y_pred_scaled)\n",
    "\n",
    "y_pred = y_pred.flatten() # [[...,...,...,....,]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.48077768e-01, 1.01075354e+01, 3.55674591e+01, 7.57110672e+01,\n",
       "       1.30902237e+02, 2.06429703e+02, 2.89408875e+02, 3.93725403e+02,\n",
       "       5.29241760e+02, 6.68669312e+02, 8.33652344e+02, 1.01122522e+03,\n",
       "       1.22392493e+03, 1.48270752e+03, 1.75594983e+03, 2.06547729e+03,\n",
       "       2.39354370e+03, 2.76061646e+03, 3.10572974e+03, 3.50561963e+03,\n",
       "       3.87141528e+03, 4.27199561e+03, 4.82306396e+03, 5.45916406e+03,\n",
       "       6.08846191e+03, 6.66957617e+03, 7.30144287e+03, 7.82518799e+03,\n",
       "       8.44919629e+03, 8.99634082e+03, 9.48702246e+03, 9.97394824e+03,\n",
       "       1.05443037e+04, 1.10592080e+04, 1.16060684e+04, 1.21077207e+04,\n",
       "       1.26654639e+04, 1.30886045e+04, 1.36613623e+04, 1.41818818e+04,\n",
       "       1.46952959e+04, 1.51265703e+04, 1.56665488e+04, 1.61767539e+04,\n",
       "       1.67691641e+04, 1.72946934e+04, 1.77289062e+04, 1.81423535e+04,\n",
       "       1.86234863e+04, 1.90725000e+04, 1.94456250e+04, 1.98205566e+04,\n",
       "       2.01353555e+04, 2.08274160e+04, 2.14248262e+04, 2.20552988e+04,\n",
       "       2.26836387e+04, 2.32324590e+04, 2.39128047e+04, 2.44996211e+04,\n",
       "       2.50921289e+04, 2.57046738e+04, 2.62852852e+04, 2.67161191e+04,\n",
       "       2.71267715e+04, 2.73864492e+04, 2.73923301e+04, 2.74272637e+04,\n",
       "       2.71436621e+04, 2.67233789e+04, 2.69823086e+04, 2.75215488e+04,\n",
       "       2.80707461e+04, 2.86388125e+04, 2.91034766e+04, 2.96699082e+04,\n",
       "       3.01137617e+04, 3.04791250e+04, 3.09028477e+04, 3.12723418e+04,\n",
       "       3.16437871e+04, 3.19827500e+04, 3.23515566e+04, 3.28486992e+04,\n",
       "       3.32302852e+04, 3.36548398e+04, 3.38314492e+04, 3.42515586e+04,\n",
       "       3.47294961e+04, 3.51147227e+04, 3.54558750e+04, 3.58649570e+04,\n",
       "       3.62425156e+04, 3.65379922e+04, 3.69083438e+04, 3.72398203e+04,\n",
       "       3.75917773e+04, 3.80337031e+04, 3.84298203e+04, 3.90797930e+04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.44775896,   1.99148385,   3.54232707,   5.10028238,\n",
       "         6.66534353,   8.23802392,   9.82767563,  11.42442209,\n",
       "        13.028257  ,  14.63917406,  16.25819912,  17.89358734,\n",
       "        19.53604558,  21.18556747,  22.84214665,  24.5073068 ,\n",
       "        26.18818526,  27.87610752,  29.57106716,  31.27305774,\n",
       "        32.98404148,  34.70992017,  36.442814  ,  38.1827165 ,\n",
       "        39.92962116,  41.67925046,  43.42298711,  45.17359645,\n",
       "        46.93107205,  48.69540745,  50.45937633,  52.21325849,\n",
       "        53.97384698,  55.74113545,  57.51511753,  59.28931984,\n",
       "        61.05811835,  62.83348104,  64.6154016 ,  66.40387373,\n",
       "        68.18757523,  69.96073882,  71.74028792,  73.52621632,\n",
       "        75.31851781,  77.09795907,  78.86011811,  80.62843438,\n",
       "        82.4029018 ,  84.18351431,  85.94450405,  87.6856959 ,\n",
       "        89.4327894 ,  91.18577866,  92.94465781,  94.68031203,\n",
       "        96.39785308,  98.12104081,  99.84986954, 101.58433354,\n",
       "       103.29510182, 104.99178028, 106.69387268, 108.40137347,\n",
       "       110.11427711, 111.80617435, 113.48910708, 115.17725779,\n",
       "       116.87062107, 118.56919149, 120.25147777, 121.92964132,\n",
       "       123.61286549, 125.30114496, 126.99447441, 128.67821619,\n",
       "       130.36204239, 132.05081413, 133.74452615, 135.4431732 ,\n",
       "       137.14019152, 138.84045206, 140.54558447, 142.25558349,\n",
       "       143.9704439 , 145.69127149, 147.41713284, 149.14782559,\n",
       "       150.88334448, 152.62368425, 154.3795096 , 156.1413544 ,\n",
       "       157.90802904, 159.67952822, 161.45584663, 161.5574594 ,\n",
       "       161.57079698, 161.58413482, 161.59747293, 161.61081131])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Graficamos \n",
    "# Buscamos los máximos y mínimos \n",
    "y_true_max = np.max(y_true)\n",
    "y_true_min = np.min(y_true)\n",
    "\n",
    "y_pred_max = np.max(y_pred)\n",
    "y_pred_min = np.min(y_pred)\n",
    "\n",
    "# Pos y\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(y_true, label='Posiciones Z reales', linestyle='None', marker='.')\n",
    "# plt.plot(y_pred, label='Posiciones Z predichas', linestyle = 'None',marker='o')\n",
    "# Dibujamos los max y min\n",
    "plt.axhline(y = y_true_max, color = 'red', linestyle = '-.', label=f'Máx_true: {y_true_max:.3f}')\n",
    "# plt.axhline(y = y_pred_max, color = 'red', linestyle = ':', label= f'Máx_pred: {y_pred_max:.3f}')\n",
    "plt.axhline(y = y_true_min, color = 'blue', linestyle ='-.', label=f'Mín_true: {y_true_min:.3f}')\n",
    "# plt.axhline(y = y_pred_min, color = 'blue', linestyle = ':',label= f'Mín_pred:{y_pred_min: .3f}')\n",
    "\n",
    "# plt.ylim(-35,-50) ##(-60,-30)\n",
    "plt.title('Comparación de Posiciones Z')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
