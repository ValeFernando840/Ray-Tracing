{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Utils import utils_nn as utlnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_excel(\"../Train_Test/Dataset_Separado/x_test_new.xlsx\")\n",
    "x_train = pd.read_excel(\"../Train_Test/Dataset_Separado/x_train_new.xlsx\")\n",
    "y_test = pd.read_excel(\"../Train_Test/Dataset_Separado/y_test_new.xlsx\")\n",
    "y_train = pd.read_excel(\"../Train_Test/Dataset_Separado/y_train_new.xlsx\")\n",
    "# Se Verificó que las alturas comienzan desde R0 si el valor inicial es 6.371E6 estamos con R0 incluido.\n",
    "# Tenemos que quitar ese R0 inicial de las alturas para el entrenamiento y para evitar alturas negativas aplicamos modulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De mi y_train y y_test solo quiero las coordenadas Z\n",
    "R0 = 6.371E6\n",
    "out_z_coord = [f'alt_{i}' for i in range(1,201)]\n",
    "y_train_z = y_train[out_z_coord] - R0\n",
    "y_test_z = y_test[out_z_coord] - R0 \n",
    "# 'y_test_z son las columnas filtradas de las 3 coordenadas'\n",
    "y_train_z = y_train_z.abs()\n",
    "y_test_z = y_test_z.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información Min-Max del dataframe: y_train_z:(29977, 200)\n",
      "Columna 0 (alt_1): min=0.0000, max=967.7734, mean=34.5070, std=150.4915\n",
      "Columna 1 (alt_2): min=0.0000, max=4830.6334, mean=1227.7708, std=665.8072\n",
      "Columna 2 (alt_3): min=0.0009, max=9675.9811, mean=2507.8030, std=1332.7501\n",
      "Columna 3 (alt_4): min=1.5971, max=14536.1726, mean=3878.7076, std=1969.4474\n",
      "Columna 4 (alt_5): min=0.7039, max=19410.9981, mean=5273.4198, std=2564.9557\n",
      "Columna 5 (alt_6): min=4.4097, max=24300.2182, mean=6662.1439, std=3176.4037\n",
      "Columna 6 (alt_7): min=9.9492, max=29204.2055, mean=8053.6555, std=3779.8459\n",
      "Columna 7 (alt_8): min=0.5763, max=34123.0016, mean=9438.1208, std=4395.1892\n",
      "Columna 8 (alt_9): min=25.6304, max=39056.2009, mean=10826.6331, std=5010.7811\n",
      "Columna 9 (alt_10): min=24.3595, max=44004.0823, mean=12223.9242, std=5620.9888\n",
      "Columna 10 (alt_11): min=38.0584, max=48966.7294, mean=13629.0301, std=6229.2046\n",
      "Columna 11 (alt_12): min=27.7157, max=53943.7318, mean=15040.1009, std=6839.9561\n",
      "Columna 12 (alt_13): min=25.4183, max=58935.3140, mean=16457.8944, std=7451.9494\n",
      "Columna 13 (alt_14): min=26.1386, max=63942.2621, mean=17882.3031, std=8065.6748\n",
      "Columna 14 (alt_15): min=112.9496, max=68965.2119, mean=19324.8361, std=8656.4819\n",
      "Columna 15 (alt_16): min=1290.3448, max=74000.0610, mean=20769.7588, std=9258.2551\n",
      "Columna 16 (alt_17): min=1484.0126, max=79050.2883, mean=22221.9959, std=9860.5813\n",
      "Columna 17 (alt_18): min=1693.4918, max=84139.0982, mean=23682.2877, std=10462.0581\n",
      "Columna 18 (alt_19): min=1917.2158, max=89203.1848, mean=25150.6228, std=11062.8419\n",
      "Columna 19 (alt_20): min=2153.9736, max=94166.5332, mean=26627.0045, std=11663.0596\n",
      "Columna 20 (alt_21): min=2404.3389, max=99002.3923, mean=28111.4296, std=12262.8174\n",
      "Columna 21 (alt_22): min=2668.4892, max=103768.3766, mean=29603.8962, std=12862.2170\n",
      "Columna 22 (alt_23): min=2946.4859, max=108524.4116, mean=31104.4058, std=13461.4097\n",
      "Columna 23 (alt_24): min=3238.2033, max=113250.0005, mean=32612.9340, std=14060.4529\n",
      "Columna 24 (alt_25): min=3543.6694, max=117953.0715, mean=34129.4612, std=14659.4083\n",
      "Columna 25 (alt_26): min=3863.0254, max=122662.3930, mean=35653.9496, std=15258.3028\n",
      "Columna 26 (alt_27): min=4196.3092, max=127383.9757, mean=37186.3399, std=15857.0818\n",
      "Columna 27 (alt_28): min=4543.3928, max=132096.7868, mean=38726.5771, std=16455.7107\n",
      "Columna 28 (alt_29): min=4904.3363, max=136779.6057, mean=40274.5938, std=17054.1272\n",
      "Columna 29 (alt_30): min=5279.1864, max=141432.3338, mean=41830.3046, std=17652.2607\n",
      "Columna 30 (alt_31): min=5667.8041, max=146054.7483, mean=43393.6068, std=18250.0374\n",
      "Columna 31 (alt_32): min=6070.2634, max=150640.6145, mean=44964.4139, std=18847.4588\n",
      "Columna 32 (alt_33): min=6486.7067, max=155183.7562, mean=46542.6009, std=19444.4566\n",
      "Columna 33 (alt_34): min=6917.1327, max=159688.6106, mean=48127.9849, std=20040.8807\n",
      "Columna 34 (alt_35): min=7361.4424, max=164163.4302, mean=49720.4375, std=20636.5963\n",
      "Columna 35 (alt_36): min=7819.6680, max=168625.8014, mean=51319.6938, std=21231.3451\n",
      "Columna 36 (alt_37): min=8291.8020, max=173038.6417, mean=52925.4199, std=21824.8179\n",
      "Columna 37 (alt_38): min=8777.7265, max=177348.8989, mean=54537.3300, std=22416.7907\n",
      "Columna 38 (alt_39): min=9277.5559, max=181548.6307, mean=56155.0548, std=23006.9191\n",
      "Columna 39 (alt_40): min=9791.4305, max=185638.6080, mean=57778.1521, std=23594.8022\n",
      "Columna 40 (alt_41): min=10319.2575, max=189608.4605, mean=59406.2142, std=24180.1574\n",
      "Columna 41 (alt_42): min=10861.0155, max=193440.6609, mean=61038.7274, std=24762.5791\n",
      "Columna 42 (alt_43): min=11416.8130, max=197139.4249, mean=62675.1700, std=25341.7765\n",
      "Columna 43 (alt_44): min=11986.6778, max=200712.2153, mean=64315.0153, std=25917.5466\n",
      "Columna 44 (alt_45): min=12570.4993, max=206175.1317, mean=65957.9349, std=26489.8231\n",
      "Columna 45 (alt_46): min=13168.3408, max=212931.8635, mean=67603.3684, std=27058.4870\n",
      "Columna 46 (alt_47): min=13780.2599, max=219634.4110, mean=69250.9355, std=27623.4960\n",
      "Columna 47 (alt_48): min=14406.1555, max=226170.2586, mean=70900.4010, std=28185.0981\n",
      "Columna 48 (alt_49): min=15046.0477, max=232418.8418, mean=72551.7150, std=28743.6158\n",
      "Columna 49 (alt_50): min=15700.0068, max=238300.1186, mean=74204.7123, std=29299.2579\n",
      "Columna 50 (alt_51): min=16367.9684, max=243758.4251, mean=75859.4367, std=29852.4021\n",
      "Columna 51 (alt_52): min=17049.8906, max=248767.6871, mean=77516.1341, std=30403.5487\n",
      "Columna 52 (alt_53): min=17745.9220, max=253325.8318, mean=79175.1369, std=30953.1841\n",
      "Columna 53 (alt_54): min=18456.1573, max=257447.0892, mean=80836.4833, std=31501.4899\n",
      "Columna 54 (alt_55): min=19180.4621, max=261156.5420, mean=82500.2613, std=32048.6658\n",
      "Columna 55 (alt_56): min=19918.8819, max=264485.1372, mean=84166.5434, std=32594.8725\n",
      "Columna 56 (alt_57): min=20671.4884, max=267466.1032, mean=85835.2524, std=33140.1484\n",
      "Columna 57 (alt_58): min=21438.2015, max=270134.2432, mean=87506.2265, std=33684.4934\n",
      "Columna 58 (alt_59): min=22219.0142, max=272522.0034, mean=89179.1647, std=34227.7776\n",
      "Columna 59 (alt_60): min=23014.0017, max=274658.8229, mean=90853.7029, std=34769.8888\n",
      "Columna 60 (alt_61): min=23823.1442, max=276570.9615, mean=92529.3871, std=35310.5556\n",
      "Columna 61 (alt_62): min=24646.3546, max=278281.8021, mean=94205.7440, std=35849.5426\n",
      "Columna 62 (alt_63): min=25483.7748, max=279812.6377, mean=95882.3044, std=36386.4858\n",
      "Columna 63 (alt_64): min=26335.5288, max=281182.9888, mean=97558.6860, std=36921.0664\n",
      "Columna 64 (alt_65): min=27201.5091, max=282410.0932, mean=99234.5372, std=37452.9671\n",
      "Columna 65 (alt_66): min=28081.7115, max=283508.7738, mean=100909.4132, std=37981.8540\n",
      "Columna 66 (alt_67): min=28976.1770, max=284492.7111, mean=102583.0036, std=38507.3264\n",
      "Columna 67 (alt_68): min=29884.8132, max=285373.0084, mean=104255.1323, std=39029.0855\n",
      "Columna 68 (alt_69): min=30807.6238, max=286159.9627, mean=105925.4719, std=39546.7411\n",
      "Columna 69 (alt_70): min=31744.7647, max=286863.0060, mean=107593.6199, std=40059.6776\n",
      "Columna 70 (alt_71): min=32696.3230, max=287490.3117, mean=109259.3303, std=40567.4217\n",
      "Columna 71 (alt_72): min=33662.1763, max=288049.0207, mean=110922.3780, std=41069.5619\n",
      "Columna 72 (alt_73): min=34642.3483, max=288546.5127, mean=112582.4108, std=41565.6123\n",
      "Columna 73 (alt_74): min=35636.8677, max=288988.6199, mean=114238.7826, std=42054.7388\n",
      "Columna 74 (alt_75): min=36645.6294, max=289380.5983, mean=115890.8424, std=42536.0001\n",
      "Columna 75 (alt_76): min=37668.6877, max=289727.3475, mean=117537.8599, std=43008.5086\n",
      "Columna 76 (alt_77): min=38706.1623, max=290033.3018, mean=119179.0620, std=43471.3834\n",
      "Columna 77 (alt_78): min=39758.0278, max=290302.2260, mean=120813.7147, std=43923.6444\n",
      "Columna 78 (alt_79): min=40824.2168, max=290537.7022, mean=122441.0273, std=44364.1953\n",
      "Columna 79 (alt_80): min=41904.8484, max=290743.0611, mean=124060.0281, std=44791.8598\n",
      "Columna 80 (alt_81): min=42999.9936, max=290920.8954, mean=125669.7541, std=45205.4921\n",
      "Columna 81 (alt_82): min=44109.5355, max=291074.5955, mean=127269.1334, std=45603.8650\n",
      "Columna 82 (alt_83): min=45233.5324, max=291206.9030, mean=128857.0334, std=45985.6160\n",
      "Columna 83 (alt_84): min=46372.0615, max=291732.4570, mean=130432.0189, std=46349.2823\n",
      "Columna 84 (alt_85): min=47525.0210, max=292326.7260, mean=131992.6091, std=46693.5287\n",
      "Columna 85 (alt_86): min=48692.4413, max=292871.3901, mean=133537.0999, std=47016.7382\n",
      "Columna 86 (alt_87): min=49874.4452, max=293373.3276, mean=135063.5800, std=47317.2711\n",
      "Columna 87 (alt_88): min=51071.0414, max=293835.9118, mean=136569.7692, std=47593.4891\n",
      "Columna 88 (alt_89): min=52282.1438, max=294253.3142, mean=138053.2015, std=47843.8872\n",
      "Columna 89 (alt_90): min=53507.8318, max=294629.4328, mean=139511.1378, std=48066.6136\n",
      "Columna 90 (alt_91): min=54748.1524, max=294969.0707, mean=140940.7075, std=48260.0621\n",
      "Columna 91 (alt_92): min=56003.0018, max=295340.4596, mean=142338.8869, std=48422.6298\n",
      "Columna 92 (alt_93): min=57272.4431, max=295984.1970, mean=143702.0183, std=48553.2227\n",
      "Columna 93 (alt_94): min=58556.5632, max=296536.3410, mean=145026.1595, std=48650.6264\n",
      "Columna 94 (alt_95): min=59855.2832, max=296992.2323, mean=146307.1926, std=48713.7425\n",
      "Columna 95 (alt_96): min=61168.6058, max=297358.0980, mean=147540.9368, std=48742.1867\n",
      "Columna 96 (alt_97): min=62496.6195, max=297635.2994, mean=148723.0244, std=48735.7836\n",
      "Columna 97 (alt_98): min=63839.3317, max=297821.2591, mean=149848.7999, std=48695.2574\n",
      "Columna 98 (alt_99): min=65196.6682, max=297919.2212, mean=150914.1195, std=48621.7878\n",
      "Columna 99 (alt_100): min=66568.6760, max=297959.7171, mean=151915.1888, std=48517.1300\n",
      "Columna 100 (alt_101): min=67955.3756, max=297945.4884, mean=152848.6329, std=48383.5918\n",
      "Columna 101 (alt_102): min=69356.6776, max=297904.8412, mean=153712.7383, std=48223.8913\n",
      "Columna 102 (alt_103): min=70772.6468, max=297817.6957, mean=154506.7836, std=48040.2714\n",
      "Columna 103 (alt_104): min=72203.3680, max=297598.1362, mean=155230.9935, std=47835.3529\n",
      "Columna 104 (alt_105): min=73648.7586, max=297247.2945, mean=155886.9523, std=47611.6559\n",
      "Columna 105 (alt_106): min=75108.8292, max=297032.6522, mean=156477.3140, std=47371.5691\n",
      "Columna 106 (alt_107): min=76583.6751, max=297298.3498, mean=157005.6593, std=47117.5851\n",
      "Columna 107 (alt_108): min=75911.6216, max=297385.2076, mean=157475.7787, std=46852.3210\n",
      "Columna 108 (alt_109): min=74569.6946, max=297293.0415, mean=157891.7116, std=46578.6215\n",
      "Columna 109 (alt_110): min=73230.3629, max=297022.2192, mean=158257.6974, std=46299.9213\n",
      "Columna 110 (alt_111): min=71468.1470, max=296663.0016, mean=158577.6862, std=46020.0283\n",
      "Columna 111 (alt_112): min=69705.5423, max=296127.4533, mean=158855.6140, std=45743.5387\n",
      "Columna 112 (alt_113): min=67961.9061, max=295406.2783, mean=159095.2355, std=45475.3712\n",
      "Columna 113 (alt_114): min=66236.9331, max=294492.2487, mean=159299.8305, std=45220.7829\n",
      "Columna 114 (alt_115): min=64530.8357, max=293382.1371, mean=159472.3347, std=44984.6937\n",
      "Columna 115 (alt_116): min=62844.8716, max=292573.8267, mean=159615.7783, std=44772.4239\n",
      "Columna 116 (alt_117): min=61178.8730, max=292500.2149, mean=159732.9112, std=44589.4125\n",
      "Columna 117 (alt_118): min=59533.3916, max=292172.4544, mean=159826.3009, std=44440.9379\n",
      "Columna 118 (alt_119): min=57909.7231, max=291586.0755, mean=159898.3889, std=44331.9039\n",
      "Columna 119 (alt_120): min=56307.6488, max=290795.0091, mean=159951.2400, std=44266.6399\n",
      "Columna 120 (alt_121): min=54727.1131, max=289898.5487, mean=159986.9465, std=44249.4572\n",
      "Columna 121 (alt_122): min=53168.1626, max=288886.9894, mean=160007.3351, std=44284.3732\n",
      "Columna 122 (alt_123): min=51630.7989, max=288581.1012, mean=160014.2274, std=44374.8559\n",
      "Columna 123 (alt_124): min=50115.1207, max=288240.2663, mean=160009.1168, std=44523.7888\n",
      "Columna 124 (alt_125): min=48621.1517, max=287859.8974, mean=159993.3463, std=44733.5507\n",
      "Columna 125 (alt_126): min=47148.8958, max=287434.4774, mean=159968.0260, std=45005.9064\n",
      "Columna 126 (alt_127): min=45698.3768, max=286958.2764, mean=159934.1935, std=45341.9382\n",
      "Columna 127 (alt_128): min=44269.6016, max=286424.8821, mean=159892.8145, std=45742.1901\n",
      "Columna 128 (alt_129): min=42862.6018, max=285826.9200, mean=159844.6298, std=46206.6091\n",
      "Columna 129 (alt_130): min=41477.3785, max=285155.4149, mean=159790.3096, std=46734.6942\n",
      "Columna 130 (alt_131): min=40113.9606, max=284400.6296, mean=159730.3996, std=47325.6423\n",
      "Columna 131 (alt_132): min=38772.4614, max=284301.7790, mean=159665.3491, std=47978.2822\n",
      "Columna 132 (alt_133): min=37452.8720, max=284669.9728, mean=159595.5119, std=48691.0865\n",
      "Columna 133 (alt_134): min=36155.2582, max=285020.5574, mean=159521.2954, std=49462.1757\n",
      "Columna 134 (alt_135): min=34879.7204, max=285354.7872, mean=159443.0484, std=50289.5348\n",
      "Columna 135 (alt_136): min=33626.2429, max=285673.8248, mean=159361.2008, std=51170.8979\n",
      "Columna 136 (alt_137): min=32394.8667, max=285978.0170, mean=159276.1781, std=52103.7979\n",
      "Columna 137 (alt_138): min=31185.5916, max=286269.2117, mean=159188.2685, std=53085.7514\n",
      "Columna 138 (alt_139): min=29998.4562, max=286611.3161, mean=159097.9166, std=54114.1470\n",
      "Columna 139 (alt_140): min=28833.5885, max=287050.8911, mean=159005.5322, std=55186.3567\n",
      "Columna 140 (alt_141): min=27690.9876, max=287468.8389, mean=158911.5772, std=56299.6705\n",
      "Columna 141 (alt_142): min=26570.6868, max=287864.3689, mean=158816.5206, std=57451.4198\n",
      "Columna 142 (alt_143): min=25472.7201, max=288240.3182, mean=158720.8582, std=58638.9529\n",
      "Columna 143 (alt_144): min=24397.0833, max=288596.8310, mean=158624.8857, std=59859.8328\n",
      "Columna 144 (alt_145): min=23343.9110, max=288935.1718, mean=158528.7953, std=61111.8159\n",
      "Columna 145 (alt_146): min=22313.2394, max=289257.2306, mean=158432.7728, std=62392.7527\n",
      "Columna 146 (alt_147): min=21305.0769, max=289723.8138, mean=158336.8223, std=63700.7654\n",
      "Columna 147 (alt_148): min=20319.4936, max=290456.7327, mean=158240.8221, std=65034.1534\n",
      "Columna 148 (alt_149): min=19356.4790, max=291155.0653, mean=158144.5452, std=66391.4466\n",
      "Columna 149 (alt_150): min=18416.0927, max=291812.6525, mean=158047.7138, std=67771.2724\n",
      "Columna 150 (alt_151): min=17498.3583, max=292431.0213, mean=157950.0618, std=69172.3041\n",
      "Columna 151 (alt_152): min=16603.2870, max=293013.1926, mean=157851.2904, std=70593.3466\n",
      "Columna 152 (alt_153): min=15731.0429, max=293562.1796, mean=157751.1522, std=72033.2243\n",
      "Columna 153 (alt_154): min=14881.6373, max=294079.4486, mean=157649.4153, std=73490.7952\n",
      "Columna 154 (alt_155): min=14055.0993, max=294560.3927, mean=157545.8814, std=74965.0181\n",
      "Columna 155 (alt_156): min=13251.4984, max=295006.2683, mean=157440.6043, std=76454.6790\n",
      "Columna 156 (alt_157): min=12470.8176, max=295419.2331, mean=157333.6902, std=77958.5651\n",
      "Columna 157 (alt_158): min=11713.1434, max=295801.4384, mean=157225.4567, std=79475.3703\n",
      "Columna 158 (alt_159): min=10978.4796, max=296153.6883, mean=157116.3983, std=81003.7186\n",
      "Columna 159 (alt_160): min=10266.8719, max=296472.7904, mean=157007.1339, std=82542.1700\n",
      "Columna 160 (alt_161): min=9578.4962, max=296759.7205, mean=156898.3522, std=84089.3382\n",
      "Columna 161 (alt_162): min=8913.3292, max=297015.9121, mean=156790.7456, std=85643.8930\n",
      "Columna 162 (alt_163): min=8271.4388, max=297242.7926, mean=156684.8933, std=87204.6433\n",
      "Columna 163 (alt_164): min=7652.8866, max=297438.9141, mean=156581.2129, std=88770.6074\n",
      "Columna 164 (alt_165): min=7057.6598, max=297599.5440, mean=156480.5011, std=90340.4603\n",
      "Columna 165 (alt_166): min=6465.1777, max=297730.0888, mean=156382.7955, std=91913.6068\n",
      "Columna 166 (alt_167): min=5879.5857, max=297836.5549, mean=156288.7574, std=93488.8307\n",
      "Columna 167 (alt_168): min=5321.2072, max=297924.9447, mean=156198.3877, std=95065.6214\n",
      "Columna 168 (alt_169): min=4790.1517, max=297980.4263, mean=156112.1994, std=96642.9763\n",
      "Columna 169 (alt_170): min=4286.4031, max=298001.2976, mean=156030.0568, std=98220.4894\n",
      "Columna 170 (alt_171): min=3810.2461, max=297902.7938, mean=155952.3958, std=99797.2856\n",
      "Columna 171 (alt_172): min=3361.6900, max=297941.0471, mean=155879.2983, std=101372.9154\n",
      "Columna 172 (alt_173): min=2940.7723, max=298314.0479, mean=155810.9070, std=102946.9266\n",
      "Columna 173 (alt_174): min=2547.4887, max=298053.8937, mean=155747.2217, std=104518.7817\n",
      "Columna 174 (alt_175): min=2181.9163, max=298016.1905, mean=155688.4368, std=106088.1721\n",
      "Columna 175 (alt_176): min=1844.0705, max=298101.6756, mean=155634.6505, std=107654.7320\n",
      "Columna 176 (alt_177): min=1533.6131, max=298424.1407, mean=155585.9306, std=109218.1102\n",
      "Columna 177 (alt_178): min=1253.4353, max=297874.1224, mean=155542.2989, std=110777.8923\n",
      "Columna 178 (alt_179): min=999.7567, max=298452.9748, mean=155503.9127, std=112333.8831\n",
      "Columna 179 (alt_180): min=774.4552, max=298285.1815, mean=155470.6743, std=113885.6011\n",
      "Columna 180 (alt_181): min=327.0634, max=298528.3466, mean=155442.7600, std=115432.9352\n",
      "Columna 181 (alt_182): min=120.8329, max=298257.8147, mean=155420.2063, std=116975.6237\n",
      "Columna 182 (alt_183): min=458.1285, max=298448.3598, mean=155403.2101, std=118513.4857\n",
      "Columna 183 (alt_184): min=57.5604, max=298693.6029, mean=155391.7573, std=120046.5909\n",
      "Columna 184 (alt_185): min=50.7088, max=298722.8877, mean=155386.0509, std=121574.6695\n",
      "Columna 185 (alt_186): min=99.7359, max=298608.8499, mean=155386.3454, std=123097.7131\n",
      "Columna 186 (alt_187): min=63.9080, max=298927.0619, mean=155392.7785, std=124615.8157\n",
      "Columna 187 (alt_188): min=28.8089, max=299653.7132, mean=155405.1751, std=126129.0515\n",
      "Columna 188 (alt_189): min=4.2487, max=301196.9568, mean=155424.2164, std=127637.6410\n",
      "Columna 189 (alt_190): min=2.4860, max=302740.5041, mean=155449.7440, std=129140.9521\n",
      "Columna 190 (alt_191): min=1.1410, max=304284.3448, mean=155481.6299, std=130638.6095\n",
      "Columna 191 (alt_192): min=20.1237, max=305828.4687, mean=155519.8200, std=132131.0470\n",
      "Columna 192 (alt_193): min=1.5456, max=307372.8656, mean=155563.1007, std=133617.6012\n",
      "Columna 193 (alt_194): min=1.9890, max=308917.5252, mean=155611.6947, std=135097.8867\n",
      "Columna 194 (alt_195): min=1.7576, max=310462.4373, mean=155663.5090, std=136572.3583\n",
      "Columna 195 (alt_196): min=0.1557, max=312007.5918, mean=155716.4113, std=138045.0720\n",
      "Columna 196 (alt_197): min=0.1949, max=313552.9785, mean=155761.6196, std=139516.3965\n",
      "Columna 197 (alt_198): min=0.0685, max=315098.5871, mean=155805.4322, std=140985.8873\n",
      "Columna 198 (alt_199): min=0.2399, max=316644.4076, mean=155878.3074, std=142469.9979\n",
      "Columna 199 (alt_200): min=0.0000, max=318268.0664, mean=156110.3532, std=143902.0806\n"
     ]
    }
   ],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "def info_dataset(df, name):\n",
    "\tprint(f\"Información Min-Max del dataframe: {name}:{df.shape}\")\t\n",
    "\tfor i, col_name in enumerate(df.columns):\n",
    "\t\tcol = df[col_name]\n",
    "\t\t# si no es numerica la ignoro, como lo hace ella conmigo.\n",
    "\t\tif not is_numeric_dtype(col):\n",
    "\t\t\tprint(f\"Columna {i} ({col_name}) no es numerica, se ignora.\")\n",
    "\t\t\tcontinue\n",
    "\t\tprint(f\"Columna {i} ({col_name}): min={col.min():.4f}, max={col.max():.4f}, mean={col.mean():.4f}, std={col.std():.4f}\")\n",
    "\n",
    "# Gracias a la función pude observar una anomalía en los datos de y_train_z, que puede ser resuelta con un simple preprocesamiento.\n",
    "# Alturas negativas no tienen sentido en este contexto.\n",
    "# info_dataset(y_train_z, \"y_train_z\")\n",
    "# Quitamos del train test xq year no varia, mmdd pasa en forma de sen y cos, hour igualmente\n",
    "def drop_unnecessary_columns(x_train, x_test):\n",
    "\tx_train = x_train.drop(columns = ['year', 'mmdd_modified', 'mmdd','day_of_year', 'hour'])\n",
    "\tx_test = x_test.drop(columns =['year', 'mmdd_modified', 'mmdd','day_of_year', 'hour'])\n",
    "\treturn x_train, x_test\n",
    "x_train, x_test = drop_unnecessary_columns(x_train, x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De toda la Información anterior observo que las columnas como.\n",
    "latitude_pos_tx: -42.28 (valor único y constante)\n",
    "longitude_pos_tx: -63.40 (valor único y constante)\n",
    "elevation_pos_tx: 0.0 (valor único y constante)\n",
    "year: 2010 (valor único y constante)\n",
    "\n",
    "Estas 4 columnas tienen desviacion estándar 0, es decir, no aportan nada al aprendizaje del modelo.\\\n",
    "**Nota**: Los modelos de ML aprenden de las variaciones, y esas columnas no tienen ninguna.\\\n",
    "Procedemos a quitarlos del x_train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información Min-Max del dataframe: y_train_z:(29977, 200)\n",
      "Columna 0 (alt_1): min=-0.0000, max=967.7734, mean=34.5070, std=150.4915\n",
      "Columna 1 (alt_2): min=-214.3333, max=4830.6334, mean=1225.7706, std=669.4825\n",
      "Columna 2 (alt_3): min=-304.1357, max=9675.9811, mean=2502.7084, std=1342.2928\n",
      "Columna 3 (alt_4): min=-303.8887, max=14536.1726, mean=3876.3509, std=1974.0819\n",
      "Columna 4 (alt_5): min=-698.4350, max=19410.9981, mean=5268.3631, std=2575.3265\n",
      "Columna 5 (alt_6): min=-695.3559, max=24300.2182, mean=6661.0787, std=3178.6367\n",
      "Columna 6 (alt_7): min=-699.0836, max=29204.2055, mean=8051.4690, std=3784.5014\n",
      "Columna 7 (alt_8): min=-699.1293, max=34123.0016, mean=9427.6327, std=4417.6419\n",
      "Columna 8 (alt_9): min=25.6304, max=39056.2009, mean=10826.6331, std=5010.7811\n",
      "Columna 9 (alt_10): min=24.3595, max=44004.0823, mean=12223.9242, std=5620.9888\n",
      "Columna 10 (alt_11): min=38.0584, max=48966.7294, mean=13629.0301, std=6229.2046\n",
      "Columna 11 (alt_12): min=27.7157, max=53943.7318, mean=15040.1009, std=6839.9561\n",
      "Columna 12 (alt_13): min=25.4183, max=58935.3140, mean=16457.8944, std=7451.9494\n",
      "Columna 13 (alt_14): min=26.1386, max=63942.2621, mean=17882.3031, std=8065.6748\n",
      "Columna 14 (alt_15): min=112.9496, max=68965.2119, mean=19324.8361, std=8656.4819\n",
      "Columna 15 (alt_16): min=1290.3448, max=74000.0610, mean=20769.7588, std=9258.2551\n",
      "Columna 16 (alt_17): min=1484.0126, max=79050.2883, mean=22221.9959, std=9860.5813\n",
      "Columna 17 (alt_18): min=1693.4918, max=84139.0982, mean=23682.2877, std=10462.0581\n",
      "Columna 18 (alt_19): min=1917.2158, max=89203.1848, mean=25150.6228, std=11062.8419\n",
      "Columna 19 (alt_20): min=2153.9736, max=94166.5332, mean=26627.0045, std=11663.0596\n",
      "Columna 20 (alt_21): min=2404.3389, max=99002.3923, mean=28111.4296, std=12262.8174\n",
      "Columna 21 (alt_22): min=2668.4892, max=103768.3766, mean=29603.8962, std=12862.2170\n",
      "Columna 22 (alt_23): min=2946.4859, max=108524.4116, mean=31104.4058, std=13461.4097\n",
      "Columna 23 (alt_24): min=3238.2033, max=113250.0005, mean=32612.9340, std=14060.4529\n",
      "Columna 24 (alt_25): min=3543.6694, max=117953.0715, mean=34129.4612, std=14659.4083\n",
      "Columna 25 (alt_26): min=3863.0254, max=122662.3930, mean=35653.9496, std=15258.3028\n",
      "Columna 26 (alt_27): min=4196.3092, max=127383.9757, mean=37186.3399, std=15857.0818\n",
      "Columna 27 (alt_28): min=4543.3928, max=132096.7868, mean=38726.5771, std=16455.7107\n",
      "Columna 28 (alt_29): min=4904.3363, max=136779.6057, mean=40274.5938, std=17054.1272\n",
      "Columna 29 (alt_30): min=5279.1864, max=141432.3338, mean=41830.3046, std=17652.2607\n",
      "Columna 30 (alt_31): min=5667.8041, max=146054.7483, mean=43393.6068, std=18250.0374\n",
      "Columna 31 (alt_32): min=6070.2634, max=150640.6145, mean=44964.4139, std=18847.4588\n",
      "Columna 32 (alt_33): min=6486.7067, max=155183.7562, mean=46542.6009, std=19444.4566\n",
      "Columna 33 (alt_34): min=6917.1327, max=159688.6106, mean=48127.9849, std=20040.8807\n",
      "Columna 34 (alt_35): min=7361.4424, max=164163.4302, mean=49720.4375, std=20636.5963\n",
      "Columna 35 (alt_36): min=7819.6680, max=168625.8014, mean=51319.6938, std=21231.3451\n",
      "Columna 36 (alt_37): min=8291.8020, max=173038.6417, mean=52925.4199, std=21824.8179\n",
      "Columna 37 (alt_38): min=8777.7265, max=177348.8989, mean=54537.3300, std=22416.7907\n",
      "Columna 38 (alt_39): min=9277.5559, max=181548.6307, mean=56155.0548, std=23006.9191\n",
      "Columna 39 (alt_40): min=9791.4305, max=185638.6080, mean=57778.1521, std=23594.8022\n",
      "Columna 40 (alt_41): min=10319.2575, max=189608.4605, mean=59406.2142, std=24180.1574\n",
      "Columna 41 (alt_42): min=10861.0155, max=193440.6609, mean=61038.7274, std=24762.5791\n",
      "Columna 42 (alt_43): min=11416.8130, max=197139.4249, mean=62675.1700, std=25341.7765\n",
      "Columna 43 (alt_44): min=11986.6778, max=200712.2153, mean=64315.0153, std=25917.5466\n",
      "Columna 44 (alt_45): min=12570.4993, max=206175.1317, mean=65957.9349, std=26489.8231\n",
      "Columna 45 (alt_46): min=13168.3408, max=212931.8635, mean=67603.3684, std=27058.4870\n",
      "Columna 46 (alt_47): min=13780.2599, max=219634.4110, mean=69250.9355, std=27623.4960\n",
      "Columna 47 (alt_48): min=14406.1555, max=226170.2586, mean=70900.4010, std=28185.0981\n",
      "Columna 48 (alt_49): min=15046.0477, max=232418.8418, mean=72551.7150, std=28743.6158\n",
      "Columna 49 (alt_50): min=15700.0068, max=238300.1186, mean=74204.7123, std=29299.2579\n",
      "Columna 50 (alt_51): min=16367.9684, max=243758.4251, mean=75859.4367, std=29852.4021\n",
      "Columna 51 (alt_52): min=17049.8906, max=248767.6871, mean=77516.1341, std=30403.5487\n",
      "Columna 52 (alt_53): min=17745.9220, max=253325.8318, mean=79175.1369, std=30953.1841\n",
      "Columna 53 (alt_54): min=18456.1573, max=257447.0892, mean=80836.4833, std=31501.4899\n",
      "Columna 54 (alt_55): min=19180.4621, max=261156.5420, mean=82500.2613, std=32048.6658\n",
      "Columna 55 (alt_56): min=19918.8819, max=264485.1372, mean=84166.5434, std=32594.8725\n",
      "Columna 56 (alt_57): min=20671.4884, max=267466.1032, mean=85835.2524, std=33140.1484\n",
      "Columna 57 (alt_58): min=21438.2015, max=270134.2432, mean=87506.2265, std=33684.4934\n",
      "Columna 58 (alt_59): min=22219.0142, max=272522.0034, mean=89179.1647, std=34227.7776\n",
      "Columna 59 (alt_60): min=23014.0017, max=274658.8229, mean=90853.7029, std=34769.8888\n",
      "Columna 60 (alt_61): min=23823.1442, max=276570.9615, mean=92529.3871, std=35310.5556\n",
      "Columna 61 (alt_62): min=24646.3546, max=278281.8021, mean=94205.7440, std=35849.5426\n",
      "Columna 62 (alt_63): min=25483.7748, max=279812.6377, mean=95882.3044, std=36386.4858\n",
      "Columna 63 (alt_64): min=26335.5288, max=281182.9888, mean=97558.6860, std=36921.0664\n",
      "Columna 64 (alt_65): min=27201.5091, max=282410.0932, mean=99234.5372, std=37452.9671\n",
      "Columna 65 (alt_66): min=28081.7115, max=283508.7738, mean=100909.4132, std=37981.8540\n",
      "Columna 66 (alt_67): min=28976.1770, max=284492.7111, mean=102583.0036, std=38507.3264\n",
      "Columna 67 (alt_68): min=29884.8132, max=285373.0084, mean=104255.1323, std=39029.0855\n",
      "Columna 68 (alt_69): min=30807.6238, max=286159.9627, mean=105925.4719, std=39546.7411\n",
      "Columna 69 (alt_70): min=31744.7647, max=286863.0060, mean=107593.6199, std=40059.6776\n",
      "Columna 70 (alt_71): min=32696.3230, max=287490.3117, mean=109259.3303, std=40567.4217\n",
      "Columna 71 (alt_72): min=33662.1763, max=288049.0207, mean=110922.3780, std=41069.5619\n",
      "Columna 72 (alt_73): min=34642.3483, max=288546.5127, mean=112582.4108, std=41565.6123\n",
      "Columna 73 (alt_74): min=35636.8677, max=288988.6199, mean=114238.7826, std=42054.7388\n",
      "Columna 74 (alt_75): min=36645.6294, max=289380.5983, mean=115890.8424, std=42536.0001\n",
      "Columna 75 (alt_76): min=37668.6877, max=289727.3475, mean=117537.8599, std=43008.5086\n",
      "Columna 76 (alt_77): min=38706.1623, max=290033.3018, mean=119179.0620, std=43471.3834\n",
      "Columna 77 (alt_78): min=39758.0278, max=290302.2260, mean=120813.7147, std=43923.6444\n",
      "Columna 78 (alt_79): min=40824.2168, max=290537.7022, mean=122441.0273, std=44364.1953\n",
      "Columna 79 (alt_80): min=41904.8484, max=290743.0611, mean=124060.0281, std=44791.8598\n",
      "Columna 80 (alt_81): min=42999.9936, max=290920.8954, mean=125669.7541, std=45205.4921\n",
      "Columna 81 (alt_82): min=44109.5355, max=291074.5955, mean=127269.1334, std=45603.8650\n",
      "Columna 82 (alt_83): min=45233.5324, max=291206.9030, mean=128857.0334, std=45985.6160\n",
      "Columna 83 (alt_84): min=46372.0615, max=291732.4570, mean=130432.0189, std=46349.2823\n",
      "Columna 84 (alt_85): min=47525.0210, max=292326.7260, mean=131992.6091, std=46693.5287\n",
      "Columna 85 (alt_86): min=48692.4413, max=292871.3901, mean=133537.0999, std=47016.7382\n",
      "Columna 86 (alt_87): min=49874.4452, max=293373.3276, mean=135063.5800, std=47317.2711\n",
      "Columna 87 (alt_88): min=51071.0414, max=293835.9118, mean=136569.7692, std=47593.4891\n",
      "Columna 88 (alt_89): min=52282.1438, max=294253.3142, mean=138053.2015, std=47843.8872\n",
      "Columna 89 (alt_90): min=53507.8318, max=294629.4328, mean=139511.1378, std=48066.6136\n",
      "Columna 90 (alt_91): min=54748.1524, max=294969.0707, mean=140940.7075, std=48260.0621\n",
      "Columna 91 (alt_92): min=56003.0018, max=295340.4596, mean=142338.8869, std=48422.6298\n",
      "Columna 92 (alt_93): min=57272.4431, max=295984.1970, mean=143702.0183, std=48553.2227\n",
      "Columna 93 (alt_94): min=58556.5632, max=296536.3410, mean=145026.1595, std=48650.6264\n",
      "Columna 94 (alt_95): min=59855.2832, max=296992.2323, mean=146307.1926, std=48713.7425\n",
      "Columna 95 (alt_96): min=61168.6058, max=297358.0980, mean=147540.9368, std=48742.1867\n",
      "Columna 96 (alt_97): min=62496.6195, max=297635.2994, mean=148723.0244, std=48735.7836\n",
      "Columna 97 (alt_98): min=63839.3317, max=297821.2591, mean=149848.7999, std=48695.2574\n",
      "Columna 98 (alt_99): min=65196.6682, max=297919.2212, mean=150914.1195, std=48621.7878\n",
      "Columna 99 (alt_100): min=66568.6760, max=297959.7171, mean=151915.1888, std=48517.1300\n",
      "Columna 100 (alt_101): min=67955.3756, max=297945.4884, mean=152848.6329, std=48383.5918\n",
      "Columna 101 (alt_102): min=69356.6776, max=297904.8412, mean=153712.7383, std=48223.8913\n",
      "Columna 102 (alt_103): min=70772.6468, max=297817.6957, mean=154506.7836, std=48040.2714\n",
      "Columna 103 (alt_104): min=72203.3680, max=297598.1362, mean=155230.9935, std=47835.3529\n",
      "Columna 104 (alt_105): min=73648.7586, max=297247.2945, mean=155886.9523, std=47611.6559\n",
      "Columna 105 (alt_106): min=75108.8292, max=297032.6522, mean=156477.3140, std=47371.5691\n",
      "Columna 106 (alt_107): min=76583.6751, max=297298.3498, mean=157005.6593, std=47117.5851\n",
      "Columna 107 (alt_108): min=75911.6216, max=297385.2076, mean=157475.7787, std=46852.3210\n",
      "Columna 108 (alt_109): min=74569.6946, max=297293.0415, mean=157891.7116, std=46578.6215\n",
      "Columna 109 (alt_110): min=73230.3629, max=297022.2192, mean=158257.6974, std=46299.9213\n",
      "Columna 110 (alt_111): min=71468.1470, max=296663.0016, mean=158577.6862, std=46020.0283\n",
      "Columna 111 (alt_112): min=69705.5423, max=296127.4533, mean=158855.6140, std=45743.5387\n",
      "Columna 112 (alt_113): min=67961.9061, max=295406.2783, mean=159095.2355, std=45475.3712\n",
      "Columna 113 (alt_114): min=66236.9331, max=294492.2487, mean=159299.8305, std=45220.7829\n",
      "Columna 114 (alt_115): min=64530.8357, max=293382.1371, mean=159472.3347, std=44984.6937\n",
      "Columna 115 (alt_116): min=62844.8716, max=292573.8267, mean=159615.7783, std=44772.4239\n",
      "Columna 116 (alt_117): min=61178.8730, max=292500.2149, mean=159732.9112, std=44589.4125\n",
      "Columna 117 (alt_118): min=59533.3916, max=292172.4544, mean=159826.3009, std=44440.9379\n",
      "Columna 118 (alt_119): min=57909.7231, max=291586.0755, mean=159898.3889, std=44331.9039\n",
      "Columna 119 (alt_120): min=56307.6488, max=290795.0091, mean=159951.2400, std=44266.6399\n",
      "Columna 120 (alt_121): min=54727.1131, max=289898.5487, mean=159986.9465, std=44249.4572\n",
      "Columna 121 (alt_122): min=53168.1626, max=288886.9894, mean=160007.3351, std=44284.3732\n",
      "Columna 122 (alt_123): min=51630.7989, max=288581.1012, mean=160014.2274, std=44374.8559\n",
      "Columna 123 (alt_124): min=50115.1207, max=288240.2663, mean=160009.1168, std=44523.7888\n",
      "Columna 124 (alt_125): min=48621.1517, max=287859.8974, mean=159993.3463, std=44733.5507\n",
      "Columna 125 (alt_126): min=47148.8958, max=287434.4774, mean=159968.0260, std=45005.9064\n",
      "Columna 126 (alt_127): min=45698.3768, max=286958.2764, mean=159934.1935, std=45341.9382\n",
      "Columna 127 (alt_128): min=44269.6016, max=286424.8821, mean=159892.8145, std=45742.1901\n",
      "Columna 128 (alt_129): min=42862.6018, max=285826.9200, mean=159844.6298, std=46206.6091\n",
      "Columna 129 (alt_130): min=41477.3785, max=285155.4149, mean=159790.3096, std=46734.6942\n",
      "Columna 130 (alt_131): min=40113.9606, max=284400.6296, mean=159730.3996, std=47325.6423\n",
      "Columna 131 (alt_132): min=38772.4614, max=284301.7790, mean=159665.3491, std=47978.2822\n",
      "Columna 132 (alt_133): min=37452.8720, max=284669.9728, mean=159595.5119, std=48691.0865\n",
      "Columna 133 (alt_134): min=36155.2582, max=285020.5574, mean=159521.2954, std=49462.1757\n",
      "Columna 134 (alt_135): min=34879.7204, max=285354.7872, mean=159443.0484, std=50289.5348\n",
      "Columna 135 (alt_136): min=33626.2429, max=285673.8248, mean=159361.2008, std=51170.8979\n",
      "Columna 136 (alt_137): min=32394.8667, max=285978.0170, mean=159276.1781, std=52103.7979\n",
      "Columna 137 (alt_138): min=31185.5916, max=286269.2117, mean=159188.2685, std=53085.7514\n",
      "Columna 138 (alt_139): min=29998.4562, max=286611.3161, mean=159097.9166, std=54114.1470\n",
      "Columna 139 (alt_140): min=28833.5885, max=287050.8911, mean=159005.5322, std=55186.3567\n",
      "Columna 140 (alt_141): min=27690.9876, max=287468.8389, mean=158911.5772, std=56299.6705\n",
      "Columna 141 (alt_142): min=26570.6868, max=287864.3689, mean=158816.5206, std=57451.4198\n",
      "Columna 142 (alt_143): min=25472.7201, max=288240.3182, mean=158720.8582, std=58638.9529\n",
      "Columna 143 (alt_144): min=24397.0833, max=288596.8310, mean=158624.8857, std=59859.8328\n",
      "Columna 144 (alt_145): min=23343.9110, max=288935.1718, mean=158528.7953, std=61111.8159\n",
      "Columna 145 (alt_146): min=22313.2394, max=289257.2306, mean=158432.7728, std=62392.7527\n",
      "Columna 146 (alt_147): min=21305.0769, max=289723.8138, mean=158336.8223, std=63700.7654\n",
      "Columna 147 (alt_148): min=20319.4936, max=290456.7327, mean=158240.8221, std=65034.1534\n",
      "Columna 148 (alt_149): min=19356.4790, max=291155.0653, mean=158144.5452, std=66391.4466\n",
      "Columna 149 (alt_150): min=18416.0927, max=291812.6525, mean=158047.7138, std=67771.2724\n",
      "Columna 150 (alt_151): min=17498.3583, max=292431.0213, mean=157950.0618, std=69172.3041\n",
      "Columna 151 (alt_152): min=16603.2870, max=293013.1926, mean=157851.2904, std=70593.3466\n",
      "Columna 152 (alt_153): min=15731.0429, max=293562.1796, mean=157751.1522, std=72033.2243\n",
      "Columna 153 (alt_154): min=14881.6373, max=294079.4486, mean=157649.4153, std=73490.7952\n",
      "Columna 154 (alt_155): min=14055.0993, max=294560.3927, mean=157545.8814, std=74965.0181\n",
      "Columna 155 (alt_156): min=13251.4984, max=295006.2683, mean=157440.6043, std=76454.6790\n",
      "Columna 156 (alt_157): min=12470.8176, max=295419.2331, mean=157333.6902, std=77958.5651\n",
      "Columna 157 (alt_158): min=11713.1434, max=295801.4384, mean=157225.4567, std=79475.3703\n",
      "Columna 158 (alt_159): min=10978.4796, max=296153.6883, mean=157116.3983, std=81003.7186\n",
      "Columna 159 (alt_160): min=10266.8719, max=296472.7904, mean=157007.1339, std=82542.1700\n",
      "Columna 160 (alt_161): min=9578.4962, max=296759.7205, mean=156898.3522, std=84089.3382\n",
      "Columna 161 (alt_162): min=8913.3292, max=297015.9121, mean=156790.7456, std=85643.8930\n",
      "Columna 162 (alt_163): min=8271.4388, max=297242.7926, mean=156684.8933, std=87204.6433\n",
      "Columna 163 (alt_164): min=7652.8866, max=297438.9141, mean=156581.2129, std=88770.6074\n",
      "Columna 164 (alt_165): min=7057.6598, max=297599.5440, mean=156480.5011, std=90340.4603\n",
      "Columna 165 (alt_166): min=6465.1777, max=297730.0888, mean=156382.7955, std=91913.6068\n",
      "Columna 166 (alt_167): min=5879.5857, max=297836.5549, mean=156288.7574, std=93488.8307\n",
      "Columna 167 (alt_168): min=5321.2072, max=297924.9447, mean=156198.3877, std=95065.6214\n",
      "Columna 168 (alt_169): min=4790.1517, max=297980.4263, mean=156112.1994, std=96642.9763\n",
      "Columna 169 (alt_170): min=4286.4031, max=298001.2976, mean=156030.0568, std=98220.4894\n",
      "Columna 170 (alt_171): min=3810.2461, max=297902.7938, mean=155952.3958, std=99797.2856\n",
      "Columna 171 (alt_172): min=3361.6900, max=297941.0471, mean=155879.2983, std=101372.9154\n",
      "Columna 172 (alt_173): min=2940.7723, max=298314.0479, mean=155810.9070, std=102946.9266\n",
      "Columna 173 (alt_174): min=2547.4887, max=298053.8937, mean=155747.2217, std=104518.7817\n",
      "Columna 174 (alt_175): min=2181.9163, max=298016.1905, mean=155688.4368, std=106088.1721\n",
      "Columna 175 (alt_176): min=1844.0705, max=298101.6756, mean=155634.6505, std=107654.7320\n",
      "Columna 176 (alt_177): min=1533.6131, max=298424.1407, mean=155585.9306, std=109218.1102\n",
      "Columna 177 (alt_178): min=1253.4353, max=297874.1224, mean=155542.2989, std=110777.8923\n",
      "Columna 178 (alt_179): min=999.7567, max=298452.9748, mean=155503.9127, std=112333.8831\n",
      "Columna 179 (alt_180): min=774.4552, max=298285.1815, mean=155470.6743, std=113885.6011\n",
      "Columna 180 (alt_181): min=327.0634, max=298528.3466, mean=155442.7600, std=115432.9352\n",
      "Columna 181 (alt_182): min=120.8329, max=298257.8147, mean=155420.2063, std=116975.6237\n",
      "Columna 182 (alt_183): min=458.1285, max=298448.3598, mean=155403.2101, std=118513.4857\n",
      "Columna 183 (alt_184): min=-84.0433, max=298693.6029, mean=155391.7517, std=120046.5982\n",
      "Columna 184 (alt_185): min=-102.5530, max=298722.8877, mean=155386.0441, std=121574.6782\n",
      "Columna 185 (alt_186): min=99.7359, max=298608.8499, mean=155386.3454, std=123097.7131\n",
      "Columna 186 (alt_187): min=-308.0153, max=298927.0619, mean=155392.7580, std=124615.8413\n",
      "Columna 187 (alt_188): min=-68.2327, max=299653.7132, mean=155405.1706, std=126129.0571\n",
      "Columna 188 (alt_189): min=-291.0451, max=301196.9568, mean=155424.1917, std=127637.6711\n",
      "Columna 189 (alt_190): min=-234.0392, max=302740.5041, mean=155449.7181, std=129140.9833\n",
      "Columna 190 (alt_191): min=-304.7491, max=304284.3448, mean=155481.6048, std=130638.6393\n",
      "Columna 191 (alt_192): min=-198.8502, max=305828.4687, mean=155519.7810, std=132131.0929\n",
      "Columna 192 (alt_193): min=-130.0937, max=307372.8656, mean=155563.0613, std=133617.6471\n",
      "Columna 193 (alt_194): min=-634.2528, max=308917.5252, mean=155611.5552, std=135098.0473\n",
      "Columna 194 (alt_195): min=-928.7129, max=310462.4373, mean=155663.1321, std=136572.7880\n",
      "Columna 195 (alt_196): min=-891.9982, max=312007.5918, mean=155716.0687, std=138045.4585\n",
      "Columna 196 (alt_197): min=-822.3242, max=313552.9785, mean=155761.0045, std=139517.0832\n",
      "Columna 197 (alt_198): min=-982.0160, max=315098.5871, mean=155800.7311, std=140991.0825\n",
      "Columna 198 (alt_199): min=-952.6247, max=316644.4076, mean=155866.5059, std=142482.9094\n",
      "Columna 199 (alt_200): min=-0.0000, max=318268.0664, mean=156110.3532, std=143902.0806\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "cols_to_scale = ['fc', 'elevation','azimuth']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train[cols_to_scale])\n",
    "\n",
    "x_train[cols_to_scale] = scaler.transform(x_train[cols_to_scale])\n",
    "x_test[cols_to_scale] = scaler.transform(x_test[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../NUEVO/scaler_alt.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardamos el scaler para luego\n",
    "import joblib\n",
    "joblib.dump(scaler, '../NUEVO/scaler_alt.pkl')\n",
    "\n",
    "#PARA TRANSOFRMAR NUEVOS DATOS DESPUES\n",
    "# scaler = joblib.load(\"scaler_input.pkl\")\n",
    "# nuevos_scaled = scaler.transform(df_nuevos[cols_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizamos la salida\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_z = MinMaxScaler()\n",
    "scaler_z.fit(y_train_z)\n",
    "y_train_z_scaled = scaler_z.fit_transform(y_train_z)\n",
    "y_test_z_scaled = scaler_z.transform(y_test_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "  monitor = 'val_loss',\t#monitoriamos la pérdida en validación\n",
    "  patience = 30, # Si no mejora en 10->20 epochs, detenemos el entrenamiento.\n",
    "  restore_best_weights = True # Restaura los mejores pesos encontrados.\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "  monitor = 'val_loss',\n",
    "  patience = 20,\n",
    "  factor = 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ z_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ z_output (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m25,700\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,348</span> (270.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m69,348\u001b[0m (270.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,348</span> (270.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m69,348\u001b[0m (270.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 6.1708 - val_loss: 0.4810 - learning_rate: 0.0010\n",
      "Epoch 2/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4397 - val_loss: 0.3700 - learning_rate: 0.0010\n",
      "Epoch 3/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3619 - val_loss: 0.3533 - learning_rate: 0.0010\n",
      "Epoch 4/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3273 - val_loss: 0.2922 - learning_rate: 0.0010\n",
      "Epoch 5/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2981 - val_loss: 0.2727 - learning_rate: 0.0010\n",
      "Epoch 6/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2854 - val_loss: 0.2955 - learning_rate: 0.0010\n",
      "Epoch 7/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2791 - val_loss: 0.2764 - learning_rate: 0.0010\n",
      "Epoch 8/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2619 - val_loss: 0.2457 - learning_rate: 0.0010\n",
      "Epoch 9/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2559 - val_loss: 0.2515 - learning_rate: 0.0010\n",
      "Epoch 10/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2495 - val_loss: 0.2220 - learning_rate: 0.0010\n",
      "Epoch 11/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2288 - val_loss: 0.2424 - learning_rate: 0.0010\n",
      "Epoch 12/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2481 - val_loss: 0.2198 - learning_rate: 0.0010\n",
      "Epoch 13/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2357 - val_loss: 0.2352 - learning_rate: 0.0010\n",
      "Epoch 14/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2305 - val_loss: 0.2159 - learning_rate: 0.0010\n",
      "Epoch 15/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2118 - val_loss: 0.2024 - learning_rate: 0.0010\n",
      "Epoch 16/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2043 - val_loss: 0.2048 - learning_rate: 0.0010\n",
      "Epoch 17/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2089 - val_loss: 0.1979 - learning_rate: 0.0010\n",
      "Epoch 18/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2125 - val_loss: 0.1970 - learning_rate: 0.0010\n",
      "Epoch 19/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2035 - val_loss: 0.2073 - learning_rate: 0.0010\n",
      "Epoch 20/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2056 - val_loss: 0.1903 - learning_rate: 0.0010\n",
      "Epoch 21/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1996 - val_loss: 0.2193 - learning_rate: 0.0010\n",
      "Epoch 22/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1986 - val_loss: 0.1920 - learning_rate: 0.0010\n",
      "Epoch 23/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1895 - val_loss: 0.2018 - learning_rate: 0.0010\n",
      "Epoch 24/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1897 - val_loss: 0.1883 - learning_rate: 0.0010\n",
      "Epoch 25/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1907 - val_loss: 0.1821 - learning_rate: 0.0010\n",
      "Epoch 26/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1808 - val_loss: 0.1753 - learning_rate: 0.0010\n",
      "Epoch 27/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1807 - val_loss: 0.1743 - learning_rate: 0.0010\n",
      "Epoch 28/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1814 - val_loss: 0.1856 - learning_rate: 0.0010\n",
      "Epoch 29/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1784 - val_loss: 0.1686 - learning_rate: 0.0010\n",
      "Epoch 30/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1693 - val_loss: 0.1716 - learning_rate: 0.0010\n",
      "Epoch 31/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1726 - val_loss: 0.1722 - learning_rate: 0.0010\n",
      "Epoch 32/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1691 - val_loss: 0.1739 - learning_rate: 0.0010\n",
      "Epoch 33/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1678 - val_loss: 0.1667 - learning_rate: 0.0010\n",
      "Epoch 34/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1739 - val_loss: 0.1599 - learning_rate: 0.0010\n",
      "Epoch 35/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1592 - val_loss: 0.1654 - learning_rate: 0.0010\n",
      "Epoch 36/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1699 - val_loss: 0.1665 - learning_rate: 0.0010\n",
      "Epoch 37/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1640 - val_loss: 0.1581 - learning_rate: 0.0010\n",
      "Epoch 38/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1557 - val_loss: 0.1769 - learning_rate: 0.0010\n",
      "Epoch 39/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1641 - val_loss: 0.1588 - learning_rate: 0.0010\n",
      "Epoch 40/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1630 - val_loss: 0.1539 - learning_rate: 0.0010\n",
      "Epoch 41/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1534 - val_loss: 0.1524 - learning_rate: 0.0010\n",
      "Epoch 42/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1543 - val_loss: 0.1471 - learning_rate: 0.0010\n",
      "Epoch 43/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1496 - val_loss: 0.1590 - learning_rate: 0.0010\n",
      "Epoch 44/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1509 - val_loss: 0.1701 - learning_rate: 0.0010\n",
      "Epoch 45/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1536 - val_loss: 0.1562 - learning_rate: 0.0010\n",
      "Epoch 46/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1479 - val_loss: 0.1479 - learning_rate: 0.0010\n",
      "Epoch 47/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1443 - val_loss: 0.1404 - learning_rate: 0.0010\n",
      "Epoch 48/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1423 - val_loss: 0.1348 - learning_rate: 0.0010\n",
      "Epoch 49/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1382 - val_loss: 0.1406 - learning_rate: 0.0010\n",
      "Epoch 50/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1423 - val_loss: 0.1495 - learning_rate: 0.0010\n",
      "Epoch 51/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1435 - val_loss: 0.1308 - learning_rate: 0.0010\n",
      "Epoch 52/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1332 - val_loss: 0.1413 - learning_rate: 0.0010\n",
      "Epoch 53/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1337 - val_loss: 0.1358 - learning_rate: 0.0010\n",
      "Epoch 54/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1309 - val_loss: 0.1417 - learning_rate: 0.0010\n",
      "Epoch 55/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1301 - val_loss: 0.1288 - learning_rate: 0.0010\n",
      "Epoch 56/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1295 - val_loss: 0.1254 - learning_rate: 0.0010\n",
      "Epoch 57/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1238 - val_loss: 0.1287 - learning_rate: 0.0010\n",
      "Epoch 58/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1251 - val_loss: 0.1187 - learning_rate: 0.0010\n",
      "Epoch 59/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1230 - val_loss: 0.1181 - learning_rate: 0.0010\n",
      "Epoch 60/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1186 - val_loss: 0.1202 - learning_rate: 0.0010\n",
      "Epoch 61/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1217 - val_loss: 0.1190 - learning_rate: 0.0010\n",
      "Epoch 62/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1203 - val_loss: 0.1189 - learning_rate: 0.0010\n",
      "Epoch 63/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1182 - val_loss: 0.1129 - learning_rate: 0.0010\n",
      "Epoch 64/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1129 - val_loss: 0.1225 - learning_rate: 0.0010\n",
      "Epoch 65/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1188 - val_loss: 0.1117 - learning_rate: 0.0010\n",
      "Epoch 66/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1112 - val_loss: 0.1131 - learning_rate: 0.0010\n",
      "Epoch 67/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1136 - val_loss: 0.1120 - learning_rate: 0.0010\n",
      "Epoch 68/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1132 - val_loss: 0.1095 - learning_rate: 0.0010\n",
      "Epoch 69/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1113 - val_loss: 0.1039 - learning_rate: 0.0010\n",
      "Epoch 70/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1065 - val_loss: 0.1091 - learning_rate: 0.0010\n",
      "Epoch 71/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1105 - val_loss: 0.0997 - learning_rate: 0.0010\n",
      "Epoch 72/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1041 - val_loss: 0.1009 - learning_rate: 0.0010\n",
      "Epoch 73/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1038 - val_loss: 0.1137 - learning_rate: 0.0010\n",
      "Epoch 74/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1067 - val_loss: 0.1028 - learning_rate: 0.0010\n",
      "Epoch 75/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1019 - val_loss: 0.1007 - learning_rate: 0.0010\n",
      "Epoch 76/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0990 - val_loss: 0.1020 - learning_rate: 0.0010\n",
      "Epoch 77/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1022 - val_loss: 0.1103 - learning_rate: 0.0010\n",
      "Epoch 78/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1005 - val_loss: 0.0969 - learning_rate: 0.0010\n",
      "Epoch 79/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0982 - val_loss: 0.0918 - learning_rate: 0.0010\n",
      "Epoch 80/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0937 - val_loss: 0.0954 - learning_rate: 0.0010\n",
      "Epoch 81/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0934 - val_loss: 0.1051 - learning_rate: 0.0010\n",
      "Epoch 82/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0950 - val_loss: 0.0934 - learning_rate: 0.0010\n",
      "Epoch 83/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0943 - val_loss: 0.0931 - learning_rate: 0.0010\n",
      "Epoch 84/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0933 - val_loss: 0.1071 - learning_rate: 0.0010\n",
      "Epoch 85/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1026 - val_loss: 0.0903 - learning_rate: 0.0010\n",
      "Epoch 86/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0924 - val_loss: 0.0940 - learning_rate: 0.0010\n",
      "Epoch 87/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0893 - val_loss: 0.1003 - learning_rate: 0.0010\n",
      "Epoch 88/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0915 - val_loss: 0.0877 - learning_rate: 0.0010\n",
      "Epoch 89/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0877 - val_loss: 0.0870 - learning_rate: 0.0010\n",
      "Epoch 90/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0859 - val_loss: 0.1076 - learning_rate: 0.0010\n",
      "Epoch 91/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0946 - val_loss: 0.0903 - learning_rate: 0.0010\n",
      "Epoch 92/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0893 - val_loss: 0.0889 - learning_rate: 0.0010\n",
      "Epoch 93/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0849 - val_loss: 0.0864 - learning_rate: 0.0010\n",
      "Epoch 94/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0838 - val_loss: 0.0910 - learning_rate: 0.0010\n",
      "Epoch 95/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0821 - val_loss: 0.0900 - learning_rate: 0.0010\n",
      "Epoch 96/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0830 - val_loss: 0.0873 - learning_rate: 0.0010\n",
      "Epoch 97/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0861 - val_loss: 0.0909 - learning_rate: 0.0010\n",
      "Epoch 98/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0858 - val_loss: 0.0851 - learning_rate: 0.0010\n",
      "Epoch 99/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0827 - val_loss: 0.0818 - learning_rate: 0.0010\n",
      "Epoch 100/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0812 - val_loss: 0.0831 - learning_rate: 0.0010\n",
      "Epoch 101/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0814 - val_loss: 0.0770 - learning_rate: 0.0010\n",
      "Epoch 102/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0788 - val_loss: 0.0810 - learning_rate: 0.0010\n",
      "Epoch 103/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0806 - val_loss: 0.0826 - learning_rate: 0.0010\n",
      "Epoch 104/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0818 - val_loss: 0.0802 - learning_rate: 0.0010\n",
      "Epoch 105/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0777 - val_loss: 0.0844 - learning_rate: 0.0010\n",
      "Epoch 106/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0795 - val_loss: 0.0777 - learning_rate: 0.0010\n",
      "Epoch 107/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0748 - val_loss: 0.0708 - learning_rate: 0.0010\n",
      "Epoch 108/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0751 - val_loss: 0.0735 - learning_rate: 0.0010\n",
      "Epoch 109/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0735 - val_loss: 0.0822 - learning_rate: 0.0010\n",
      "Epoch 110/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0738 - val_loss: 0.0775 - learning_rate: 0.0010\n",
      "Epoch 111/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0750 - val_loss: 0.0788 - learning_rate: 0.0010\n",
      "Epoch 112/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0780 - val_loss: 0.0746 - learning_rate: 0.0010\n",
      "Epoch 113/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0729 - val_loss: 0.0725 - learning_rate: 0.0010\n",
      "Epoch 114/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0714 - val_loss: 0.0807 - learning_rate: 0.0010\n",
      "Epoch 115/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0736 - val_loss: 0.0719 - learning_rate: 0.0010\n",
      "Epoch 116/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0720 - val_loss: 0.0747 - learning_rate: 0.0010\n",
      "Epoch 117/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0736 - val_loss: 0.0809 - learning_rate: 0.0010\n",
      "Epoch 118/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0710 - val_loss: 0.0745 - learning_rate: 0.0010\n",
      "Epoch 119/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0706 - val_loss: 0.0784 - learning_rate: 0.0010\n",
      "Epoch 120/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0729 - val_loss: 0.0707 - learning_rate: 0.0010\n",
      "Epoch 121/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0694 - val_loss: 0.0694 - learning_rate: 0.0010\n",
      "Epoch 122/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0681 - val_loss: 0.0692 - learning_rate: 0.0010\n",
      "Epoch 123/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0741 - val_loss: 0.0813 - learning_rate: 0.0010\n",
      "Epoch 124/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0721 - val_loss: 0.0720 - learning_rate: 0.0010\n",
      "Epoch 125/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0644 - val_loss: 0.0792 - learning_rate: 0.0010\n",
      "Epoch 126/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0744 - val_loss: 0.0732 - learning_rate: 0.0010\n",
      "Epoch 127/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0674 - val_loss: 0.0683 - learning_rate: 0.0010\n",
      "Epoch 128/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0676 - val_loss: 0.0676 - learning_rate: 0.0010\n",
      "Epoch 129/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0698 - val_loss: 0.0724 - learning_rate: 0.0010\n",
      "Epoch 130/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0669 - val_loss: 0.0655 - learning_rate: 0.0010\n",
      "Epoch 131/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0681 - val_loss: 0.0672 - learning_rate: 0.0010\n",
      "Epoch 132/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0672 - val_loss: 0.0854 - learning_rate: 0.0010\n",
      "Epoch 133/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0691 - val_loss: 0.0698 - learning_rate: 0.0010\n",
      "Epoch 134/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0656 - val_loss: 0.0738 - learning_rate: 0.0010\n",
      "Epoch 135/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0657 - val_loss: 0.0602 - learning_rate: 0.0010\n",
      "Epoch 136/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0620 - val_loss: 0.0600 - learning_rate: 0.0010\n",
      "Epoch 137/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0609 - val_loss: 0.0696 - learning_rate: 0.0010\n",
      "Epoch 138/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0658 - val_loss: 0.0772 - learning_rate: 0.0010\n",
      "Epoch 139/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0689 - val_loss: 0.0577 - learning_rate: 0.0010\n",
      "Epoch 140/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0609 - val_loss: 0.0680 - learning_rate: 0.0010\n",
      "Epoch 141/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0656 - val_loss: 0.0592 - learning_rate: 0.0010\n",
      "Epoch 142/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0629 - val_loss: 0.0664 - learning_rate: 0.0010\n",
      "Epoch 143/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0643 - val_loss: 0.0596 - learning_rate: 0.0010\n",
      "Epoch 144/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0619 - val_loss: 0.0611 - learning_rate: 0.0010\n",
      "Epoch 145/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0665 - val_loss: 0.0653 - learning_rate: 0.0010\n",
      "Epoch 146/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0642 - val_loss: 0.0590 - learning_rate: 0.0010\n",
      "Epoch 147/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0594 - val_loss: 0.0708 - learning_rate: 0.0010\n",
      "Epoch 148/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0619 - val_loss: 0.0587 - learning_rate: 0.0010\n",
      "Epoch 149/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0591 - val_loss: 0.0682 - learning_rate: 0.0010\n",
      "Epoch 150/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0652 - val_loss: 0.0608 - learning_rate: 0.0010\n",
      "Epoch 151/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0603 - val_loss: 0.0645 - learning_rate: 0.0010\n",
      "Epoch 152/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0608 - val_loss: 0.0688 - learning_rate: 0.0010\n",
      "Epoch 153/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0612 - val_loss: 0.0617 - learning_rate: 0.0010\n",
      "Epoch 154/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0590 - val_loss: 0.0616 - learning_rate: 0.0010\n",
      "Epoch 155/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0599 - val_loss: 0.0575 - learning_rate: 0.0010\n",
      "Epoch 156/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0615 - val_loss: 0.0576 - learning_rate: 0.0010\n",
      "Epoch 157/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0622 - val_loss: 0.0601 - learning_rate: 0.0010\n",
      "Epoch 158/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0584 - val_loss: 0.0565 - learning_rate: 0.0010\n",
      "Epoch 159/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0584 - val_loss: 0.0686 - learning_rate: 0.0010\n",
      "Epoch 160/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0580 - val_loss: 0.0558 - learning_rate: 0.0010\n",
      "Epoch 161/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0580 - val_loss: 0.0613 - learning_rate: 0.0010\n",
      "Epoch 162/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0590 - val_loss: 0.0600 - learning_rate: 0.0010\n",
      "Epoch 163/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0574 - val_loss: 0.0602 - learning_rate: 0.0010\n",
      "Epoch 164/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0579 - val_loss: 0.0628 - learning_rate: 0.0010\n",
      "Epoch 165/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0615 - learning_rate: 0.0010\n",
      "Epoch 166/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0555 - learning_rate: 0.0010\n",
      "Epoch 167/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0566 - val_loss: 0.0638 - learning_rate: 0.0010\n",
      "Epoch 168/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0585 - val_loss: 0.0615 - learning_rate: 0.0010\n",
      "Epoch 169/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0576 - val_loss: 0.0534 - learning_rate: 0.0010\n",
      "Epoch 170/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0593 - val_loss: 0.0647 - learning_rate: 0.0010\n",
      "Epoch 171/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0647 - val_loss: 0.0701 - learning_rate: 0.0010\n",
      "Epoch 172/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0635 - val_loss: 0.0536 - learning_rate: 0.0010\n",
      "Epoch 173/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0546 - val_loss: 0.0561 - learning_rate: 0.0010\n",
      "Epoch 174/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0541 - val_loss: 0.0538 - learning_rate: 0.0010\n",
      "Epoch 175/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0550 - val_loss: 0.0593 - learning_rate: 0.0010\n",
      "Epoch 176/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0572 - val_loss: 0.0573 - learning_rate: 0.0010\n",
      "Epoch 177/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0561 - val_loss: 0.0523 - learning_rate: 0.0010\n",
      "Epoch 178/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0538 - val_loss: 0.0520 - learning_rate: 0.0010\n",
      "Epoch 179/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0585 - val_loss: 0.0541 - learning_rate: 0.0010\n",
      "Epoch 180/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0557 - val_loss: 0.0545 - learning_rate: 0.0010\n",
      "Epoch 181/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0544 - val_loss: 0.0555 - learning_rate: 0.0010\n",
      "Epoch 182/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0536 - val_loss: 0.0641 - learning_rate: 0.0010\n",
      "Epoch 183/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0582 - val_loss: 0.0527 - learning_rate: 0.0010\n",
      "Epoch 184/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0551 - val_loss: 0.0541 - learning_rate: 0.0010\n",
      "Epoch 185/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0540 - val_loss: 0.0567 - learning_rate: 0.0010\n",
      "Epoch 186/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0543 - val_loss: 0.0513 - learning_rate: 0.0010\n",
      "Epoch 187/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0523 - val_loss: 0.0623 - learning_rate: 0.0010\n",
      "Epoch 188/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0564 - val_loss: 0.0552 - learning_rate: 0.0010\n",
      "Epoch 189/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0596 - val_loss: 0.0521 - learning_rate: 0.0010\n",
      "Epoch 190/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0539 - val_loss: 0.0553 - learning_rate: 0.0010\n",
      "Epoch 191/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0531 - val_loss: 0.0534 - learning_rate: 0.0010\n",
      "Epoch 192/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0546 - val_loss: 0.0503 - learning_rate: 0.0010\n",
      "Epoch 193/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0543 - val_loss: 0.0541 - learning_rate: 0.0010\n",
      "Epoch 194/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0536 - val_loss: 0.0569 - learning_rate: 0.0010\n",
      "Epoch 195/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0530 - val_loss: 0.0512 - learning_rate: 0.0010\n",
      "Epoch 196/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0524 - val_loss: 0.0545 - learning_rate: 0.0010\n",
      "Epoch 197/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0522 - val_loss: 0.0540 - learning_rate: 0.0010\n",
      "Epoch 198/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0519 - val_loss: 0.0569 - learning_rate: 0.0010\n",
      "Epoch 199/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0526 - val_loss: 0.0506 - learning_rate: 0.0010\n",
      "Epoch 200/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0497 - val_loss: 0.0499 - learning_rate: 0.0010\n",
      "Epoch 201/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0515 - val_loss: 0.0506 - learning_rate: 0.0010\n",
      "Epoch 202/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0516 - val_loss: 0.0488 - learning_rate: 0.0010\n",
      "Epoch 203/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0523 - val_loss: 0.0475 - learning_rate: 0.0010\n",
      "Epoch 204/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0524 - val_loss: 0.0536 - learning_rate: 0.0010\n",
      "Epoch 205/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0522 - val_loss: 0.0634 - learning_rate: 0.0010\n",
      "Epoch 206/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0644 - val_loss: 0.0538 - learning_rate: 0.0010\n",
      "Epoch 207/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0524 - val_loss: 0.0525 - learning_rate: 0.0010\n",
      "Epoch 208/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0514 - val_loss: 0.0595 - learning_rate: 0.0010\n",
      "Epoch 209/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0545 - val_loss: 0.0572 - learning_rate: 0.0010\n",
      "Epoch 210/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0578 - val_loss: 0.0522 - learning_rate: 0.0010\n",
      "Epoch 211/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0492 - val_loss: 0.0492 - learning_rate: 0.0010\n",
      "Epoch 212/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0501 - val_loss: 0.0559 - learning_rate: 0.0010\n",
      "Epoch 213/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0501 - val_loss: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 214/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0478 - val_loss: 0.0522 - learning_rate: 0.0010\n",
      "Epoch 215/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0525 - val_loss: 0.0632 - learning_rate: 0.0010\n",
      "Epoch 216/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0571 - val_loss: 0.0546 - learning_rate: 0.0010\n",
      "Epoch 217/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0517 - val_loss: 0.0471 - learning_rate: 0.0010\n",
      "Epoch 218/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0497 - val_loss: 0.0479 - learning_rate: 0.0010\n",
      "Epoch 219/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0502 - val_loss: 0.0646 - learning_rate: 0.0010\n",
      "Epoch 220/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0545 - val_loss: 0.0654 - learning_rate: 0.0010\n",
      "Epoch 221/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0523 - val_loss: 0.0506 - learning_rate: 0.0010\n",
      "Epoch 222/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0501 - val_loss: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 223/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0489 - val_loss: 0.0510 - learning_rate: 0.0010\n",
      "Epoch 224/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0490 - val_loss: 0.0522 - learning_rate: 0.0010\n",
      "Epoch 225/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0524 - val_loss: 0.0510 - learning_rate: 0.0010\n",
      "Epoch 226/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0479 - val_loss: 0.0479 - learning_rate: 0.0010\n",
      "Epoch 227/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0487 - val_loss: 0.0554 - learning_rate: 0.0010\n",
      "Epoch 228/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0502 - val_loss: 0.0488 - learning_rate: 0.0010\n",
      "Epoch 229/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0477 - val_loss: 0.0482 - learning_rate: 0.0010\n",
      "Epoch 230/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0482 - val_loss: 0.0506 - learning_rate: 0.0010\n",
      "Epoch 231/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0516 - val_loss: 0.0617 - learning_rate: 0.0010\n",
      "Epoch 232/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0528 - val_loss: 0.0516 - learning_rate: 0.0010\n",
      "Epoch 233/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0495 - val_loss: 0.0458 - learning_rate: 0.0010\n",
      "Epoch 234/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0472 - val_loss: 0.0542 - learning_rate: 0.0010\n",
      "Epoch 235/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0495 - val_loss: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 236/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0490 - val_loss: 0.0471 - learning_rate: 0.0010\n",
      "Epoch 237/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0471 - val_loss: 0.0483 - learning_rate: 0.0010\n",
      "Epoch 238/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0469 - val_loss: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 239/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0487 - val_loss: 0.0527 - learning_rate: 0.0010\n",
      "Epoch 240/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0511 - val_loss: 0.0538 - learning_rate: 0.0010\n",
      "Epoch 241/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0479 - val_loss: 0.0578 - learning_rate: 0.0010\n",
      "Epoch 242/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0509 - val_loss: 0.0445 - learning_rate: 0.0010\n",
      "Epoch 243/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0454 - val_loss: 0.0521 - learning_rate: 0.0010\n",
      "Epoch 244/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0493 - val_loss: 0.0511 - learning_rate: 0.0010\n",
      "Epoch 245/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0499 - val_loss: 0.0521 - learning_rate: 0.0010\n",
      "Epoch 246/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0458 - val_loss: 0.0446 - learning_rate: 0.0010\n",
      "Epoch 247/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0457 - val_loss: 0.0651 - learning_rate: 0.0010\n",
      "Epoch 248/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0514 - val_loss: 0.0568 - learning_rate: 0.0010\n",
      "Epoch 249/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0496 - val_loss: 0.0460 - learning_rate: 0.0010\n",
      "Epoch 250/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0458 - val_loss: 0.0569 - learning_rate: 0.0010\n",
      "Epoch 251/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0532 - val_loss: 0.0495 - learning_rate: 0.0010\n",
      "Epoch 252/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0493 - val_loss: 0.0488 - learning_rate: 0.0010\n",
      "Epoch 253/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0481 - val_loss: 0.0524 - learning_rate: 0.0010\n",
      "Epoch 254/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0465 - val_loss: 0.0443 - learning_rate: 0.0010\n",
      "Epoch 255/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0482 - val_loss: 0.0504 - learning_rate: 0.0010\n",
      "Epoch 256/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0477 - val_loss: 0.0455 - learning_rate: 0.0010\n",
      "Epoch 257/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0441 - val_loss: 0.0462 - learning_rate: 0.0010\n",
      "Epoch 258/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0472 - val_loss: 0.0462 - learning_rate: 0.0010\n",
      "Epoch 259/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0454 - val_loss: 0.0449 - learning_rate: 0.0010\n",
      "Epoch 260/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0446 - val_loss: 0.0473 - learning_rate: 0.0010\n",
      "Epoch 261/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0473 - val_loss: 0.0643 - learning_rate: 0.0010\n",
      "Epoch 262/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0525 - val_loss: 0.0465 - learning_rate: 0.0010\n",
      "Epoch 263/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0467 - val_loss: 0.0459 - learning_rate: 0.0010\n",
      "Epoch 264/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0470 - val_loss: 0.0441 - learning_rate: 0.0010\n",
      "Epoch 265/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0444 - val_loss: 0.0507 - learning_rate: 0.0010\n",
      "Epoch 266/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0469 - val_loss: 0.0450 - learning_rate: 0.0010\n",
      "Epoch 267/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0439 - val_loss: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 268/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0460 - val_loss: 0.0462 - learning_rate: 0.0010\n",
      "Epoch 269/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0464 - val_loss: 0.0444 - learning_rate: 0.0010\n",
      "Epoch 270/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0472 - val_loss: 0.0465 - learning_rate: 0.0010\n",
      "Epoch 271/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0447 - val_loss: 0.0442 - learning_rate: 0.0010\n",
      "Epoch 272/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0452 - val_loss: 0.0482 - learning_rate: 0.0010\n",
      "Epoch 273/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0464 - val_loss: 0.0493 - learning_rate: 0.0010\n",
      "Epoch 274/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0461 - val_loss: 0.0531 - learning_rate: 0.0010\n",
      "Epoch 275/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0462 - val_loss: 0.0445 - learning_rate: 0.0010\n",
      "Epoch 276/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0460 - val_loss: 0.0468 - learning_rate: 0.0010\n",
      "Epoch 277/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0459 - val_loss: 0.0482 - learning_rate: 0.0010\n",
      "Epoch 278/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0484 - val_loss: 0.0485 - learning_rate: 0.0010\n",
      "Epoch 279/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0454 - val_loss: 0.0459 - learning_rate: 0.0010\n",
      "Epoch 280/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0485 - val_loss: 0.0468 - learning_rate: 0.0010\n",
      "Epoch 281/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0456 - val_loss: 0.0475 - learning_rate: 0.0010\n",
      "Epoch 282/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0444 - val_loss: 0.0445 - learning_rate: 0.0010\n",
      "Epoch 283/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0468 - val_loss: 0.0478 - learning_rate: 0.0010\n",
      "Epoch 284/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0468 - val_loss: 0.0496 - learning_rate: 0.0010\n",
      "Epoch 285/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0449 - val_loss: 0.0425 - learning_rate: 5.0000e-04\n",
      "Epoch 286/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0411 - val_loss: 0.0436 - learning_rate: 5.0000e-04\n",
      "Epoch 287/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0421 - val_loss: 0.0443 - learning_rate: 5.0000e-04\n",
      "Epoch 288/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0454 - val_loss: 0.0433 - learning_rate: 5.0000e-04\n",
      "Epoch 289/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0405 - val_loss: 0.0420 - learning_rate: 5.0000e-04\n",
      "Epoch 290/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0415 - val_loss: 0.0426 - learning_rate: 5.0000e-04\n",
      "Epoch 291/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0419 - val_loss: 0.0429 - learning_rate: 5.0000e-04\n",
      "Epoch 292/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0408 - val_loss: 0.0444 - learning_rate: 5.0000e-04\n",
      "Epoch 293/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0406 - val_loss: 0.0434 - learning_rate: 5.0000e-04\n",
      "Epoch 294/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0435 - val_loss: 0.0420 - learning_rate: 5.0000e-04\n",
      "Epoch 295/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0407 - val_loss: 0.0434 - learning_rate: 5.0000e-04\n",
      "Epoch 296/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0406 - val_loss: 0.0420 - learning_rate: 5.0000e-04\n",
      "Epoch 297/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0405 - val_loss: 0.0412 - learning_rate: 5.0000e-04\n",
      "Epoch 298/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0410 - val_loss: 0.0419 - learning_rate: 5.0000e-04\n",
      "Epoch 299/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0413 - val_loss: 0.0414 - learning_rate: 5.0000e-04\n",
      "Epoch 300/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0406 - val_loss: 0.0424 - learning_rate: 5.0000e-04\n",
      "Epoch 301/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0421 - val_loss: 0.0422 - learning_rate: 5.0000e-04\n",
      "Epoch 302/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0434 - val_loss: 0.0411 - learning_rate: 5.0000e-04\n",
      "Epoch 303/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0411 - val_loss: 0.0432 - learning_rate: 5.0000e-04\n",
      "Epoch 304/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0406 - val_loss: 0.0399 - learning_rate: 5.0000e-04\n",
      "Epoch 305/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0399 - val_loss: 0.0427 - learning_rate: 5.0000e-04\n",
      "Epoch 306/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0420 - val_loss: 0.0408 - learning_rate: 5.0000e-04\n",
      "Epoch 307/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0398 - val_loss: 0.0430 - learning_rate: 5.0000e-04\n",
      "Epoch 308/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0409 - val_loss: 0.0435 - learning_rate: 5.0000e-04\n",
      "Epoch 309/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0424 - val_loss: 0.0421 - learning_rate: 5.0000e-04\n",
      "Epoch 310/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0450 - val_loss: 0.0410 - learning_rate: 5.0000e-04\n",
      "Epoch 311/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0396 - val_loss: 0.0418 - learning_rate: 5.0000e-04\n",
      "Epoch 312/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0408 - val_loss: 0.0414 - learning_rate: 5.0000e-04\n",
      "Epoch 313/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0411 - val_loss: 0.0438 - learning_rate: 5.0000e-04\n",
      "Epoch 314/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0397 - val_loss: 0.0423 - learning_rate: 5.0000e-04\n",
      "Epoch 315/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0401 - val_loss: 0.0410 - learning_rate: 5.0000e-04\n",
      "Epoch 316/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0399 - val_loss: 0.0415 - learning_rate: 5.0000e-04\n",
      "Epoch 317/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0399 - val_loss: 0.0394 - learning_rate: 5.0000e-04\n",
      "Epoch 318/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0403 - val_loss: 0.0414 - learning_rate: 5.0000e-04\n",
      "Epoch 319/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0399 - val_loss: 0.0454 - learning_rate: 5.0000e-04\n",
      "Epoch 320/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0422 - val_loss: 0.0426 - learning_rate: 5.0000e-04\n",
      "Epoch 321/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0437 - val_loss: 0.0404 - learning_rate: 5.0000e-04\n",
      "Epoch 322/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0410 - val_loss: 0.0416 - learning_rate: 5.0000e-04\n",
      "Epoch 323/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0406 - val_loss: 0.0433 - learning_rate: 5.0000e-04\n",
      "Epoch 324/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0409 - val_loss: 0.0410 - learning_rate: 5.0000e-04\n",
      "Epoch 325/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0418 - val_loss: 0.0412 - learning_rate: 5.0000e-04\n",
      "Epoch 326/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0395 - val_loss: 0.0406 - learning_rate: 5.0000e-04\n",
      "Epoch 327/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0421 - val_loss: 0.0405 - learning_rate: 5.0000e-04\n",
      "Epoch 328/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0396 - val_loss: 0.0419 - learning_rate: 5.0000e-04\n",
      "Epoch 329/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0404 - val_loss: 0.0467 - learning_rate: 5.0000e-04\n",
      "Epoch 330/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0413 - val_loss: 0.0444 - learning_rate: 5.0000e-04\n",
      "Epoch 331/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0398 - val_loss: 0.0402 - learning_rate: 5.0000e-04\n",
      "Epoch 332/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0410 - val_loss: 0.0412 - learning_rate: 5.0000e-04\n",
      "Epoch 333/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0387 - val_loss: 0.0388 - learning_rate: 5.0000e-04\n",
      "Epoch 334/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0396 - val_loss: 0.0406 - learning_rate: 5.0000e-04\n",
      "Epoch 335/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0397 - val_loss: 0.0421 - learning_rate: 5.0000e-04\n",
      "Epoch 336/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0402 - val_loss: 0.0399 - learning_rate: 5.0000e-04\n",
      "Epoch 337/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0395 - val_loss: 0.0391 - learning_rate: 5.0000e-04\n",
      "Epoch 338/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0402 - val_loss: 0.0407 - learning_rate: 5.0000e-04\n",
      "Epoch 339/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0409 - val_loss: 0.0422 - learning_rate: 5.0000e-04\n",
      "Epoch 340/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0422 - val_loss: 0.0400 - learning_rate: 5.0000e-04\n",
      "Epoch 341/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0393 - val_loss: 0.0388 - learning_rate: 5.0000e-04\n",
      "Epoch 342/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0402 - val_loss: 0.0465 - learning_rate: 5.0000e-04\n",
      "Epoch 343/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0428 - val_loss: 0.0412 - learning_rate: 5.0000e-04\n",
      "Epoch 344/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0391 - val_loss: 0.0405 - learning_rate: 5.0000e-04\n",
      "Epoch 345/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0393 - val_loss: 0.0407 - learning_rate: 5.0000e-04\n",
      "Epoch 346/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0397 - val_loss: 0.0418 - learning_rate: 5.0000e-04\n",
      "Epoch 347/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0387 - val_loss: 0.0400 - learning_rate: 5.0000e-04\n",
      "Epoch 348/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0392 - val_loss: 0.0402 - learning_rate: 5.0000e-04\n",
      "Epoch 349/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0411 - val_loss: 0.0402 - learning_rate: 5.0000e-04\n",
      "Epoch 350/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0388 - val_loss: 0.0404 - learning_rate: 5.0000e-04\n",
      "Epoch 351/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0400 - val_loss: 0.0388 - learning_rate: 5.0000e-04\n",
      "Epoch 352/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0391 - val_loss: 0.0430 - learning_rate: 5.0000e-04\n",
      "Epoch 353/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0413 - val_loss: 0.0416 - learning_rate: 5.0000e-04\n",
      "Epoch 354/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0384 - val_loss: 0.0408 - learning_rate: 2.5000e-04\n",
      "Epoch 355/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0385 - val_loss: 0.0387 - learning_rate: 2.5000e-04\n",
      "Epoch 356/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0388 - val_loss: 0.0387 - learning_rate: 2.5000e-04\n",
      "Epoch 357/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0371 - val_loss: 0.0392 - learning_rate: 2.5000e-04\n",
      "Epoch 358/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0378 - val_loss: 0.0400 - learning_rate: 2.5000e-04\n",
      "Epoch 359/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0389 - val_loss: 0.0405 - learning_rate: 2.5000e-04\n",
      "Epoch 360/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0393 - val_loss: 0.0388 - learning_rate: 2.5000e-04\n",
      "Epoch 361/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0377 - val_loss: 0.0390 - learning_rate: 2.5000e-04\n",
      "Epoch 362/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0371 - val_loss: 0.0424 - learning_rate: 2.5000e-04\n",
      "Epoch 363/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0378 - val_loss: 0.0397 - learning_rate: 2.5000e-04\n",
      "Epoch 364/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0376 - val_loss: 0.0382 - learning_rate: 2.5000e-04\n",
      "Epoch 365/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0371 - val_loss: 0.0403 - learning_rate: 2.5000e-04\n",
      "Epoch 366/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0385 - val_loss: 0.0389 - learning_rate: 2.5000e-04\n",
      "Epoch 367/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0380 - val_loss: 0.0425 - learning_rate: 2.5000e-04\n",
      "Epoch 368/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0374 - val_loss: 0.0380 - learning_rate: 2.5000e-04\n",
      "Epoch 369/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0370 - val_loss: 0.0403 - learning_rate: 2.5000e-04\n",
      "Epoch 370/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0372 - val_loss: 0.0380 - learning_rate: 2.5000e-04\n",
      "Epoch 371/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0388 - val_loss: 0.0390 - learning_rate: 2.5000e-04\n",
      "Epoch 372/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0381 - val_loss: 0.0392 - learning_rate: 2.5000e-04\n",
      "Epoch 373/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0384 - val_loss: 0.0384 - learning_rate: 2.5000e-04\n",
      "Epoch 374/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0374 - val_loss: 0.0402 - learning_rate: 2.5000e-04\n",
      "Epoch 375/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0382 - val_loss: 0.0389 - learning_rate: 2.5000e-04\n",
      "Epoch 376/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0377 - val_loss: 0.0393 - learning_rate: 2.5000e-04\n",
      "Epoch 377/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0377 - val_loss: 0.0377 - learning_rate: 2.5000e-04\n",
      "Epoch 378/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0382 - val_loss: 0.0392 - learning_rate: 2.5000e-04\n",
      "Epoch 379/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0375 - val_loss: 0.0388 - learning_rate: 2.5000e-04\n",
      "Epoch 380/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0367 - val_loss: 0.0412 - learning_rate: 2.5000e-04\n",
      "Epoch 381/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0374 - val_loss: 0.0404 - learning_rate: 2.5000e-04\n",
      "Epoch 382/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0401 - val_loss: 0.0408 - learning_rate: 2.5000e-04\n",
      "Epoch 383/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0375 - val_loss: 0.0402 - learning_rate: 2.5000e-04\n",
      "Epoch 384/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0384 - val_loss: 0.0387 - learning_rate: 2.5000e-04\n",
      "Epoch 385/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0376 - val_loss: 0.0391 - learning_rate: 2.5000e-04\n",
      "Epoch 386/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0377 - val_loss: 0.0388 - learning_rate: 2.5000e-04\n",
      "Epoch 387/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0376 - val_loss: 0.0392 - learning_rate: 2.5000e-04\n",
      "Epoch 388/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0381 - val_loss: 0.0378 - learning_rate: 2.5000e-04\n",
      "Epoch 389/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0377 - val_loss: 0.0381 - learning_rate: 2.5000e-04\n",
      "Epoch 390/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0377 - val_loss: 0.0402 - learning_rate: 2.5000e-04\n",
      "Epoch 391/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0383 - val_loss: 0.0388 - learning_rate: 2.5000e-04\n",
      "Epoch 392/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0376 - val_loss: 0.0381 - learning_rate: 2.5000e-04\n",
      "Epoch 393/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0377 - val_loss: 0.0383 - learning_rate: 2.5000e-04\n",
      "Epoch 394/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0376 - val_loss: 0.0383 - learning_rate: 2.5000e-04\n",
      "Epoch 395/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0378 - val_loss: 0.0385 - learning_rate: 2.5000e-04\n",
      "Epoch 396/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0369 - val_loss: 0.0397 - learning_rate: 2.5000e-04\n",
      "Epoch 397/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0369 - val_loss: 0.0379 - learning_rate: 2.5000e-04\n",
      "Epoch 398/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0368 - val_loss: 0.0378 - learning_rate: 1.2500e-04\n",
      "Epoch 399/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0364 - val_loss: 0.0376 - learning_rate: 1.2500e-04\n",
      "Epoch 400/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - val_loss: 0.0380 - learning_rate: 1.2500e-04\n",
      "Epoch 401/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0367 - val_loss: 0.0380 - learning_rate: 1.2500e-04\n",
      "Epoch 402/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0365 - val_loss: 0.0380 - learning_rate: 1.2500e-04\n",
      "Epoch 403/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0368 - val_loss: 0.0379 - learning_rate: 1.2500e-04\n",
      "Epoch 404/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0367 - val_loss: 0.0379 - learning_rate: 1.2500e-04\n",
      "Epoch 405/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0358 - val_loss: 0.0374 - learning_rate: 1.2500e-04\n",
      "Epoch 406/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0374 - val_loss: 0.0389 - learning_rate: 1.2500e-04\n",
      "Epoch 407/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0372 - val_loss: 0.0386 - learning_rate: 1.2500e-04\n",
      "Epoch 408/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0367 - val_loss: 0.0392 - learning_rate: 1.2500e-04\n",
      "Epoch 409/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0365 - val_loss: 0.0406 - learning_rate: 1.2500e-04\n",
      "Epoch 410/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0380 - val_loss: 0.0389 - learning_rate: 1.2500e-04\n",
      "Epoch 411/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0373 - val_loss: 0.0373 - learning_rate: 1.2500e-04\n",
      "Epoch 412/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0362 - val_loss: 0.0380 - learning_rate: 1.2500e-04\n",
      "Epoch 413/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0372 - val_loss: 0.0376 - learning_rate: 1.2500e-04\n",
      "Epoch 414/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0368 - val_loss: 0.0400 - learning_rate: 1.2500e-04\n",
      "Epoch 415/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0374 - val_loss: 0.0386 - learning_rate: 1.2500e-04\n",
      "Epoch 416/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0365 - val_loss: 0.0386 - learning_rate: 1.2500e-04\n",
      "Epoch 417/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0367 - val_loss: 0.0377 - learning_rate: 1.2500e-04\n",
      "Epoch 418/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0363 - val_loss: 0.0376 - learning_rate: 1.2500e-04\n",
      "Epoch 419/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0359 - val_loss: 0.0385 - learning_rate: 1.2500e-04\n",
      "Epoch 420/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0370 - val_loss: 0.0389 - learning_rate: 1.2500e-04\n",
      "Epoch 421/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0376 - learning_rate: 1.2500e-04\n",
      "Epoch 422/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0368 - val_loss: 0.0381 - learning_rate: 1.2500e-04\n",
      "Epoch 423/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0368 - val_loss: 0.0380 - learning_rate: 1.2500e-04\n",
      "Epoch 424/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0360 - val_loss: 0.0384 - learning_rate: 1.2500e-04\n",
      "Epoch 425/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0360 - val_loss: 0.0377 - learning_rate: 1.2500e-04\n",
      "Epoch 426/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0374 - val_loss: 0.0375 - learning_rate: 1.2500e-04\n",
      "Epoch 427/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0356 - val_loss: 0.0382 - learning_rate: 1.2500e-04\n",
      "Epoch 428/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0370 - val_loss: 0.0376 - learning_rate: 1.2500e-04\n",
      "Epoch 429/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0365 - val_loss: 0.0373 - learning_rate: 1.2500e-04\n",
      "Epoch 430/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0364 - val_loss: 0.0378 - learning_rate: 1.2500e-04\n",
      "Epoch 431/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0383 - learning_rate: 1.2500e-04\n",
      "Epoch 432/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0367 - val_loss: 0.0383 - learning_rate: 6.2500e-05\n",
      "Epoch 433/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0356 - val_loss: 0.0375 - learning_rate: 6.2500e-05\n",
      "Epoch 434/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0359 - val_loss: 0.0380 - learning_rate: 6.2500e-05\n",
      "Epoch 435/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0361 - val_loss: 0.0375 - learning_rate: 6.2500e-05\n",
      "Epoch 436/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0352 - val_loss: 0.0378 - learning_rate: 6.2500e-05\n",
      "Epoch 437/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0365 - val_loss: 0.0371 - learning_rate: 6.2500e-05\n",
      "Epoch 438/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0366 - val_loss: 0.0374 - learning_rate: 6.2500e-05\n",
      "Epoch 439/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0367 - val_loss: 0.0371 - learning_rate: 6.2500e-05\n",
      "Epoch 440/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0354 - val_loss: 0.0377 - learning_rate: 6.2500e-05\n",
      "Epoch 441/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0360 - val_loss: 0.0370 - learning_rate: 6.2500e-05\n",
      "Epoch 442/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0360 - val_loss: 0.0371 - learning_rate: 6.2500e-05\n",
      "Epoch 443/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0359 - val_loss: 0.0380 - learning_rate: 6.2500e-05\n",
      "Epoch 444/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0361 - val_loss: 0.0372 - learning_rate: 6.2500e-05\n",
      "Epoch 445/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0358 - val_loss: 0.0370 - learning_rate: 6.2500e-05\n",
      "Epoch 446/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0362 - val_loss: 0.0374 - learning_rate: 6.2500e-05\n",
      "Epoch 447/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0366 - val_loss: 0.0374 - learning_rate: 6.2500e-05\n",
      "Epoch 448/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0360 - val_loss: 0.0373 - learning_rate: 6.2500e-05\n",
      "Epoch 449/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0355 - val_loss: 0.0372 - learning_rate: 6.2500e-05\n",
      "Epoch 450/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0352 - val_loss: 0.0372 - learning_rate: 6.2500e-05\n",
      "Epoch 451/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0360 - val_loss: 0.0373 - learning_rate: 6.2500e-05\n",
      "Epoch 452/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0360 - val_loss: 0.0376 - learning_rate: 6.2500e-05\n",
      "Epoch 453/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0355 - val_loss: 0.0372 - learning_rate: 6.2500e-05\n",
      "Epoch 454/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0363 - val_loss: 0.0372 - learning_rate: 6.2500e-05\n",
      "Epoch 455/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0364 - val_loss: 0.0374 - learning_rate: 6.2500e-05\n",
      "Epoch 456/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0371 - learning_rate: 6.2500e-05\n",
      "Epoch 457/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0357 - val_loss: 0.0375 - learning_rate: 6.2500e-05\n",
      "Epoch 458/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0356 - val_loss: 0.0371 - learning_rate: 3.1250e-05\n",
      "Epoch 459/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0357 - val_loss: 0.0369 - learning_rate: 3.1250e-05\n",
      "Epoch 460/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0355 - val_loss: 0.0369 - learning_rate: 3.1250e-05\n",
      "Epoch 461/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0355 - val_loss: 0.0373 - learning_rate: 3.1250e-05\n",
      "Epoch 462/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0361 - val_loss: 0.0371 - learning_rate: 3.1250e-05\n",
      "Epoch 463/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0356 - val_loss: 0.0370 - learning_rate: 3.1250e-05\n",
      "Epoch 464/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0359 - val_loss: 0.0373 - learning_rate: 3.1250e-05\n",
      "Epoch 465/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0361 - val_loss: 0.0369 - learning_rate: 3.1250e-05\n",
      "Epoch 466/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0353 - val_loss: 0.0373 - learning_rate: 3.1250e-05\n",
      "Epoch 467/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0354 - val_loss: 0.0373 - learning_rate: 3.1250e-05\n",
      "Epoch 468/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0358 - val_loss: 0.0372 - learning_rate: 3.1250e-05\n",
      "Epoch 469/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0371 - val_loss: 0.0383 - learning_rate: 3.1250e-05\n",
      "Epoch 470/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0358 - val_loss: 0.0371 - learning_rate: 3.1250e-05\n",
      "Epoch 471/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0361 - val_loss: 0.0379 - learning_rate: 3.1250e-05\n",
      "Epoch 472/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.0379 - learning_rate: 3.1250e-05\n",
      "Epoch 473/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0360 - val_loss: 0.0372 - learning_rate: 3.1250e-05\n",
      "Epoch 474/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0365 - val_loss: 0.0370 - learning_rate: 3.1250e-05\n",
      "Epoch 475/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0351 - val_loss: 0.0371 - learning_rate: 3.1250e-05\n",
      "Epoch 476/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0358 - val_loss: 0.0368 - learning_rate: 3.1250e-05\n",
      "Epoch 477/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0350 - val_loss: 0.0370 - learning_rate: 3.1250e-05\n",
      "Epoch 478/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0361 - val_loss: 0.0368 - learning_rate: 3.1250e-05\n",
      "Epoch 479/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0354 - val_loss: 0.0372 - learning_rate: 3.1250e-05\n",
      "Epoch 480/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0352 - val_loss: 0.0373 - learning_rate: 1.5625e-05\n",
      "Epoch 481/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0357 - val_loss: 0.0371 - learning_rate: 1.5625e-05\n",
      "Epoch 482/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0353 - val_loss: 0.0369 - learning_rate: 1.5625e-05\n",
      "Epoch 483/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0348 - val_loss: 0.0370 - learning_rate: 1.5625e-05\n",
      "Epoch 484/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0356 - val_loss: 0.0372 - learning_rate: 1.5625e-05\n",
      "Epoch 485/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0347 - val_loss: 0.0370 - learning_rate: 1.5625e-05\n",
      "Epoch 486/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0371 - learning_rate: 1.5625e-05\n",
      "Epoch 487/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0352 - val_loss: 0.0369 - learning_rate: 1.5625e-05\n",
      "Epoch 488/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0362 - val_loss: 0.0370 - learning_rate: 1.5625e-05\n",
      "Epoch 489/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0360 - val_loss: 0.0369 - learning_rate: 1.5625e-05\n",
      "Epoch 490/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0363 - val_loss: 0.0371 - learning_rate: 1.5625e-05\n",
      "Epoch 491/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0357 - val_loss: 0.0370 - learning_rate: 1.5625e-05\n",
      "Epoch 492/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0358 - val_loss: 0.0370 - learning_rate: 1.5625e-05\n",
      "Epoch 493/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0366 - val_loss: 0.0369 - learning_rate: 1.5625e-05\n",
      "Epoch 494/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0347 - val_loss: 0.0368 - learning_rate: 1.5625e-05\n",
      "Epoch 495/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0360 - val_loss: 0.0370 - learning_rate: 1.5625e-05\n",
      "Epoch 496/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0358 - val_loss: 0.0369 - learning_rate: 1.5625e-05\n",
      "Epoch 497/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0361 - val_loss: 0.0370 - learning_rate: 1.5625e-05\n",
      "Epoch 498/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0369 - learning_rate: 1.5625e-05\n",
      "Epoch 499/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0352 - val_loss: 0.0368 - learning_rate: 1.5625e-05\n",
      "Epoch 500/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0347 - val_loss: 0.0369 - learning_rate: 7.8125e-06\n",
      "Epoch 501/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - val_loss: 0.0368 - learning_rate: 7.8125e-06\n",
      "Epoch 502/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0353 - val_loss: 0.0369 - learning_rate: 7.8125e-06\n",
      "Epoch 503/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0352 - val_loss: 0.0369 - learning_rate: 7.8125e-06\n",
      "Epoch 504/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0360 - val_loss: 0.0370 - learning_rate: 7.8125e-06\n",
      "Epoch 505/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0359 - val_loss: 0.0369 - learning_rate: 7.8125e-06\n",
      "Epoch 506/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0358 - val_loss: 0.0369 - learning_rate: 7.8125e-06\n",
      "Epoch 507/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0369 - learning_rate: 7.8125e-06\n",
      "Epoch 508/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0354 - val_loss: 0.0368 - learning_rate: 7.8125e-06\n",
      "Epoch 509/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0367 - val_loss: 0.0369 - learning_rate: 7.8125e-06\n",
      "Epoch 510/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0351 - val_loss: 0.0370 - learning_rate: 7.8125e-06\n",
      "Epoch 511/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0353 - val_loss: 0.0371 - learning_rate: 7.8125e-06\n",
      "Epoch 512/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0357 - val_loss: 0.0369 - learning_rate: 7.8125e-06\n",
      "Epoch 513/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0350 - val_loss: 0.0369 - learning_rate: 7.8125e-06\n",
      "Epoch 514/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0368 - learning_rate: 7.8125e-06\n",
      "Epoch 515/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0368 - learning_rate: 7.8125e-06\n",
      "Epoch 516/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0356 - val_loss: 0.0368 - learning_rate: 7.8125e-06\n",
      "Epoch 517/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0358 - val_loss: 0.0368 - learning_rate: 7.8125e-06\n",
      "Epoch 518/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0352 - val_loss: 0.0368 - learning_rate: 7.8125e-06\n",
      "Epoch 519/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0356 - val_loss: 0.0368 - learning_rate: 7.8125e-06\n",
      "Epoch 520/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0354 - val_loss: 0.0369 - learning_rate: 7.8125e-06\n",
      "Epoch 521/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0357 - val_loss: 0.0368 - learning_rate: 7.8125e-06\n",
      "Epoch 522/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0358 - val_loss: 0.0368 - learning_rate: 3.9063e-06\n",
      "Epoch 523/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0356 - val_loss: 0.0369 - learning_rate: 3.9063e-06\n",
      "Epoch 524/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0351 - val_loss: 0.0369 - learning_rate: 3.9063e-06\n",
      "Epoch 525/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0359 - val_loss: 0.0368 - learning_rate: 3.9063e-06\n",
      "Epoch 526/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0351 - val_loss: 0.0369 - learning_rate: 3.9063e-06\n",
      "Epoch 527/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0367 - val_loss: 0.0369 - learning_rate: 3.9063e-06\n",
      "Epoch 528/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0360 - val_loss: 0.0369 - learning_rate: 3.9063e-06\n",
      "Epoch 529/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0361 - val_loss: 0.0369 - learning_rate: 3.9063e-06\n",
      "Epoch 530/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0352 - val_loss: 0.0368 - learning_rate: 3.9063e-06\n",
      "Epoch 531/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0347 - val_loss: 0.0368 - learning_rate: 3.9063e-06\n",
      "Epoch 532/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0354 - val_loss: 0.0368 - learning_rate: 3.9063e-06\n",
      "Epoch 533/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0370 - learning_rate: 3.9063e-06\n",
      "Epoch 534/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0359 - val_loss: 0.0369 - learning_rate: 3.9063e-06\n",
      "Epoch 535/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0357 - val_loss: 0.0368 - learning_rate: 3.9063e-06\n",
      "Epoch 536/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0360 - val_loss: 0.0369 - learning_rate: 3.9063e-06\n",
      "Epoch 537/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0353 - val_loss: 0.0370 - learning_rate: 3.9063e-06\n",
      "Epoch 538/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0357 - val_loss: 0.0368 - learning_rate: 3.9063e-06\n",
      "Epoch 539/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0358 - val_loss: 0.0368 - learning_rate: 3.9063e-06\n",
      "Epoch 540/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0348 - val_loss: 0.0369 - learning_rate: 3.9063e-06\n",
      "Epoch 541/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0359 - val_loss: 0.0368 - learning_rate: 3.9063e-06\n",
      "Epoch 542/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0352 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 543/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 544/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0351 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 545/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0352 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 546/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0345 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 547/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0346 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 548/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0350 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 549/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0353 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 550/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0352 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 551/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0353 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 552/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0353 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 553/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0349 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 554/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0351 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 555/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0353 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 556/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0353 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 557/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0350 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 558/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0348 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 559/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0350 - val_loss: 0.0369 - learning_rate: 1.9531e-06\n",
      "Epoch 560/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0352 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n",
      "Epoch 561/700\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0350 - val_loss: 0.0368 - learning_rate: 1.9531e-06\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "act_name = \"relu\"\n",
    "l2_reg = 0.0007\n",
    "epoch = 700\n",
    "b_s= 64\n",
    "optimizer_name = Adam(learning_rate = 1e-3)\n",
    "\n",
    "\n",
    "def train_model(act_name, l2_reg, epoch, b_s, optimizer_name):\n",
    "  \"\"\"\n",
    "  Función para entrenar el modelo de la coordenada Z.\n",
    "\t\n",
    "\tArguments:\n",
    "\t- act_name: función de activación a utilizar en las capas ocultas.\n",
    "\t- l2_reg: valor de la regularización L2.\n",
    "\t- epoch: número de épocas para el entrenamiento.\n",
    "\t- b_s: tamaño del batch.\n",
    "\t- optimizer_name: optimizador a utilizar.\t\n",
    "  Returns:\n",
    "\t- modelo entrenado.\n",
    "  \"\"\"\n",
    "  inputs = Input(shape=(5,))\n",
    "  encoded = Dense(32, activation= act_name, kernel_regularizer= l2(l2_reg))(inputs)\n",
    "  encoded = Dense(64, activation= act_name, kernel_regularizer= l2(l2_reg))(encoded)\n",
    "  encoded = Dense(128, activation=act_name, kernel_regularizer=l2(l2_reg))(encoded)\n",
    "  encoded = Dense(256, activation=act_name, kernel_regularizer=l2(l2_reg))(encoded)\n",
    "  decoded = Dense(200, activation= 'linear', kernel_regularizer= l2(l2_reg), name ='z_output')(encoded)\n",
    "\n",
    "  autoencoder_z = Model(inputs, decoded)\n",
    "  autoencoder_z.compile(optimizer = optimizer_name, loss= 'mae') \n",
    "  autoencoder_z.summary()\n",
    "\n",
    "  history = autoencoder_z.fit(x_train,y_train_z_scaled,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tepochs = epoch,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tbatch_size = b_s,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tvalidation_split = 0.1,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcallbacks = [reduce_lr, early_stopping]\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t)\n",
    "  return autoencoder_z,history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: si los batch_size son muy grandes es decir la actualización de los pesos por lotes. no finaliza la cantidad de epochs ya sea xq el learning rate es muy bajo o por que el early stopping detiene el entrenamiento por falta de mejora \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0346\n",
      "Pérdida en datos de Test: 0.034813448786735535\n"
     ]
    }
   ],
   "source": [
    "loss = autoencoder_z.evaluate(x_test,y_test_z_scaled)\n",
    "print(f'Pérdida en datos de Test: {loss}')\n",
    "\n",
    "# mae_in_m = loss[1]*R0\n",
    "# print(f'mae:{mae_in_m}[m]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n"
     ]
    }
   ],
   "source": [
    "idx = 80\n",
    " # Elegir una muestra para comparar (observar luego la muestra 30)\n",
    "# Predicción de una muestra \n",
    "y_pred_scaled = autoencoder_z.predict(np.expand_dims(x_test.iloc[idx], axis=0))\n",
    "###############################################\n",
    "y_true = y_test_z.iloc[idx] # Se obtine Algo de tipo Serie\n",
    "y_true=y_true.to_numpy() # Transform a Numpy array\n",
    "\n",
    "#Desnormalizamos\n",
    "y_pred = scaler_z.inverse_transform(y_pred_scaled)\n",
    "y_pred = y_pred.flatten() # [[...,...,...,....,]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABM8AAAIQCAYAAACWr0kOAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAu1NJREFUeJzs3QecE3X6x/FnWZYqvXcQCygoFlQsKIpgPQE9UVRQESsqehbgVKyInbMrKur/9EQRyyFiQw6VYkVBxUKXIgKyi9RlN//X9xcmm2ST3SSbZXeTz/v1yoVMJpPJTCbIc0/J8Pl8PgMAAAAAAABQSKXCiwAAAAAAAAAIwTMAAAAAAAAgCoJnAAAAAAAAQBQEzwAAAAAAAIAoCJ4BAAAAAAAAURA8AwAAAAAAAKIgeAYAAAAAAABEQfAMAAAAAAAAiILgGQAAQDnw3HPP2VNPPVXWuwEAAIAwBM8AAABK2THHHONu0bz22mt29dVXW9euXXfJ/jz//POWkZFhS5YssYqqbdu2dv7558f1Gn1efW59fgAAgFgRPAMAABEtXLjQLrnkEtt9992tWrVqVrt2bTviiCPsX//6l23ZsqWsdy9l/PLLL3bppZfaq6++agceeKBVRNOnT3dBKe+WlZXlvjcDBw60RYsWlfXupZTwYx3tpvUAAEByVE7SdgAAQAp555137O9//7tVrVrVBUA6depk27dvt08//dSuv/56+/777+3pp58u692sMN5///2oz3377bc2fvx4O/HEE62iu+qqq1z2XG5urn399dfuO6Lv0rx586x58+ZJfa+ffvrJKlWK7/8HbtOmjQv8KrhXUXXs2NH+7//+L+Jzf/31lw0bNsyqV69ue+211y7fNwAAUhXBMwAAEGLx4sV21llnuUDDtGnTrFmzZoHnrrjiCvv1119dQCQV5efnuyChMu2SqUqVKlGfO+OMMyxVHHXUUYHPc8EFF7gAjgJqL7zwgo0YMSKp76XAbryUkZXsc7urNWnSxM4999yIz2n5tm3b7OWXX056sBIAgHRG2SYAAAhx7733ugyWZ599NiRw5tljjz1cfy7Pjh077I477rD27du7gIZ6UY0cOdL9Iz6Ylp9yyimunOzggw922TGdO3cOlJdNmjTJPVZw46CDDrJvvvkm5PXqb7Xbbru5MsDevXtbzZo1XYDg9ttvN5/PF7Lu/fffb4cffrg1aNDAvY+2N3HixIjBlKFDh9pLL71k++67r9v/qVOnxrUN+fe//22HHHKI1ahRw+rVq2fdu3cPyTaL1PNszZo1NnjwYBcM0Wfef//9XZApUo8u7YuyuLxjrOyuL774wmKhLMFjjz3WfYaWLVvanXfe6YKEkbz77rsuAKZjW6tWLTv55JPd6xOl9/UCsp7HH388cKx1/hSQ3bBhQ6FS1tNPP92aNm3qjo32WwHd7OzsInueaTvXXHONe07b1+uUObl27doie54pSOx97rp169ppp51mP/74Y8g6t956q3utgsd6X61Xp04dFyTcvHlzxO+EvjM67vXr13f7v3z58rg/ZzwDJ/Q9vuyyy6xfv35xvx4AAERH5hkAAAjx3//+1/WrUuAoFhdddJEL+ijj6B//+IfNmTPH7r77bhd8eOONN0LWVeBhwIABrpeasmQUFDr11FPtySefdAG3yy+/3K2n15955pmFSvPy8vLshBNOsMMOO8wF+RToGjVqlAvgKYjmUV+2v/3tb3bOOee4TLJXXnnFlaFOnjzZBYTCAyfqN6YgWsOGDV3gJZ5t3HbbbS6wouOlfVCWmY6BtturV6+Ix0ylgwqm6Xjofdu1a+eGBigoowBQcHBSlEm0ceNGd9wUwNFnV4BEgcSiShBXr15tPXr0cMdn+PDhLjikIJwCOuFUCjho0CAXmLznnntcQOiJJ56wI4880gUyveMSb988UQBSdJx0vHr27OmCPDq/eg8FAj/77DP3WXSstQ8Kvl555ZUusLRixQp33HVsFLCKRAFfBcD0vbvwwgtd/zgFzd5++2377bff3LmN5MMPP3Qls/rOa/90bh555BHX30+lp+GfW99LnS99R/X8M888Y40bN3bHzHPXXXfZzTff7NbV9fHHH3+4bSqoqmOpwFuinzMSfWZtY7/99rMHH3ww5tcBAIAY+QAAAHbKzs5WCpfvtNNOi2n9uXPnuvUvuuiikOXXXXedWz5t2rTAsjZt2rhlM2fODCx777333LLq1av7li5dGlj+1FNPueUff/xxYNmgQYPcsiuvvDKwLD8/33fyySf7qlSp4vvjjz8Cyzdv3hyyP9u3b/d16tTJd+yxx4Ys1/YqVark+/777wt9tli28csvv7jX9+3b15eXlxeyvvbNc/TRR7ubZ+zYse69//3vf4dsv1u3br7ddtvNl5OT45YtXrzYrdegQQPf+vXrA+u+9dZbbvl///tfX1GGDRvm1pszZ05g2Zo1a3x16tRxy7V92bhxo69u3bq+IUOGhLx+9erVbt3w5eF0nrS95557zp2HlStX+t555x1f27ZtfRkZGb4vvvjCva/OU69evUKO1aOPPhp4rXzzzTfu8WuvvVbke+r7pO+E55ZbbnGvmzRpUqF1vXPhHc/x48cHnuvSpYuvcePGvnXr1gWWffvtt+68Dhw4MLBs1KhR7rUXXnhhyLZ17nV+PEuWLPFlZmb67rrrrpD15s2b56tcuXJgeayfszj6nup7WaNGDd+PP/5Yom0BAIDIKNsEAAABOTk57l4le7GYMmWKu7/22mtDlisDTcJ7o+2zzz7WrVu3wONDDz00UN7XunXrQssjTWpUplZ42aWyeJRB5AnOrPrzzz9dGZyykpQpFO7oo492+xUulm28+eabrgTylltuKdS8XvtW1HFTptHZZ58dWKasK/UHUwbV//73v5D1+/fv78pBPdqPaMcn/H2UpaeSUk+jRo1cNl2wDz74wGU7aX+UreXdMjMz3bn4+OOPLRbK+NL2VY6p7LxNmza5rESV6er86DypoX3wsRoyZIib5Op9V7yMq/feey9iOWQ0r7/+uit97du3b6Hnop2LVatW2dy5c13Gn0orPcrgOv744wPf72CajBpM52LdunWBa0flx/pOKOss+FjqfO+5556BY5no5wynLMX58+e7zLYOHTokvB0AABAdZZsAACBAQQxRiWAsli5d6gIh6oMWTIEClabp+WDBAbLgAEKrVq0iLlfQKpjeS+V1wbypgupn5VHpm3p7KTAS3HstUhBFJXiRxLINlSVqnyIF34qi46JASnjATZMUveeLOm5eIC38+ER6Hy8QGWzvvfcu1HsruEdZtO9FcRREVDBJQTeVSerzVK5cOeQzhb+3ylx1Tr3ndT4UjFX5oXp4aXsqn1WZb1GljDoX6h8Wj2j7JNp3BbYUAFS5ayznQsdJx1JJjTq/kXhltol+zmATJkywcePGuaCnApcAAKB0EDwDAAAB+se/soaUyRKPorKsgimoEs/y8EEAsfjkk09cEEL9pdScXkMPFLAYP3686x0WLlL/r3i3UdqSeXwi8QYIqO+ZAp/hvABYcTTwQf3MSuqBBx5w2WBvvfWWG7ygjDz1GJs9e7Zrql+WijsXOpa6HjR8IdK6GnqRjM+pYOHFF1/shkg89dRTJf5cAAAgOoJnAAAghCZiqqn8rFmzQkosI2nTpo0LFijbxsuakt9//92VAer5ZNJ7qVTRyzaTn3/+2d17jd1VvqfJhcoa0sRFjwJfsYp1GwpcaJ9++OEH69KlS8zb13H57rvv3GuDs88WLFgQeD4ZtB0vqyyYGvWHfw5R4/tkBL+i7Yv33sHZgyrl1DTO8PdVIE63m266yWbOnOka+GuwhLIBI9FniDfoG7xP4XQulD0XnHUWC+2HAmnKLAv+nkYT7+f0jplKebdu3eoGWcRaZg0AABJDzzMAABDihhtucAEDTQlUECxSxosmUcpJJ53k7seOHRuyjjfxL3yyZTI8+uijgT8rSKHHygo77rjj3DJl+yjzR5M5PSrpVH+yWMW6jT59+rjgl6ZsetlbwfsWjY6bJmGq7M6jiZjqW6XMJPVhSwa9j7KYPv/888AyTX5UmWAwTX1U1uHo0aMtNze30Hb0mpJScEwlmg8//HDIsXn22WddPznvu6LeYToWwRRc0nEOLp8Np5LNb7/9ttCE16LOhTIKFfRUXzYFez0KwikTzPt+x0NTUPX90VTR8PfVY/VHK8nn9K7Rr776ymWpqZ8cAAAoXWSeAQCAQpkzKk1UZouyyQYOHGidOnVy2S7KjHnttddcqZmoQfugQYNcppqCDwr6KFCjYIQCSz169EjqvikbbOrUqe491ctLpXFqND9y5EjXqF4UhFHw7oQTTrABAwbYmjVr7LHHHnN92ZTtFYtYt6HH//znP+2OO+5wPasUOFGm2hdffOHKXxXciETldiq103FUEERZcxMnTrTPPvvMBSKTlUmkIItKMfU51FheQVGdKy/zzaPA2RNPPGHnnXeeHXjggXbWWWe547ls2TJ3fJUNFRy0TIS2N2LECBdU0v6oLFYZXyqL7dq1q+v1JdOmTXNDIP7+97+7zC0FmPQZFJAqqqfZ9ddf746hXqf+XwcddJCtX7/e3n77bZfJpe9qJPfdd5+deOKJLsty8ODBtmXLFhfEVN+xW2+9NaHrR1lj+qwKuOo60PlUdp0Cezr31113XcKfU995Ba/1/dIx/fe//x1xvcMPP7xQf0AAAJCgKFM4AQBAmvv55599Q4YM8bVt29ZXpUoVX61atXxHHHGE75FHHvFt3bo1sF5ubq7vtttu87Vr186XlZXla9WqlW/EiBEh60ibNm18J598cqH30X+OXHHFFSHLFi9e7Jbfd999gWWDBg3y1axZ07dw4UJfr169fDVq1PA1adLEN2rUKF9eXl7I65999lnfnnvu6atataqvQ4cOvvHjx7v1wv/TJ9J7x7sNee6553wHHHCAW7devXq+o48+2vfBBx8Entdj3YL9/vvvvgsuuMDXsGFDd3w7d+7s3qO44xC879qf4nz33XfuvatVq+Zr0aKF74477nCfTa/X9oN9/PHHvt69e/vq1Knj1m/fvr3v/PPP93355ZdFvodep+299tprxe7Po48+6o6nvis6f5dddpnvzz//DDy/aNEi34UXXujeW/tQv359X48ePXwffvhhoe+TvhPB1q1b5xs6dKj7nDqmLVu2dOusXbs25HiGH2dtW9/t6tWr+2rXru079dRTfT/88EPIOt65/+OPP0KWa1uRjuXrr7/uO/LII913Vjd9Zn3Xfvrpp7g+ZzhvP4q7hX9GAACQuAz9T6KBNwAAgF1FWVrKLPrrr7/KelcAAACQRuh5BgAAAAAAAERB8AwAAAAAAACIguAZAAAAAAAAEAU9zwAAAAAAAIAoyDwDAAAAAAAAoiB4BgAAAAAAAERR2dJEfn6+rVy50mrVqmUZGRllvTsAAAAAAAAoQ+pktnHjRmvevLlVqhQ9vyxtgmcKnLVq1aqsdwMAAAAAAADlyPLly61ly5ZRn0+b4JkyzrwDUrt2bUsFubm59v7771uvXr0sKyurrHcHSAlcV0BycU0Bycd1BSQX1xSQvtdVTk6OS7TyYkaW7sEzr1RTgbNUCp7VqFHDfZ7y/GUEKhKuKyC5uKaA5OO6ApKLawpIvtwKdl0V196LgQEAAAAAAABAFATPAAAAAAAAgCgIngEAAAAAAABREDwDAAAAAAAAoiB4BgAAAAAAAERB8AwAAAAAAACIguAZAAAAAAAAEAXBMwAAAAAAACAKgmcAAAAAAABAFATPAAAAAAAAgCgIngEAAAAAAABREDwDAAAAAAAAoiB4BgAAAAAAAERB8AwAAAAAAACIguAZAAAAAAAAEAXBMwAAAAAAkJZWZW+xmQvXuvuyWDdV3z/VVLZ0s2mTWWZm7OtXrWpWeedh2rHDbNs2s0qVzKpXD91mvKpUMcvK8v85L89s61azjAyzGjUK1tm82czni76N3FzL1Ov0/t62dK9tS36+2ZadX+qaNQtep2V6Lh46BjoWon3SvoVvV/uizxIPnYtq1QofSx0HHQ/RMdexj0e0c6Rlek62b3fHMC7RzpE+g/e90ja17XhFOkeRvn8l2a53jiJ9/+IV6RxF+/7FI9I5ivb9i0ekcxTp+xfpuqqovxGR8Bvhx2/ELv2NqKTPrGOsZRX9NyJe/Eb48RuR3N+ISH9XVeDfiJT674h48RtRPn4jtmyJ77//yvtvRCQp8huxakueLV67ydrVr27Ndn4VI1mdvcWWrNtkbRvUtKZ1gs5V2DmaOHuR3fTfBbY1M8sqZZjd3beT9d+3YcRtTvxquY1663vL95lb97bT9rUzDmrlfzLsHE2ctdBu+u+PtjWzin+7/Tpb/30axLdNCTpHr85aZLdN/MZ2WIblVqnq32bX1hF/I4rd7s5zNOGLZfbPiXMtKzfXMiqZjerf1b/NCL8RE4vbZoTfiMB1Vbdu+f2NiJUvTWRnZ+us+7L9hzr226uvFmxEf9ayo48O3XjDhvFtU7dHHy14/ccf+5fts0/odvU43u2OGlXw+vnz/cu0f8G0//Fu9/LLC16/Zk3B8mBnnBH/dvWaYN5yvYdH7x3vdqOdIx0Tj45VvNuNdo50Dj06t/FuN9o5ivT9i/cW6RxF+v7Fe4t0jiJ9/+K9RTpH0b5/8dwinaNo3794bvxGFH2OIn3/4rnxG1HhfyO2b9/uW3TiidG/f/He+I2Ifo74jSj0/XP4jSjXvxEh54jfiKK/f/Hc+I0o+hzxGxH9+xfvbRf+Rsy7aJiv3fDJvjY3Tvb1GvxYYtsNOkc5N450y1444GS3Td0OvurlxLYbdI423PegWzZ57yMC2919+DuJbXfnOVq5YbPv8j7D3bJZrToFtqnlif5G6LU6nv3PHu2W/dSgdcE2g79/Cf5GbP/mG7csv5z/RgRiRdnZvqJQtgkAAAAAAMq1j3783WU9iXdfEhs2F84MzFNIpYTW/bU96dtVtl34JrTNJWs3l2ib+UneZirLUAQt3hc99thjdt9999nq1att//33t0ceecQOOeSQqOtv2LDB/vnPf9qkSZNs/fr11qZNGxs7dqyddNJJ7vlbb73VbrvttpDX7L333rZgwYLA461bt9o//vEPe+WVV2zbtm3Wu3dve/zxx61JkyYx7XNOTo7VqVPHsleutNq1a6dEKnVubq6999577lhkUbYZilTqyNul3KLYcouI11UF/Y2IiN8IP34jdtlvhK6pqW+9ZSf07GlZlG3yGyH8RpT4NyLi31UV9Dci1f47Im78RpSL34jcLVvi+++/cv4bEdEu/o1YtXmHv7yyXjVrVnXnsY5QWnncA/8LCeBkZmTYh//obk2bNQg5R7N/Xm3nvfiN5Wb6z0+GL9+q5W635y/oaofuXlAOOXvRWrtg/JeF3iuwXtA5WvVHtvUc86HlZmTa9sr+7eoof3bVoaGlnsXtq9YNOker1uZYz7s/sB0ZlWxb5SqBdT+78pCQ7Ra7Tdl5jtRjrPvoD6xybq7lZ2TYtqyqbt1Ph/ewZpVDr7eYtrvzHB0xZpo7Z1V35Jovwyy3SnX/NrVe0G/E6li2GfYbkbttm7335pv+66ocl23mbN/ujxVlZxcZK4q759mECRPs2muvtSeffNIOPfRQFwTTwfjpp5+scePGhdbfvn27HX/88e65iRMnWosWLWzp0qVWN/jgmdm+++5rH374YcGOeRfxTtdcc42988479tprr7kPNnToUOvXr5999tln8X0AHdzgAxwP7VPYfgW2WRK6yCJtI/iHM5LcXMvTRarXRvqR149CpO0G/9AnQj9ikbYb/BdToiJtVxeJd6Ekc7u6qL2//BMV6RzpXMTyl25RIp2jaN+/eEQ6R9G+f/GIdI6iff/iEekcRfv+xSPaOdJ2i7uuKtJvRHH4jSh6u/xGJO03Il+fN/yaqqi/ESXBb4QfvxEl/40o7u+qCvYbkVL/HVES/EaU3W9EpUqJ//dftO2m8X9HqI/WiEnzAr2xAr25wixavcU2ZRU+r4u3ZFhTL3AmVatam9aNLU8Brp3BG19GJdtetbq1bt3IrGbB52nTupJtq1qtUJAnfD1p1qiO3XJWVxs5ab4LyGi90f06WdPmhXueNa1ZM7BuXjHrNmtYO6btxrXNOtXtzjO6FFrXBbkS3NdmdbLcudF6WyplFt5m0PevaRz7GhB8XZXn34gYg9FxXx0PPvigDRkyxC644AL3WEE0BbWee+45Gz58eKH1tVzZZjNnzgxE8du2bVt4RypXtqZNm0Z8T0UAn332WXv55Zft2GOPdcvGjx9vHTt2tNmzZ9thhx0W78cAAAAAAABJpAwpL3AmulfApftejQoFeto1rOmCa+GBrrYNCwcN9Vov0FNU8CjW9TwK6mnfVKqo9422Xmmtm6rvn4riCp4pi+yrr76yESNGBJZVqlTJevbsabNmzYr4mrffftu6detmV1xxhb311lvWqFEjGzBggN14442WGTTZ4JdffrHmzZtbtWrV3Pp33323tW7tj07rPZWervfxdOjQwT2v940UPFNpp27BZZui7eiWCrzPkSqfBygPuK6A5OKaApKP6wpILq6p2K3K3mpL1222Ng0UPCmc6fPr6pyIfbQW/p5jDWuEhh/0+M7T9rGb3vohkKV2x2kd3fJI56Jfl2bWrV09W7Z+s7Wu73//kqwXvB8NW9eO6TtQGuum6vvnVpDrKtb9iyt4tnbtWsvLyyvUZ0yPg/uTBVu0aJFNmzbNzjnnHJsyZYr9+uuvdvnll7sdHDVqlFtH5Z/PP/+863O2atUq1//sqKOOsvnz51utWrVcb7UqVaoUKvXU++q5SBR8C++jJu+//77VKGmKcjnzwQcflPUuACmH6wpILq4pIPm4roDk4poq2qzfM2zCokrmswzLMJ/13z3fujUJjZRt2GaWYZluHY/WXTh3tq37sfA2VXw36gCzP7ZmWKNqPqv5+3c2Zcp3xe7LOjP7JoZ9jnU9pO91tTnGPpglLGouXn5+vut39vTTT7tMs4MOOshWrFjhBg54wbMTTzwxsP5+++3ngmkaKvDqq6/a4MGDE3pfZcepN1tw5lmrVq2sV69e8Q0MKMcUgNQXUT3lYmpsCaBYXFdAcnFNAcnHdQUkF9dUbBln1zwww2s55oJjry7OtMv7dS+UgZbV+reQbLI7T9vX/n5QyzLZb5Sd3ApyXXlVikkNnjVs2NAFwH7//feQ5XocrV9Zs2bN3IEKLtFUrzJljKkMVBll4ZRhttdee7ksNdG2ta6mdgZnnxX1vlWrVnW3cNqX8nziEpGKnwkoa1xXQHJxTQHJx3UFJBfXVHS/ZWcXKsfU4xXZ2611w1ohywcc1s56dGyatr2xULGuq1j3becc3dgo0KXMsY8++igks0yP1acskiOOOMIFwbSe5+eff3ZBtUiBM/nrr79s4cKFbh3Re+oDBb+vpnsuW7Ys6vsCAAAAAIDim/zPXLjW3UfjNfcPFq25vyhg1q19AwJnSBlxBc9EpZDjxo2zF154wX788Ue77LLLbNOmTYHpmwMHDgwZKKDnNW3z6quvdkEzTeYcPXq0GyDgue666+x///ufLVmyxE3l7Nu3r8tUO/vss93zderUceWbeu+PP/7YDRDQ+ylwxqRNAAAAAADiN+GLZXbEmGk2YNwcd6/HkXhTLBUwk+KmWAKpJu6eZ/3797c//vjDbrnlFld62aVLF5s6dWpgiICywTSB06M+Y++9955dc801rp9ZixYtXCBN0zY9v/32mwuUrVu3zk3jPPLII2327Nnuz56HHnrIbff00093UzR79+5tjz/+eMmPAAAAAAAAaUaZZiMmzQuUY+p+5KT51n2vRhGDYv27tnbPUY6JdJTQwIChQ4e6WyTTp08vtEwZYgqGRfPKK68U+57VqlWzxx57zN0AAAAAAED0wNjitZtcuWW0IJeeD+9jlufzueBYtNdoOUEzpKNSn7YJAAAAAAB2DZVeehll6lOmcktljUXrYxYcQCuqjxmQzuLueQYAAAAAACpOKWakYQD0MQNiR+YZAAAAAAApIN5STPqYAbEheAYAAAAAQAr0MkukFJM+ZkDxKNsEAAAAAKAC9DI7Ysw0GzBujrvX43CUYgKlg8wzAAAAAAAqYC8zlVyGB8YoxQSSj+AZAAAAAADltBQzkV5mlGIiJvl5Zktnmv31u9luTczaHG5WKbPk66YggmcAAAAAAJQBlV56GWXqVaaSS2WOJaOXGVJMsgNdP7xtNvVGs5yVBctqNzc74R6zff6W+LopiuAZAAAAAADluBTT62Wm55VxRi+zNAuIJTvQpXVeHWhmYemMOav8y898MbF1U1j6Bc82bTKrVctsZwNF277dLDfXrHJls6pVQ9eT6tXNKu2cq6D1tH5mplm1aomtu3mzmc/nX6bnZMcOs23b/K/VNmJdV/vs2bLFLD/f/xm85Xl5Zlu3Ft5uUevquNQI+n8vtEzPValilpUV/7p6H72f1KxZsK4+gz6L1tP68a6r46LjI9qH8PMZz7qxnPtkfE8inc9kfE+88xnPurGc+5J+T6Kdz5J+T4LPZ0m/J5HOp5brdZ6K/BsR67nnN4LfiETOfRzrVtJn0LHQeavovxHxrstvBL8R8a4by7n3pMhvREr9d0S86/IbUT5+I7ZssQwdU88u+o3wSjGz8nKtcl6e5VXKtO2VswpKMcPOvetl1q6uLVu1wVo3rmXNmtQr+nzyG1F2vxHbtpqt+MIs98+CoNiWraHrKig1+QazDSv9oxwrZxQEudocV3DuF0z2B6ny8s3yrGBdL3h1ytNmHU+Obd1Tx5nt1dtsyg0FwTB9CXeYmXbfHbIMs6nDzVr38H/GWNZtc6z/z2HnM1PnQ8feOxfl8TciVr40kZ2drbPty9ZHXrOm4Ik779TXwee76KLQF9So4V++eHHBsoce8i8bMCB03YYN/cvnzy9Y9vTT/mWnnRa6bps2/uWff16w7N//9i/r2TN03X328S//+OOCZW+84V92+OG+7du3+95880137zv4YP/yyZML1n3/ff+y/fcP3e7RR/uXv/pqwbJPP/Uv22OP0HVPOsm/fPz4gmXffONf1rx56LpnnOFf/uijBct+/tm/rE6d0HUHDfIvv/fegmW//eZfVrly6LqXX+5fPmpUwbI///Qv002f33Pddf5luvfoeW9dvc6j7WmZth9M76/l2h+P9lPLtN/B9Lm0XJ/To8+vZToewXS8tFzHz6PjqmU6zsF0HrRc58Wj86VlOn/BdH61XOfbo++Blul7Eezww/3L9T3y6PulZfq+BdP3Ucv1/fToe6tl+h4H0/dcy/W99+h60DJdH8F0/Wi5riePrjMt03UXTNellus69ej69c5nsKuv9i8bObJg2V9/FayrP3u0jpbpNcF2rjvlhRf811UF/40IwW+EH78Ru/w3QtfSykMOSanfiFT574gQ/EZUqN8I778Bc595psL/RqTif0fwG1ExfyN+7N+/4L//kvAbkXOj/3vy10UXR/2NWLlhs6/d8Mm+u465wC17rdNxvt2Hv+OWO/x3RPn7jbj8PJ/vu9d8vkUzfL6c7Mi/ERfv/K4eWsXnG1Xbf3ugQ+hvxPdv+Xyj6vh8Par6lx2QtXPdOv5b9Z3LF/7qf62e671zWefKBdvVujUz/cu/+7Zg3VOq+ZftHbZuvaydv0k1C5b3re5ftntm0Lq1fb492+78u6tGwbL+O9dtFbZu5w6FfiNyp0xxy/L3269c/0YEYkXZ2b6ipF/mGQAAAAAApdjHbPWni+1qM5v09Qqr8sWyiH3MvFLMxXMmucdK5qEUswz8ucRs3kR/hliNPSOvs26R//67CWavv+X/c9WmhddTNtkP/y28XJlfwaWaKqsML4N0tCzDLG+7/+GKr0LLLyOt78v3/3Hl3OLXzVfaWIziWjfXUl2GImiWBnJycqxOnTqWvXKl1W7aNCVSqXMrV7YpU6bYSSedZFlansqp1KlWbkEqddmnUkc5n7m5uTZl+nQ76eSTLUvbqsC/EWlVbsFvRLn9jdA1NfXNN+2E44+3LMo2+Y2Id11+IyKez9z8fP9/A+q60rIK/BsR97nnN6LodfmNiH4+i1g3d8sWe/fDD+3E007z//dfCX4jVuVstSPGTLPMHQWlmHlZVezT4T0ilmLKqj+ybdnqbGvdpLY1a1w3eec+Bf47Iu5zr3Vzt5ut+sps2zp/QKzVYWbbthded+7rZu+ONNu8StMX/MtqNTM7+nZ/GaS3rgJiL5/nL1nUIfDWVSRFMaN+48wO+rs/iDW2k9mfK0JLJj3bd27/zCfN/u+0nZ/ZF2Vdn9k5E812bDB7Y0jx6572uFm1KsWvm+szO3yY2Zyx/gkVhUoxg9Y9c6L/ezLhjOLX7f+6WetuIeczd+tWe++tt6z3iSdaVu3a5fY3ImfrVn+sKDvbagfvZ5j0yzzTAfN+/EQH1vvhC18vnE5ApJrYeNYNPrkefWGC+5fFum5wXX7wj5ZHP26R9i2edYN/ZBNZVz+okdbVhRL8HxDxrqtzGGndSOcznnWlpOvGc+6T8T2JdD7jWbe0vifRzmdJvyfRzmdJvyeidXVdpcpvRDB+I/z4jSiT70m+jk1w4Kwi/0aUZF1+I+Jfl9+IyOdT/xiIdd0K8BuRUv8dUZJ1+Y0ou9+ISpXMF3w8izj3q7bk2eLVOW76pQuGha3r9THLz8yy3Myd2/T5CvqYRdhus0Z13K0Q/jsi/nO/6P3YGusrIPbmYH8EzAuGycbVZpMvNquxswm+lyXmPm7Qet7DKhlmM241O/B0f+N/va+2F2kIpn4Ktq0yW/Jp0GeOtq5Gq+aY1W4W27qN24Qui7auAl4djjX76bWd2XA7x7yG/Ezt7L2m9aRui+LX3btH4UEHmZmWp3MXfq7L22+Egm4x2Bm+BgAAAAAA0agcU1llA8bNcfd6HE5BNS9Jx6PJmG0bRghYIT4KZC3+xF9iqXs9DuZNhQwvXfSa5ev5mMomzd8E35uEWVwpZM6KgomZsQj7fkTlDRpQcCrqixS8auFfL9Z12x3lDyZG3Jmdj08Y4w+G6RbruimO4BkAAAAAAEVYlb3FRkya57LKRPcjJ813yyP1MVPATHRPH7MkUOBLJZEvnGL2+mD/vR6Xl4CY1lOwKxZtjow9IBZP8CqedZVVd+aLoZltov3S8uAsvXjWTWHpV7YJAAAAAEAcvHLMYHnB5ZhBNByg+16N3HPKOCNwVgQvmOUFn7yAUaSMsvDAmJdRpgBO9XplGxALzhLzShwL2Vni6GV+uc+UEbZuhGwuL3gVsRx1TORAV6zrdji5+OMf77opiuAZAAAAACBtrcrear9kZ7j71g0j9AgLKscMDqAVVY6pgBlBs2IoKFZcf7JYJlMqo6znrWUbEAvOEoslKBZPkKs0A11apmBeLCrFsW4KIngGAAAAAEhL6lvmL8fMtMd/nOFKLpU5Fs4rx1SppjLOKMcsoViyyRQEirXEctMfZR8QK83MLyHQVaYIngEAAAAA0k60PmYquYwUFKMcM0mlmLFmkymwFGuJZc1G5SMgVpqZXyhTBM8AAAAAACkXGFOfMpVbRgtyxdPHzEM5ZhJKMeNp2B9riWWtZuUnICYExVIOwTMAAAAAQAqWYprrUxatFDPePmZpr7iMslhLMeNp2L9v3/gyygiIoZQQPAMAAAAApF0pptfHLDjQRh+zBDPK4inFjKdhfyIllgTEUAoIngEAAAAAUkK8pZjKSOvWrp69OuVjO/OkHta6Ya1dt7MVRSwZZdXrxV6KGU/D/kRKLAmIoRQQPAMAAAAApEQvs0RKMZvVqWZ71vG5+7STrOb+PW+N7f30PvFmkyWSUQYkGcEzAAAAAEBK9DLzSjFVqqmMMwXOKMXcBc39N/0R23t6JZvxZpMJGWUoQwTPAAAAAAAp08tMATUtV6mmMs4InEWQ7Ob+NRvFV4opZJOhAiF4BgAAAAAot6WYifQy07K0DZolqxQznub+tZrFX4opZJOhgiB4BgAAAAAot6WYifYyS0vJLMWMt7m/AmHxlmICFUSlst4BAAAAAED6iVaKqeXhvF5mCphJWvYyU8bY4k/M5k303+txpFLM8MCYV4qp5yXWUszg5v7BGWRFZZQpQDZsvtmgyWanP+u/HzaPwBkqPDLPAAAAAAC7XLylmGndy6y4jLLSKMVMtLk/pZhIQQTPAAAAAAC7vI9ZIqWYadnLLJbm/tXrlU4ppofm/khzlG0CAAAAAJLax+yIMdNswLg57l6PI6EUM4ZSzGIzysyfUbZRgbBSKsUMzyjrfIb/nsAZ0giZZwAAAACAUu1jpnJLSjFLsbn/pj9KtxQTSHMEzwAAAAAASSnHjLePmVCKGaUUUwGsWJv712xEKSZQigieAQAAAACKpfJLL6tMvcpUcqnMsZL2MUs5KrUsKiBVGs39azXzZ6y5gFxG2LZjKMUEUCR6ngEAAAAAEirH1PJgad/HTBllYzuZvXCK2euD/fd6rOWeWEsxg5v7F+pNFpxR1sK/nleKWbtZ6Cp6vZfJBiAhZJ4BAAAAAIoUTzlm2vYxS3YpZnBz/1gzyijFBEoFwTMAAAAASGPF9TFLpBwz7fqYlUYpZqLN/SnFBJKO4BkAAAAApKlY+pgFl2OqVFMZZ2lXjllcL7NESjFp7g+kds+zxx57zNq2bWvVqlWzQw891D7//PMi19+wYYNdccUV1qxZM6tatarttddeNmXKlMDzd999t3Xt2tVq1apljRs3tj59+thPP/0Uso1jjjnGMjIyQm6XXnppIrsPAAAAAGkv1j5mHgXVPh3ew/4z5DB3HynIlra9zBIpxXTCe5nF0Ny/8xn+ewJnQPkNnk2YMMGuvfZaGzVqlH399de2//77W+/evW3NmjUR19++fbsdf/zxtmTJEps4caILio0bN85atGgRWOd///ufC67Nnj3bPvjgA8vNzbVevXrZpk2bQrY1ZMgQW7VqVeB27733JvKZAQAAACClKQA2c+HaqIGw4vqYRaNMs27tG6RXxpnXyyw8s8zrZabnEy3FpLk/kJplmw8++KALYl1wwQXu8ZNPPmnvvPOOPffcczZ8+PBC62v5+vXrbebMmZaVleWWKWst2NSpU0MeP//88y4D7auvvrLu3bsHlteoUcOaNm0a7y4DAAAAQNqItRQz3j5mKSk/zzKWfmot1s+yjKW1zXbvHprRFWsvs6vmUooJpLC4gmfKIlNAa8SIEYFllSpVsp49e9qsWbMivubtt9+2bt26ucyyt956yxo1amQDBgywG2+80TIzI/8oZGdnu/v69euHLH/ppZfs3//+twugnXrqqXbzzTe7gFok27ZtczdPTk6Ou1dWm26pwPscqfJ5gPKA6wpILq4pIPm4rlCUVdlbC5Vi6nG3dvWsWZ1qIes2rFHZ7jxtH7vprR8CgbY7TuvolqfD9ytjwWTLfH+kVd640g7WgqVPmK9Wc8vrNdp8HU7xr7P0U6scQy+zHUs+Mzt+tGW+riSTDMsICqD5dpZi5h1/l/ny8s10C9bysII/R3oeqIByK8jfVbHuX4bP54sUFo9o5cqVrtxSWWQKiHluuOEGV3o5Z86cQq/p0KGDK9k855xz7PLLL7dff/3V3V911VWu9DNcfn6+/e1vf3N90j799NPA8qefftratGljzZs3t++++84F3w455BCbNGlSxH299dZb7bbbbiu0/OWXX44acAMAAACAiuyX7Ax79IfCSQpD98mzPetE/qffhm1mf2zNsEbVfFa3qqWFZhu+sK6LHynUdcw7Ql+0u9JW1e3qMtIOXvpEsdv7ss1ltqJ+N7fdzr+9ZNVz1wee25xV3+a3PMdtD0D5snnzZpfgpSSu2rVrl13wTMMBtm7daosXLw5kmqn087777nN9y8Jddtll9u6777rAWcuWLaPuy7Rp0+y4445zwbj27dvHlHnWqlUrW7t2bZEHpCJRhFQ94tRTziuJBVAyXFdAcnFNAcnHdZXelFm2dN1ma9OgRqFMMu/5Yx6YEVKKqYyy6f/oHnH9lC3FXD4rUArpa9WtUClm5UcPMNu4slC7/kCmWO3mtuOKr912Kv+7T7FvuePcN83X5sjY3h9IA7kV5O8qxYoaNmxYbPAsrrJNbVABsN9/D50kosfRepFpwqYOVHCJZseOHW316tWuDLRKlSqB5UOHDrXJkyfbjBkzigyciaZ8SrTgmaZ66hZO+1KeT1wiUvEzAWWN6wpILq4pIPm4rtJPLL3MWjfMcss1NVPN/9XDbHS/Tta6YS1LC2rerx5lwaWW6jWm6ZZeE/7Fs13gLBpXcpmzwrJWfuHvgRZDL7PKIb3Sssz26JHkDwZUTFnl/O+qWPctrmmbCnQddNBB9tFHH4WUWepxcCZasCOOOMIFuLSe5+eff3ZBNS9wpuQ3Bc7eeOMNl1HWrl27Yvdl7ty57l7bAQAAAIBUpqmZ4b3MFCCLNE1TAbVPh/ew/ww5zN1HGhaQtlMxRRlhsdB6Cogp8OaE56ntfHzCGDLLgBQXV/BMrr32Whs3bpy98MIL9uOPP7oyy02bNgWmbw4cODBkoICe17TNq6++2gXNNJlz9OjRboCAR3/WIAD1I6tVq5bLStNtyxb/XwQLFy60O+64ww0rUP80DSHQ+2gS53777ZecIwEAAAAAZUABsJkL10YMhHkWr90UUoopyixbsnZzxPWb1alu3do3cPdpodipmOafiqn1NNUyFt56ylg780Wz2mGJG8pI03Ivow1AyoqrbFP69+9vf/zxh91yyy0uwNWlSxebOnWqNWni/2FZtmyZm8DpUZ+x9957z6655hoX6FLPNAXS1PDf88QT/gaMxxxzTMh7jR8/3s4//3yXofbhhx/a2LFjXaBO2zz99NPtpptuKslnBwAAAIByX4op7RrWdM8HB9BUktm2YRoNQ1Pga+nMQC8xa3N4QcaXlscwFdOtp9fFUIrp1vMoQNbh5OjvDyClxR08E5VY6hbJ9OnTCy1TSefs2bOjbq+4mQUKlmkgAQAAAACkeilm970aFcoY0+NIvczSJrOsuF5miZRiqpTTlV76YivF1ON2RyXhwwBIi+AZAAAAAKBkiirFjBQUU0aaAmt6XhlnaRU4c4EuX+ReZiqdTLQUM2JAbgylmABCEDwDAAAAgFLIKlNwTOWW0YJciZRialspFTQrqhQzpl5mGf5eZlfNTbgUc8eiGTb3k/esy1G9w6ZmAoAfwTMAAAAAKIM+ZpRiFlOKGU8vs+VzEi7F9LU50lZ8n2P7tzmSwBmAiAieAQAAAEAZ9DETSjGLKMWMt5dZ5zMoxQRQKgieAQAAAEAZ9TETSjGjlGJqumUivcyYigkgyQieAQAAAECSepkl0scspSSzFFPrKfAVby8zpmICSLJKyd4gAAAAAKRqL7MjxkyzAePmuHs9jtbHTAEzSas+Zl4pZnhgzCvF1PMSTymmAmEKvAX3LoullxkAJBGZZwAAAACQxF5madnHrLRLMellBqAMETwDAAAAkNaKK8VMpJdZyvUxK66XWWmXYtLLDEAZIngGAAAAIG2p9NLLKFOvMpVcKnMsHL3Miulllkgpppu2mREWQCuiFJNeZgDKCD3PAAAAAKSlaKWYWh6OXmbF9DJLtBSzdrPQ5xWQ03JKMQGUI2SeAQAAAEhL8ZZipmQvs6JKMePpZXbVXEoxAaQsgmcAAAAA0rKPWSKlmCnVy6y4Usx4epktn0MpJoCURdkmAAAAgJTrY3bEmGk2YNwcd6/HkVCKWUwppsTTy4xSTAApiswzAAAAACnfx0zllpRixlmKqZLKRHqZUYoJIMUQPAMAAACQtn3MhFLMKKWYWk+Br3h7mVGKCSDFULYJAAAAoEJlls1cuDbiRMzgPmbBiutjljJKoxRTgTAF3pywA1tULzMASCEEzwAAAACkTC+ztO1jVmwppvlLMbVeIqWY9DIDkMYo2wQAAACQUr3MUrKPWXG9zEq7FJNeZgDSGMEzAAAAACnXyyyl+pjF0ssskVJMlXK60ktfbKWY9DIDkKYo2wQAAABQrvuYCb3MiullRikmAJQaMs8AAAAAlBn1LfPKMRUcU78ylV1G62WmUk1lnKVML7OiSjFj6mWW4e9ldtVcSjEBoJQQPAMAAABQ7vuYpWQvs+JKMePpZbZ8DqWYAFBKKNsEAAAAUO76mEWjgFm39g1SI3BWXCmmxNPLjFJMACgVZJ4BAAAAKJWsMgXH1KssWqDL62MWHEBLiT5mySrFVEllIr3MKMUEgKQieAYAAAAgqdK6j1kySzG1ngJf8fYyoxQTAJKK4BkAAACApEnrPmZeKWZ4kMsrxfRKJ+MpxVQgLJFeZgCApKHnGQAAAICkSds+ZsWWYpq/FFPrJVKKSS8zACgzZJ4BAAAASFovs5TtY1ZcL7PSLsWklxkAlBmCZwAAAACS1sssJfuYxdLLbFeUYtLLDADKBMEzAAAAAEntZZZSfcxi7WWWaClmxIDcGEoxAaAcIXgGAAAApLniSjGL62UW6TVaViGCZkWVYsbUyyzD38vsqrmUYgJAiiJ4BgAAAKSxWEoxU7aXWXGlmPH0Mls+h1JMAEhRTNsEAAAA0lS0UkwtD+f1MlPATCp8LzOvFDM8MOaVYup5iaeXGVMxASAlkXkGAAAApKl4SzFTppdZrKWYKqlMpJcZpZgAkFIIngEAAABp2scskVLMCtHLrLg+ZrGWYmo9vTbeXmaUYgJASiF4BgAAAKRpHzOvFFOlmso4q/ClmLH2MYunFFOBsER6mQEAUgbBMwAAACAN+pip3DKlSzGD+5iFZ4h5fcy8vmOJlGLqtRGDcmPoZQYAKY7gGQAAAJDGfcwqTClmceWY8fQxS6QUk15mAJC2CJ4BAAAAFciq7K32S3aGu2/dMCspfcxSohwznj5m6keWSCkmvcwAIC1VSuRFjz32mLVt29aqVatmhx56qH3++edFrr9hwwa74oorrFmzZla1alXba6+9bMqUKXFtc+vWrW4bDRo0sN12281OP/10+/33GHsVAAAAACnSy+yYB2bYoz9kuns9jtbHTAEzSZk+Zgp0hQfHvHJMPR9PH7PgUszazUKfV0DOK+8EACCRzLMJEybYtddea08++aQLco0dO9Z69+5tP/30kzVu3LjQ+tu3b7fjjz/ePTdx4kRr0aKFLV261OrWrRvXNq+55hp755137LXXXrM6derY0KFDrV+/fvbZZ5+V9BgAAAAAKdXLLKX6mMVajtnnidi2F9zvjFJMAEBpBM8efPBBGzJkiF1wwQXusQJeCmo999xzNnz48ELra/n69ett5syZlpXlTytXhlk828zOzrZnn33WXn75ZTv22GPdOuPHj7eOHTva7Nmz7bDDDov3YwAAAAAp3cssJfqYSazlmD5f/H3MhFJMAEAyg2fKIvvqq69sxIgRgWWVKlWynj172qxZsyK+5u2337Zu3bq5ksu33nrLGjVqZAMGDLAbb7zRMjMzY9qmns/NzXXLPB06dLDWrVu7dSIFz7Zt2+ZunpycHHev7eiWCrzPkSqfBygPuK6A5OKaAmKj/mVL1222Ng2UJVYt4jot61Qt1MtMj1vUqVJhr7GMBZMt8/2RlrGxIDjmq9Xc8nqNNl+HU/zrZK+I6R8tOzauNjt+tGW+rv9DPsMyggJovp19zPKOv8t8eflmugE78XcVkL7XVW6M+xdX8Gzt2rWWl5dnTZqEjnbW4wULFkR8zaJFi2zatGl2zjnnuD5nv/76q11++eVuB0eNGhXTNlevXm1VqlQJKfX01tFzkdx999122223FVr+/vvvW40aFbxZapgPPvigrHcBSDlcV0BycU0B0c36PcMmLKrkAjwK+PTfPd+6NYmUOWV2ZrvQdc9sl2/ffDbNvrGKp9mGL6zr4kcKP7FxpWW+fr590e5KW1W3qzXYuMSOjGF7s+cvsXW1OlqzdkOt828vWfXc9YHntmTVs/ktz7FViyqZLQrtvQx4+LsKSL/ravPmzeVj2mZ+fr7rW/b000+7TLODDjrIVqxYYffdd58LnpUWZbKpj1pw5lmrVq2sV69eVrt2bUsFCkDqi6iecl5JLICS4boCkotrCig+4+yaB2YEcqQUFHt1caZd3q97xAy0k8zs4nUbbdL7n1q/Xkdaqwa1rFzKz7OM5bMCpZi+Vt1CSzHz86zyo8ODZ1sG+GdfZljXdZNsx1k3mVlv8z36gtnGVSHZZCFZZbWb26F/H7bzPU4yy7/JdgS9f1arbnZApUw7oLQ/Nyok/q4C0ve6ytlZpZjU4FnDhg1dACx8yqUeN23aNOJrNGFTB0qv86hXmTLGVLIZyzZ1r3U1tTM4+6yo99VUT93CaV/K84lLRCp+JqCscV0BycU1BUT2W3Z2oT5merwie7u1bhg5MKaA2Z51fO6+XF5XmnypBv/BfcrUa+yEewomWC6e7TLMonFBspwVlrXyC38/shPv8U/V3BlaC17TBd9OGGNZVYODjVlme/RI/mdDSuPvKiD9rqusGPetUjwbVemkMsc++uijkMwyPVZfs0iOOOIIV6qp9Tw///yzC6ppe7FsU8/rAwWvo0mcy5Yti/q+AAAAQFlPx5y5cK27j6Zdw5qub1mwzIwMNyGzQlLgTEGu8Ab/auKv5XpelBEWC289Bd3OfNGsdrPQ5xWU03IvKAcAQCmIu2xTpZCDBg2ygw8+2A455BAbO3asbdq0KTApc+DAgdaiRQvXc0wuu+wye/TRR+3qq6+2K6+80n755RcbPXq0XXXVVTFvs06dOjZ48GC3Xv369V3ZpbalwBmTNgEAAFDeTPhimY2YNM9lkSk4dne/zta/a+tC62kapp4bOWm+m5ypwNnofp0qxpTMSFMzlXEWcdKllmWYTR1u1uFk/1TNWASvpwCZXlvUZE4AAMpD8Kx///72xx9/2C233OJKL7t06WJTp04NNPxXNpimZXrUZ+y9996za665xvbbbz8XWFMgTdM2Y92mPPTQQ267p59+upui2bt3b3v88cdLfgQAAACAJFKmmRc4E90rONZ9r0YRg2IKqum5JWs3u4yzch04U4AsWvBKy8MzzkL4SzHdenqdssaUkRYx2ObvY+bWC6b3UhknAAC7UEIDA4YOHepukUyfPr3QMmWIzZ49O+FtSrVq1eyxxx5zNwAAAKC8Wrx2U6E+ZsoqU3AsWmBMy8t10CyWXmbxlGIqCHZC9D5mzgljyCoDAJQLcfU8AwAAAFC0lOtjFmsvs3hLMeljBgBI5cwzAAAAIJ3LMpVdpiBZpGyxlOpjFk8vs6vmxl+KSR8zAEAFQPAMAAAASPIggJTpYxZPL7PlcxIrxaSPGQCgnCN4BgAAAJTCIICU6GMm8fQy63yGv+Qy4jbHUIoJAKiQCJ4BAAAApTQIoEL0MQsvsfT6mHl9xxLpZUYpJgAghRA8AwAAQNorro9Z8CCA4ABauR0EUFwpZqx9zBQE02vj7WVGKSYAIIUQPAMAAEBai7WPWYUZBBBLKWasfcy0noJgifQyAwAgRRA8AwAAQNqKt49ZuR8EEGspZjx9zESvoZcZACBNETwDAABA2kqkj1m5HQQQTylmvH3MhF5mAIA0RfAMAAAAKSnl+phJfp5lLP3UWqyfZRlLa5vt3r0geBVPKWYifcyEXmYAgDRE8AwAAAApJ+X6mAX1Mqucs9IO1uOlT4T2MounFFNBMPqYAQAQE4JnAAAASCkp18cs1l5m8ZZi0scMAICYEDwDAABASkmpPmbx9DK7am78pZj0MQMAoFgEzwAAAJBSvcwqYh+zIoNXsfYyWz4nsVJM+pgBAFAkgmcAAABIqV5mFbGPWeGyyZ19zCSeXmadz6AUEwCAJCN4BgAAgJTrZZYyfcwU7EqklxmlmAAAJA3BMwAAAKRkL7OU6GOmIJgCX/H2MqMUEwCApKmUvE0BAAAApcfrZRas3PYyU3Bs8Sdm8yb67/U4WKx9zLSeAmEq43TCDkBRvcwAAEBSEDwDAABAuSjJnLlwrbuPxutlpoCZlNteZirHHNvJ7IVTzF4f7L/XYy33xNPHzCvFVBln7WahzyvjzCvvBAAApYKyTQAAAJT7IQAVppdZafUxC+pltmPRDJv7yXvW5ajeVnn37mScAQBQysg8AwAAQLkbAlBcBlq39g3KX+Cs2D5m5u9jpvW8PmaFyjCD+5i1CO1jJpUyzdfmSFtRv5u7J3AGAEDpI3gGAACAcjkEoFwqqpcZfcwAAEhJlG0CAACgVCh7TMExNfqPliXmDQEIDqCV2yEAKslUZllwgEzZYwqCqaQy0T5mEbc5hj5mAACUEwTPAAAAUGZ9zLwhACrVVMZZuR4CUFwvsxL0MXPZaAqq6TmVapJxBgBAuUHwDAAAALukj5ka/UcKipX7IQDF9jLL8Pcyu2quP2tMAbWI66qPWfOIfcys3VGltfcAAKCE6HkGAACAMu9jVqZDAIrqYxZPL7Plc+hjBgBACiLzDAAAADFLuz5mEk8vs85n0McMAIAUQ/AMAAAAMUnLPmYKdsXby4w+ZgAApBSCZwAAAChW2vYxUxBMga94e5nRxwwAgJRB8AwAAAAl6mMWLTCm5WUWNFNwrKjMr1j7mGk9BcFUxumy1NS7LPhA0MsMwK6Vl5dnubm5Zb0bQJH0Ha1cubJt3brVfWfLSlZWlmVmlvzvZ4JnAAAAKFZa9zETvY5eZgDKkM/ns9WrV9uGDRvKeleAmL6vTZs2teXLl1tGRvgQnV2rbt26bl9Ksh8EzwAAAFDsIIC072Mm9DIDUIa8wFnjxo2tRo0aZR6QAIqSn59vf/31l+22225WqVIlK6sA3ubNm23NmjXucbNmzRLeFsEzAACANBfrIIC072Mm9DIDUAZU9uYFzho0aFDWuwPEFDzbvn27VatWrcyCZ1K9uv+/VRRA0/WTaAln2X0CAAAAlNtBAFoeiQJm3do3KNteZos/MZs30X+vx4n0MVMQTGWcTnj2Bn3MAJQvXo8zZZwBiI933ZSkVyCZZwAAAGkskUEA5baXGX3MAKQ4SjWBsrluCJ4BAACkaR+zCjUIIJZeZvQxAwAApYCyTQAAgBTtY3bEmGk2YNwcd6/HkXiDABQwk3I5CKDYXmbm72XW6lB/1lihMszgPmYtovcx63yG/57AGQCUe9OnT3cZRbFOHz3mmGNs2LBhpb5fqWTJkiXuGM+dO9fSHZlnAAAAadLHTM3+IwXFynwQgIJjRWV+xdrLbPkcfwmny1DLCAu20ccMAHa1888/31544QX356ysLGvdurUNHDjQRo4caZUrlywccfjhh9uqVausTp06Ma0/adIktw/lOVDVrl27qM+3bdvWFi9evEv3CQUIngEAAKSYRPqYaXmZZJsV18dM4ullpuwx+pgBQLlxwgkn2Pjx423btm02ZcoUu+KKK1wQa8SIESXabpUqVaxp06Yxr1+/fn0rz1q1auWCgeG+/PJL69OnjztusdKUSx0fJA9lmwAAACnG62MWrFz3MQvPKvP6mOl5ibeXmQJkw+abDZpsdvqz/vth8wicAcDO7OSZC9dGnaqcbFWrVnVBrjZt2thll11mPXv2tLff9v++//nnny4TrV69em4i4oknnmi//PJL4LVLly61U0891T1fs2ZN23fffV0ALlrZ5meffebKM7UtvaZ3797uPSKVbRb33s8//7zVrVvX3nvvPevYsaPttttuLhAYHuB65pln3PPVqlWzDh062OOPPx4SxBo6dKg1a9bMPa9jcPfdd0c8TpmZme44Bd/0+XTMzj77bLvuuuuiHmN9Nr2PPl/Dhg3d55b58+e7z6V9b9KkiZ133nm2du3awOumTp1qRx55pPucDRo0sFNOOcUWLlxY5PmcX8w2J06caJ07d3bna/fdd7devXrZpk2brKIjeAYAAJBi/+hJqT5mWk9lnPH2MqOPGQAk3A+zNFWvXt0FlbyyTmVWKZg2a9Ys8/l8dtJJJ1lubq57XtlWylibMWOGzZs3z+655x4XtIlEfbmOO+4422effdy2Pv30Uxd4y8vLi7h+ce8tmzdvtvvvv9/+7//+z+3DsmXLQoJYL730kt1yyy1211132Y8//mijR4+2m2++OVCq+vDDD7vtv/rqq/bTTz+59VV+GQvtx+mnn+6CaOPGjSt2fb2nss0UQHzyySddUPHYY4+1Aw44wH1OBcp+//13O/PMMwOvUVDr2muvdc9/9NFHVqlSJevbt6/l5+dHfI8NxWxTgUUF+i688EL7/vvv7b///a/bno5tWpZtPvbYY3bffffZ6tWrbf/997dHHnnEDjnkkIjrKlp7wQUXFIo8b926tdixoffee69df/317s/6ginqHEwR2+HDhyfyEQAAACoc/SPH62WmzDIFyNSvLJKU6WOm9RT8opcZAOzSfpjJpgCKAjTK5LryyitdlpcCSwr2qH+ZKLik8sU333zT/v73v7tglQJIymQSZTJFo/jBwQcfHJL5pUy1SGJ5by+ApUBU+/bt3WNld91+++2B7YwaNcoeeOAB69evn3usnmU//PCDPfXUUzZo0CC3/3vuuafL7lLcQ5lnsdJ7KQvsiy++cFlrxdH76Bh47rzzThfkUkDP89xzz7nP+PPPP9tee+3ljm0wPd+oUSP3GTp16lToPR599NEit/nXX3/Zjh073PHQMpXKduvWzQXl0i54NmHCBBeZ1Bfo0EMPtbFjx7qUQEVRGzduHPE1tWvXds9HC5aFpz2+++67Nnjw4EInUl/SIUOGBB7XqlUr3t0HAABIm3/0pEwfM9Hr6GUGALu0H2YyTJ482WWLKRCljKYBAwbYrbfe6gJpGhqguIJHpYN77723y+KSq666ypUtvv/++67cUzGC/fbbL2rmmRf0Ko62X9x7i8o5vcCZqPxyzZo1gawtBbcUuwiOUyh45A0xUHbb8ccf77arkk+VRaqMsTiKtygR6eOPP7aWLVvG9JkOOuigkMfffvute32kTD3tt4JnCiIqc27OnDmu9NLLOFPQL1Lw7NtitqnPpuw/BTv156OOOsrOPfdcd2zTLnj24IMPui+Gl02mk/rOO++4aGO0LDAFy4pq5Bf+3FtvvWU9evQoFFVWsCyehoAAAACpoqz+0ZNwH7Pwckyvj5kCYAp0xdvHTPS6DicXndEGACiyH2bw3yW7oh+m/m3/xBNPuJLC5s2bxzVl86KLLnLJOoo5KICm6jNleilzLVI5aLKFT+dUbMMrQVSWlaikMjgI5/UvkwMPPNBNyFSC0IcffujKGxUEVF+waFRuqqChMui8rLhYqMdYMO2fylZV6hpOQUDR88qG02fQuVHwTEEzr6w23F/FbFOf+4MPPrCZM2e6DMOnn37albQqOFfUJNGUC57pAH711VchUzGUfqeTrxrhaHSAdUJ0IvTlUYpftPRJ1cvqwvBqhIONGTPG7rjjDjfeVtHqa665JuqFp7po3Tw5OTnuXtHu4Brmisz7HKnyeYDygOsKSC6uqdityt5qS9dttjYNVGJZuDyjZZ2qhf7Ro8ct6lQpP8c3P88qv+vvY1a4KYfPv3TqcNvRvpdZ865WuVZzs42rLCNC3zO3bu3mtqN5V32BQp9seVjBn/Py/bc0wnUFpN81pX1T0Eb/po7Wj6o4TWpVtbv6drKb3phveT4Fzszu7LuvW57oNoujfVb2VnBijPdeysZSlpZiCV6QaN26da5qTY33vfVatGhhF198sbuNHDnSBXrUC8173jsmynZSNptKKYvaH60by3sHbz9833Wv8kYFnJRxpT5f4bx1laWljDjdVM6ovmrK8oo0/XP58uUuu04JS+obFs958T6bR+WVkyZNcvGTSHGTP/74w31elZgqQ8wL3AUf0/BjfEAx2/TWV6nmYYcdZldffbVr9aXXKH5TVrRfOj66jrzApifW6z6u4JlOsJrtaaJCMD1esGBBxNfoS6msNKVWZmdnu2Z7+nKqeVyk9EMFzZRh5tUMexR5VeBNXzBFMRXAU7mnMuEiUUT6tttuK7Rc0WpdvKlEkV0AycV1BSQX11TRZv2eYRMWVXIBIwWS+u+eb92aFA4ondkudL0z2+XbN59Ns2921Y768q3BXz9ZtdwNtjWrrq3bbW+zjII+Jg02/mhHbozex8wFyXJW2JzXxtq6Wh2tWcPTrevGR1zoLDjY5v/kPvuiQT9bNfW9Uv1IFRnXFZA+15QCFarCUmJKtKygWJy4Vx078LKDbdmfW611vWrWpHbVQKJJaVBgQkGqSO+hOIICSQoU6d/1CjLp3/DKYFK2ml6jf/crWWePPfZwzeoVHNOf9Zya+cvGjRtdUo96hB1xxBGBSjllun3yySfWp08fVzao/dCx02tjeW/1aVfAJXjft2zxD+vxlt14442uAk993VWuqAQelY9qXxXgU794vZfiIdrH//znP+6x/hx+TPR+2led58svvzxk8mfwMYsk+LN5NAVTgUZluymeoqmiixYtcoEsDTJQEEnxFWW4KQbz22+/BWIo+pzalpddt2nTJve4uG1+88039r///c8NFdDUTyVfKUinYFtpfs+Ko2Ojz6ShDzpWwbzvUakMDIiHIo66eRQ40xhXRTeVRRZOgbZzzjmnUEM89Vnz6IunC+GSSy5xQTJ9UcPpIgt+jU6UGtap7lY92FKBfoj0A68a6vB0UgCJ4boCkotrKraMs2semBHIvVJg7NXFmXZ5v+6FMtBOMrPLs7fasvWbrXX9yBlqpSVjwWTLfH+kZQQFx3y1mlter9Hm63CKf53vt5j9Wvy2DuvU1nz76tOcZHkLDnLbteCgW+0Wlnf8XXZAh1PsgFL5NBUb1xWQfteUAivKSlKQJ5bm8UXRP4f3jK2NVonpeCrwF+3f4C+++KINGzbMZW4pwKEMqClTpgR6ZCnAowCVAjvahko4FezSn72kGAV+9FjJNpr+eNNNN7mAm8o4NdhQgTQ9r/1QHMHbl+LeW8dZZZrB++6VhnrLFLBTAEqlpOodptJJZcApsKR1FEBSAE2BMH2Wrl27ukq7unXrFjoWCjwp8CaR+o1JtMmh4Z/N20dlkim4p2w2BfZUEahjqPfXZ1MwT8dAcRolPqmnvQJf+px6vdfbrGbNmu5xcdtU8PHzzz938R4vBqNhk+H97Mvi+tFn6t69e6HrJ9agXoYvjpmh+kLpC6r6XEVEPZoiociqepXFQumKOrk6UcEUFdaH0RdGqX1FUeaavlDKeNNJLo4OiJr2KfstlYJnurgVMS+vP/JARcN1BSQX11TxZi5cawPGzSm0/D9DDrNu7RuU7z5mXr6Y18ds8SdmL/gDaUUaNNk/QTPWyZwIwXUFpN81pX/8q3eW+kaVNHgG7KpSyZycHBd/Ketpm0VdP7HGiuL6BIpkaoKDUiWDD4geB2eXFUWR0nnz5gUa1AV79tln3faLC5yJAmw6AdEmfAIAAFSkBs7BdkUD55gpsKUJlxH6kgWWTR3uX09BL02/jNDxzE99zFr41wumQJmCaZ3P8N8TOAMAAOVI3OE/lUKqxlW9yTTCVWNjVf/qTd8cOHBgyECB22+/3fUZUx3s119/7caULl261E3NCI/2vfbaa4WWi5r4KX1QY1G1nZdeesk1m9O2VGMLAABQHq3K3uIyy3QfjSZl3t2vswuYie5H9+u0aydoKvClrLF5E/33euxRRlhO9D5mLoCWs8K/noJeJ3gTuMIDaDsfnzCG4BgAAKhQ4u551r9/f9fwTfW8q1evti5duri6Yq9x3bJly0JS8v7880/XhE/rKtClzDI1/N9nn31CtvvKK6+4ZnyRplSop5mev/XWW11NrVLtFDwL7mkGAABQnkz4YpmNmDTPTcdUZpkCZP27to64rpZ336uRLVm72WWc7dLAmUoylVkWHCBT9piCYCrFVCllLLz19BqVcUbc5hj/8wAAABVIQgMD1BRPt0imT58e8vihhx5yt+J4o2cjUeO/2bNnJ7KrAAAAu5wyzbzAmeh+5KT5LkAWLTCm5bs0aFZUL7OcVf7lCoKpB1ksgtdTgKzDyfQxAwAAKaHUp20CAACkm8VrNwUCZ548n89llu3yAFnCvcwy/L3MrprrzxpTQC3iuupj1jx6HzMAAIAKrmxHHgAAAKSgcjEEoKg+ZvH0Mls+hz5mAAAgrRE8AwAASLUhACrHHNvJ7IVTzF4f7L/XYy33xNPLzOtjVjtsWroyzrScPmYAACCFUbYJAACQSkMAYuljpmBXvL3M6GMGAADSFMEzAACAVBkCEGsfMwXBFPiKt5cZfcwAAEAaomwTAACghEMAKlwfM62nQBi9zAAAFdT06dMtIyPDNmzYENP6xxxzjA0bNqzU9ysdtG3b1saOHRt4rPPw5ptvxvTaW2+91bp06WIVDZlnAAAAOzPLFCBTs/9I2WLeEIDgANouHQKgckxllQUHx5QZpgCY13Msnj5m4vUyi7jdMfQyA4BUo//TZReW359//vn2wgsvuD9nZWVZ69atbeDAgTZy5EirXLlk4YjDDz/cVq1aZXXq1Ilp/UmTJrl9KK+WLFli7dq1KzJgtXjxYiuPVq1aZfXq1bNURvAMAACkvVh6mXlDAFSqqYyzXToEoLT6mAm9zAAgPcTyf8KUghNOOMHGjx9v27ZtsylTptgVV1zhglgjRowo0XarVKliTZs2jXn9+vXrW3nWqlUrF4QK9+WXX1qfPn3ccUum7du3u2OYDE3jOA8VFWWbAAAgrUXrZRZpmqYCap8O72H/GXKYu482LGDX9jEzfx8zref1MStUhhncx6xFaB+z4F5mnc/w3xM4A4DU4v2fMOGl/d7/CRM8jTnJqlat6oIrbdq0scsuu8x69uxpb7/tf78///zTZaIpa6lGjRp24okn2i+//BJ47dKlS+3UU091z9esWdP23XdfF4CLVrb52WefufJMbUuv6d27t3uPSGWbxb33888/b3Xr1rX33nvPOnbsaLvttpsLBIYHuJ555hn3fLVq1axDhw72+OOPhwSohg4das2aNXPP6xjcfffdEY9TZmamO07BN30+HbOzzz7brrvuuqjHWJ9N76ObMvEaNmxoN998s/l8vpDMtTvuuMN95tq1a9vFF1/sln/66ad21FFHWfXq1V0A76qrrrJNmzYFXrdmzRp3DvS8MuNeeumlQu8fXrb522+/2YABA9z6tWrVsoMPPtjmzJkT8pr/+7//c/uk/T3rrLNs48aNgeemTp1qRx55pDv+DRo0sFNOOcUWLlyY0HFNFoJnAAAgrcXby0yZZt3aN0huxllRvczoYwYA2FX/J8wuoCCMgh9eWacyqxRMmzVrlgv2nHTSSZabm+ueV7aVMtZmzJhh8+bNs3vuuccFsSKZO3euHXfccbbPPvu4bSkopKBPXl7kz1Xce8vmzZvt/vvvd4Ee7cOyZctCglgKJN1yyy1211132Y8//mijR492QSuvVPXhhx9223/11Vftp59+cusrYBQL7cfpp5/ugmjjxo0rdn29p0phP//8c/vXv/5lDz74oAvsBdNn2X///e2bb75x+6mAlAKCep/vvvvOJkyY4I6bAlPBx2n58uX28ccf28SJE11wUAG1aP766y87+uijbeXKlfbyyy+797rhhhssPz8/sI7eV8G2yZMnu9v//vc/GzNmTOB5Be+uvfZad34++ugjq1SpkvXt2zewjZIc10RRtgkAANJaue9lRh8zAEBJxPN/wpTiRGUFpxQIUSbXlVde6bK8FABRtpj6l4mCIMp+UmDl73//uwtWKbDTuXNn9/zuu+8edfv33nuvy3AKzvxSploksby3F8B68sknrX379u6xgkq33357YDujRo2yBx54wPr16+ceK9Pqhx9+sKeeesoGDRrk9n/PPfd0WVTKzlKGVKz0XgoyffHFFy67qjja94ceesi9z9577+2CjXo8ZMiQwDrHHnus/eMf/wg8vuiii+ycc84JZORpXxWYUvDriSeecPv/7rvvuoBc165d3TrPPvusy7SLRgGzP/74w2WaKZinLLe99torZB0FwZTZp6w0Oe+889x3Q0FI0TkP9txzz1mjRo3cse3UqVOJjmuiyDwDAAApS6WXMxeujViCGd7LTAEzKZNeZkWV0STax2zYfLNBk81Of9Z/P2wegTMASEfx/p8wSabMImWLKQCk0sj+/fu7iYvK1FJw5dBDDw2sqxI9BX70nKiE8M4777QjjjjCBaqUHRWNl3kWi1jeW1TO6QXORGWCXtaVsqMU3Bo8eLD7fN5N++uVGCprS/ul7eqzvP/++zHtnwJ2Ci69/vrr1rJly5hec9hhh7lAkqdbt24uSBiceafgYrBvv/3WvU/w/qvUVcEtDSfwjtNBBx0UeI1KU1VOGY0+7wEHHFBkjzlliXmBs/DjKtpvlaoqWKrgm5dVpqBZSY5rSZB5BgAA0nYIgEfLu+/VyJVqKuNslwTOii2jyfCX0Vw11581poBaxHXVx6x59D5mAID0lsj/CZNEPXr0cFlMak7fvHnzuKZsKjNKwZx33nnHBUjU10qZXspci1QOmmzh0zkVnPL6iKk8UVRSGRyE8/qXyYEHHuiCUMre+vDDD+3MM890Pd9U/hiNyiYVEFIGnZcVlyzqGxdMn+GSSy5x7xdOk1F//vnnuN+jegznIdJxDS7rVLmtssl0bPWd0XPKOPPKfRM5riVF5hkAAEjrIQCl2sssGWU0y+fQxwwAkLhEh8kkMWCzxx57uGBMcOBMpX87duwIaSS/bt0618NKfcuCyxEvvfRSmzRpkis5jNb/a7/99nOlf7GI9b2L0qRJExfYWbRokft8wTeVb3qUOaVsO+23eoopm2z9+vURt6neYipZVDN/BQ7jEd6Qf/bs2a600QvkRaIglEohw/dfNwU7lWWm4/TVV18FXqNjFDykIdJ5UFZYtM9YHO883HTTTS6TUOfKG/oQLJ7jmgwEzwAAgKX7EIBSUdQQgHjLaLw+ZrWbhT6nfwxpOeWYAIBoyukwGQV2TjvtNNeTS9lWKiE899xzrUWLFm65qBeXeqQpy+jrr792Teuj9dsaMWKE6w92+eWXu/LOBQsWuIy3tWvXJvTesbjttttcNpz6hClLS33Gxo8f75r1i+7/85//uH3R86+99pobABCp7HHr1q2uKb72Yfjw4bZ69epCt6KopFFN9hV40ns+8sgjdvXVVxf5mhtvvNFmzpzp+qsp4KVyybfeeiswMEBlkRoocMkll7jgnIJoCuoVlV2mckt9RvWBUwBPwUUFtjSUIRaafqoS2qefftp+/fVXmzZtmvtcweI5rslC2SYAAEg55X4IQCJlNHpdh5P9GWsKqGm5sgTIOAMAFKecDpNRoEkBnlNOOcWV5HXv3t2mTJkSKOtTvy5N3Pztt99cppECOWqCH4ma0qu0c+TIkXbIIYe4AI/KKRXMSeS9Y6FAkvqi3XfffXb99de7LDsNN/Aa8KuvlwYZKCilDDA13dd7aHpkOC845WXbReKVjEYycOBA27Jli/vsei99NmWwFUVZYpp0+c9//tOOOuoot331eFNGV/Bxuuiii9wQAWXbqaebJnVGo4w1nQcFvFROqXOobL7HHnvMYqFj88orr7hSUpVqKoCn4OQxxxwTWCee45osGb6ijn4KycnJsTp16lh2dra76FKBJn/oC6JxuvFc4ACi47oCyv81pdJLZZYpQFZUiaV6nqlUUxln3hCAaD3PSmUIQKH+ZDv/330vU0yZaGM7Fd/LTI3+CZAhCH9XAel3TSkrSdlXKgeMZfJiVPq7h/8TJuUosNSlSxcbO3aslRf5+fkuDqP4S2kGtUp6/cQaKyLzDAAAVBgpMwRAGWReGY0LtGWEvYZeZgCAUsAwGSAh9DwDAAAVQrkYAlBcH7NYhwBoPaGXGQAAQLlH5hkAAKjwQwB2SVZZLH3M4hkC4KGXGQAAKIHp06eX9S6kPIJnAACgQijTIQDR+pipX5mWe1li8Q4B8FBGAwAAUG5RtgkAAMoFlV/OXLg2ahmmssvU40wBM/GGAJR61lmxfczM38dM6yljTNloXs+yiEMAWvjXAwAAQIVA5hkAAKgwgwBKbQhAUdPH4uljpuwxhgAAAACkFIJnAACgXA4CUJAsUnBMy5KabVZcL7N4+5h5QwAibnMMQwAAAAAqGIJnAAAgfQcBxNLLLJE+ZgwBAAAASBkEzwAAQHoOAii2l1mGv5fZVXP9WWMKqEVcV33MmhfuY8YQAAAAgJTAwAAAAFBqVmVvtV+yM9x9NGU2CCDWXmbL5/hLOJ3wQQD0MQMAoDT8/vvvdvvtt9uff/5Z1rsCkHkGAABKewhApj3+44yoQwBKbRBAUUMAJJ5eZp3PoI8ZAAC7SH5+vp177rl23HHHWb169cp6dwAyzwAAwK4bAqDl0Shg1q19g+QEztTLbGwnsxdOMXt9sP9ej7XcE28vMwXIhs03GzTZ7PRn/ffD5hE4AwAgivPPP98yMjLs0ksvLfTcFVdc4Z7TOuHGjBlj7du3t+HDhyd1f9q2bWtjx4618ua7776zo446yqpVq2atWrWye++9N6bXPf/887bffvu51zVu3NgdU8+SJUvc8Q2/zZ49O7DOuHHj3PsqQKlbz5497fPPPy+Vz1jRkXkGAADSbwiAAl7KRIu3lxl9zAAAiIuCQa+88oo99NBDVr26/78Btm7dai+//LK1bh05I33kyJFWVvLy8lyQqVKlXZNrlJOTY7169XKBqyeffNLmzZtnF154odWtW9cuvvjiqK978MEH7YEHHrD77rvPDj30UNu0aZMLmIX78MMPbd999w08btCgQeDP06dPt7PPPtsOP/xwF4C755573L58//331qJFi1L4tBUXmWcAAKDUhgAEKx9DAMw/BEDrKRBGLzMAQEW3aVP8tx07Cl6vP2vZlrDs8EivS8CBBx7oAmiTJk0KLNOfFTg74IADQtadOnWqHXnkkS5wpCDPKaecYgsXLgw8/+KLL9puu+1mv/zyS2DZ5Zdfbh06dLDNmzcXuR/HHHOMLV261K655ppAFpaXvaX3e/vtt22fffaxqlWr2rJly9z6w4YNC9lGnz59QjLltm3bZtddd50LNNWsWdMFsRSQisdLL71k27dvt+eee84Fuc466yy76qqrXHAsGvWBu+mmm9zxGDBggMvSUwba3/5WOBtex7Fp06aBW1ZWVsh76/h16dLFHcNnnnnGlcx+9NFHcX2GdEDwDAAAxEWllzMXri22BFM9zrwAmu6TMgRAQa/Fn5jNm+i/1+NEhgBoPVEGmjLRajcLXU0ZZ16GGgAA5dluu8V/e+ONgtfrz1p24omh223btvDrEqRMqvHjxwceK1B0wQUXFFpP2VPXXnutffnllzZt2jQX6Onbt68L6MjAgQPtpJNOsnPOOcd27Nhh77zzjgv4KAhUo0bR/wedAnYtW7Z0QwhWrVrlbh4F3pR1pW0p60olkLEYOnSozZo1y2XWqfTy73//u51wwgkhwT0F6RSgi0av7969u1WpUiWwrHfv3vbTTz9FHZbwwQcfuGOyYsUK69ixo/tcZ555pi1fvrzQugqo6fMoKKkAYVF0HHJzc61+/foxff50QtkmAABIYAiAPyBW3BCAbu3q2atTPrYzT+phrRvWKnk5ZsSG/fcUBLniGQLg0Ws7nFz0cAEAAJAwNf8fMWKEy/ySzz77zAWcwrO0Tj/99JDHCmY1bNjQfvjhB+vUqZNb9tRTT7ksK2VnKSB266232kEHHVTsPigglJmZabVq1XIZWMEUMHr88cdt//33j/kzKTtNAUHdN2/e3C1TFpqy57R89OjRbtnee+9tderUibqd1atXW7t27UKWNWnSJPBcpIEJixYtcsEzvce//vUvt31loh1//PEuiKdAnDL0VNZ5xBFHuBLU119/3WXOvfnmmxEz1OTGG290n0UlpAhF8AwAAJRoCICmZEbLKGtWp5rtWcfn7ndJH7N4hwB46GUGAKio/vor/tdUrVrw5759/dsI7/EVoX9Woho1amQnn3yyy8Dy+XzuzwqKhfvxxx9dAEdN7deuXevWFQWovOCZgknPPvusy85Sr65kDBVQsEkBuXioN5n6o+21114hy1XKGdxXbMGCBZZsCpwp4Pfwww+7HmXyn//8xwUFP/74Y3dsdHyVxefp2rWrrVy50vVIixQ805AGL6Cp/mcIRfAMAACU7yEAxfYxy/D3MVP2WCJDAAAAqMhq1izZ6ytX9t+Svd0IpZsqc5THHnss4joK6hx22GE2Z84cV4qo0kyVY6onWLAZM2a4LDKVXqrUU9lkJaFBBl4PNI+ytbzgnUcBK89ff/3l9uGrr75y98GU9RUrBbx+/z00c957HJ4h52nWzN9uQj3aggOUCpgp0BiNerKp5DPc/fff74JnGi4QbxAxXdDzDAAAlO8hAPH0MWMIAAAA5ZJ6gSkIpgCUMqPCKdPs119/tUsvvdSVMarf2cyZO3uUBtEy9Sf773//64JUXkAu1gwzZYvFQsGo4L5oet38+fMDjzXsQMvWrFlje+yxR8gtWtArkm7durlgYHBgTgEulXtGKtkUlWKK+qJ51q9f745hmzZtor7X3LlzA4E3z7333mt33HGHKzc9+OCDY97vdEPwDAAAxDQIwBsCoICZ6D4pQwCKGwQQbx8zhgAAAFDuKDtLZZnqXxaeqeX1JFPm1KOPPuqCaMqCuuGGG0LW2bhxo5133nmu39mJJ57oBgVMmDDBJk6cGNM+tG3b1gWq1GhfgaaiHHvssW4ggW4qvbzssstsw4YNgedVrqnBBRpioN5rixcvts8//9zuvvtu9xqPpli+ETygIYymZSqoN3jwYDesQJ9HfcyCSy71em0n+L1PO+00u/rqq10wUUG9QYMGuXV69Ojh1nnhhRdcKaf2XTf1R9OghiuvvDKwHQUhb775Zrdcx0Y91nRTVh1CUbYJAABiHgSgZepxplJNZZwlJXBW3CCARPqYMQQAAIByp3bt2lGfU5nkq6++6jLJ1N9MmVfq6XXMMccE1lGwqGbNmoFm/J07d3Z/vuSSS1wGV4sWLYp8f03a1Lrt27d3vcnCyzLDy0y//fZbFxyrXLmyXXPNNYHAlEeDAe688077xz/+4QJyCv6p7PSUU04JrKPssOzs7Kjvo2b/77//vl1xxRVu8IG2ccstt9jFF18cWEevD84ykxdffNHtk/rH6dgdffTRLntMGXseZZRpSIP2X4E1BebOOOOMwPNPPPGEywYMXiajRo1ygxhQIMNX1LclheTk5Lgvpb50RV2wFYnSOqdMmeJG9QZfIAASx3WFdKRMsyPGTAvpZ6assk+H9yhxcKzYayraIACvxFKZYgqCje1UfB+zYfMIjiEt8HcVkH7X1NatW11mk8oZaeaOiiA/P9/FYRR/UXCvvF4/scaKKNsEACDNFTUIoFQVOwjA/IMAhD5mAAAAKCMJBc80GUP1sIrYaVqD6nqj0ShaTa0IvoVH+s4///xC66iZYDA1v1M9sSKBdevWdfXA1OECAJAmgwDoYwYAAIrwySefuAEC0W7ALu15phpZNa578sknXeBs7NixblKG6m8bN24c8TUKeAXX54aPgBUFy1Qv7KlatWrI8wqcadKFpk4orfaCCy5wNcAvv/xyvB8BAIC0KslUZpkCZNFKML1BACMnzXcZZ0kbBJCfZxlLP7UW62dZxtLaZrt3D80OS2QQAH3MAABABJoUqWmSQLkInj344IM2ZMgQF7wSBdE0SULTGYYP31laEUbBsuJGtSpYFm0dTeRQ47svvvgiMDr1kUcecTXp999/vzVv3jzejwEAQMqLdQhAqQwC2DkEoHLOSnN/cy99InQIgCQyCECBsnZHlWzfAABAyqlevbrtscceZb0bSFFxBc80heGrr76yESNGBJap8VvPnj1t1qxZUV+n8so2bdq4hnEHHnigm4ax7777hqwzffp0l7lWr149NxJWEysaNGjgntO2VarpBc5E76n3njNnjvXt27fQe2pyhm7BTeBEWWu6pQLvc6TK5wHKA64rpIpV2VsDgTPRvR53a1fPmtWJ3Gi4YY3K1rB17RJfAxkLJlvm6/o/2XwhHcp8avj/6kDLO328+TqcYta8q1Wu1dxs4yrLiND3zL26dnPb0byrdijh/QFSDX9XAel3TWnfNOtP/6bWDSjvfDtnU3rf27Kk99d+6DrKzAytWIj1uo8reLZ27VrLy8uzJk1C/59iPV6wYEHE12i8rLLS9ttvPze9QJlihx9+uH3//ffWsmXLQMlmv3793OSDhQsX2siRI+3EE090QTN9sNWrVxcqCdWo1fr167vnIrn77rvttttuK7RcI2Br1CjlHi67mEpZASQX1xUqul+yMyzfF/ofBwqgvTrlY9uzTikO2vblW6/vr7XMsMCZKECmd97+9rX2wUItqGTNGp5uXTc+4paHBNp2/u8XDfrZqqnvld7+AhUYf1cB6XNN6d+/qtRSYoqSWoCKYuPGjWW9C+6a2bJli82YMcN27NgR8tzmzZtLp2wzXt26dXM3jwJnHTt2tKeeesruuOMOt+yss84KPN+5c2cXaGvfvr3LRjvuuOMSel9lx6k3W3DmWatWraxXr15Fjh+tSBQh1Q/88ccfX25HKgMVDdcVUinz7PEfZ4RM0VTp5pkn9YiaeRZzH7PlswI9x3ytuoX0HFOPs8pz10d9uQJkNXLX28md6pqvzZFmdpLlLTjIMt8fabYxaHhA7RaWd/xddkCHU+yAxPcWSEn8XQWk3zW1detWW758uWt8Hz6ADyiPfD6fC5zVqlUrYt/7XX39qKy3e/fuha4fr0oxqcGzhg0bukyw338PbfCrx8X1NPPox+iAAw6wX3/9Neo6u+++u3svraPgmba9Zs2akHUULdQEzmjvqx5q4UMHvPcvrz+IiUrFzwSUNa4rVPQhAK0bZkUcAtC6Ya0S9zELmZAZ3sdsy7qYNlVZ63nXWOe+Zvv+LWQQQEabw60ygwCAIvF3FZA+15QqwBSAUOsi3YDyLn9nqab3vS1Len/tR6RrPNZrPq5PUKVKFTvooIPso48+CjkgehycXVbcRT9v3jxr1ixs1HyQ3377zdatWxdYR9vesGGD67fmmTZtmntvTfwEACCdhgAcMWaaDRg3x93rcTQaAvDp8B72nyGHuftowwJiDpy9OjA0cCY7+5i55xMdAhA8CKDzGf57AmcAAKQ1Jencfvvt9ueff5b1rgDxBc9EpZDjxo2zF154wU3BvOyyy2zTpk2B6ZsDBw4MGSigL7v6jC1atMi+/vprO/fcc23p0qV20UUXuedVs3399dfb7NmzbcmSJS4Qd9ppp7kpGb1793brqMxTfdE05fPzzz+3zz77zIYOHerKPZm0CQBIp4yz8CEAyizT8miUmdatfYOSTc/Mz/NnnEVo6h9YNnW4f702h/uz0Qp1PPNoCEAL/3oAAAARKFFGsQMl8GioYEWlbKc333yzrHcDZRE869+/v2v6f8stt1iXLl1s7ty5NnXq1MAQgWXLltmqVasC6ytKrKCXAmAnnXSSqyedOXOm7bPPPu55lYF+99139re//c322msvGzx4sMtu++STT0LKLl966SXr0KGDK+PUdo488kh7+umnk3EMAACoEFSqGdzDTFSSuWRtbI1OE6ZyyvCMsxA+s5wV/vWUMaYyTqfwyADnhDFklgEAkAbOP/98F0C69NJLCz13xRVXuOe0TrgxY8a4PujDhw+3dKP2VOecc47r1V63bl0XI1HSUXE0cPHYY4+1mjVruteqv5ea5Ifbtm2bi+Xo2CueE9wXTOdCfeg1oKJPnz5J/2wVWUIDA5T1pVskavIf7KGHHnK3aNS07b33ip+ipcmaL7/8cgJ7CwBAalCPMzX9Dw6gqZdZ24ZJmCKtrLGgnmMuM8wLcGlZLLz11P/szBej9EcbU9AfDQAApDwN7nvllVdcXED//vcCNfr3fevWkVtKjBw50srTQIld2QtPgTMlJGmIhd5bVX4XX3xxkfEQBc5UracqwEceecQFv7799tuIvcZuuOEGV8Gn58NbbOn8XHXVVfb666+XymeryOg0CABABaHSSw0BUMBMvCEAJSrJFPUrG9vJ7IVTzF4f7L/X45L0MVOAbNh823Hum/Zlm8vcvQ2bR+AMAIA0c+CBB7oA2qRJkwLL9GcFzjRMMJiq2lRlpoyrBg0a2CmnnGILFy4MPP/iiy+6iaO//PJLYNnll1/uqtQ2by4+E79t27Z2xx132Nlnn+0ytFq0aGGPPfZYyDrKyHriiSdcdZzWueuuu9zyt956y30WTWvUkMPbbrvNDTL0aJ+8aY6qtFPwK15qjaVj8Mwzz7j+7joWCoYp+LhyZfQqgGuuucYFvZSpt++++9ree+9tZ555ZqEhiu+++65rq6VqwnD6rPrcqhyMdSBkOiF4BgBAOaHeZTMXri2yh1lShwDEOggg0T5mlTLN1+ZIW1G/m7unVBMAgFKwaZP/5gtKTd++3b9s27bI6+6chOjk5vqXbd1a/LoJuvDCC238+PGBx88991ygb3roW25yfda//PJLNyRQGV99+/YNTG5Uj3W1cVJ2lgJX77zzjgs0qc1TjRqxZeLfd999tv/++9s333zjgk1XX311oUDXrbfe6t5Xww6172orpffWuj/88IM99dRT9vzzzwcCa9q/fv36uR5tc+bMsSeffNJuvFH9YkMdc8wxEctUgzPIFDg8+OCDA8t69uzpMsi03UjWrFnjnmvcuLEdfvjhrqXW0UcfbZ9++mmhAQwKjP3f//1fzMcKBQieAQBQwaZoJmUIQDyDAIQ+ZgAAlE+77ea/rV1bsOy++/zLwtstNW7sX74s6L8zlHmlZYMHh67btq1/+Y8/lngX1fxfwRwND9RNQwC1LNzpp5/uglAaIKgAlwJjCmApYOVR4Epljcq0Uj8wBbrUNz1WRxxxhAuaqef6lVdeaWeccUahVlMDBgxwwT1lmClDTllmes2gQYPcsuOPP95lsGlf5MMPP7QFCxa4zDjttzLQRo8eXei9ta1mzZpF3bfVq1e7IFgwlWCqjZWei0TDGUXHQcExZa4pQ0794r0MPZ/P54J26j0XHJhD7AieAQBQAado7vJBAF4fs9ph/8GnjDQtpxwTAABE0ahRIzv55JNdtpYy0PTnhg0bRixbVLmkAkjKtvLW0WBCj6ZvPvvss67EMJGhAt26dSv0WO8bLDzApP5gt99+uysZ9W4KVCmIp3JRvV6lqeolFu19RMG1u+++25LJy8q75JJLXMBPpbAKBqp0Uxl+otLPjRs3up5o2IUDAwAAwK6Zolmi7LKihgAkOgigw8lFbxMAAOxa3iTG4FK86683GzZMaUuh665Z47/f2bjfueIKsyFDzDLD/j5fsqTwuiWg8kdv8GB4nzGPAmeHHXaYK0Ns2bKlK81UieF2laEGmTFjhmVmZrrglUo9a9WqZcmk/l/BNO1S2WfKigunHmfJol5jKsMMpmOgCZzR+pB5mWzqsxasY8eOgaCjSmBVEhreA01BQpXAvvDCC0n7DKmK4BkAAKk4RVO9yiJOu7ynIEsskUEACpS1Oyrx/QIAAMkVFuhxqlTx32JZV5MkI02TjLRuCWgapIJgasjfu3fvQs+vXbvWfv31V5ed1q5du0CQLNzMmTPtnnvusf/+97+ur5gCcvEEf2bPnl3osQJNRVEZ5E8//eTKSSPR65cvX+6CeV4wK/x9YqFstQ0bNthXX30VKEVV4EvZZRogEG0IgjLetH/Bfv75ZzvxxBPdnx9++GG78847A89p+IDOwYQJE6JuF6EIngEAUIpUeqnMMgXIomWReVM0VaqpjLMST9H0hgCE9zLzhgB4ZZbeIAAtj9j3TIMAmhceBAAAABAnZYp55ZH6czj19VKZ5qOPPuqa3i9ZsqRQ032VHp533nmu35kCQ8pO69q1q5166qmud1ks1G/t3nvvtT59+rhBAa+99pobPFCUW265xU3+VM8yvY9KSlXKOX/+fBeUUlN/9VBTTzQNJMjJybF//vOfhbajoQOa8BmtdFNBOAUZVRKqoQO5ubkuOHjWWWcFSkJXrFjh+pmpBPSQQw5xwcjrr7/eRo0a5fqtdenSxQUT1YNt4sSJ7jXa72AqOxWVveoYetRbTgFOZbrpWM+dO9ct79Kli6U7gmcAAJQSNf33epkps0wBsmjTMbW8+16NXKmmMs4SDpwVOwQgwz8EQOWXyiJTJpoLtGWEvYZBAAAAILlq164d9TkFpF599VUXLOrUqZPr2aWMKU2o9GjapUoqvWb8nTt3dn9Wvy9lbSkwVZx//OMfbpqnyjC1Pw8++GDETLhgen7y5Mmu75my3jQFtEOHDnbRRRcF9v2NN95wAwwU0FI2mPZdgbBgKqPUukXR5FAdAwXItK6GKGhbHgXUlGWmXmueYcOG2datW+2aa65xgS8F0RQYVHAsHppkqoEOHvVP8wYOpLsMX5ocBUV+69SpY9nZ2UVesBWJLpopU6a4L7guXgAlx3WFZGacaWpmeCnmp8N7lHxKZlEWf2L2winFrzdockH5ZcQSzxb+wFkJBwFwTQHJx3UFpN81pcDI4sWLXTljMntspRsFtRRo0g2lKz8/38VhFH8pLmBYltdPrLEiMs8AAEjnIQDCIAAAAAAgKoJnAACk+xAAYRAAAACowD755JNAg/xINDETSBTBMwAA4sQQAAAAgPLl4IMPDjS4j0ZDCIBEEDwDACAODAEAAAAof6pXr2577LFHWe8GUlTZdm0DAKCCZZx5gTPRvTLLtDwaBcy6tW9QfOBMATI1+5830X+vxx71Igsu1SzEZ5azwr+eKANNmWi1m4WupowzL0MNAAAAQEzIPAMAoKyHABTXy4whAAAAAECZIXgGAEBZDwEorpcZQwAAAACAMkPZJgAAO6n8cubCtVHLML0hAAqYSYmHABTby8z8vcxaHerPRPN6lkUcAtCCIQAAAABAKSDzDACAOAYBJG0IQDy9zJbPYQgAAAAAUEbIPAMApL14BwEkZQiAxNPLjCEAAAAgDfz00092991327Zt28p6V4AAMs8AAGmvVAYBFDcEQOLtZcYQAAAAkMI2btxoffv2tVtuucWqVq1a1rsDBJB5BgBIe94ggGAlGgTgDQEIL8n0hgDoeVHgK95eZt4QgM5n+O8JnAEAgHLq/PPPt4yMDLv00ksLPXfFFVe457SOZ9CgQXbRRRfZWWedVeL3XrJkidv+3Llzrbx57bXXrEOHDlatWjXr3LmzTZkyJebXfvbZZ1a5cmXr0qVL1HXGjBnjPvuwYcNClq9evdrOO+88a9q0qdWsWdMOPPBAe/3110v0WdIFwTMAQNpL6iCAWIcAaD0FvpSJ5oQH0OhlBgAAKr5WrVrZK6+8Ylu2FLTD2Lp1q7388svWunVof9lJkybZtddeu0v3b/v27bv0/WbOnGlnn322DR482L755hvr06ePu82fP7/Y127YsMEGDhxoxx13XNR1vvjiC3vqqadsv/32K/ScXquy2LffftvmzZtn/fr1szPPPNPtB4pG8AwAkNYTNIMHAXw6vIf9Z8hh7j7SsICkDgHQekIvMwAAUAKbNsV/27Gj4PX6s5YFxbaibjcRym5SAE2BMY/+rMDZAQccELLuMcccE5It1bZtWxs9erRdeOGFVqtWLfeap59+Oqb3bdeunbvXeygLS9sWZbopWHXXXXdZ8+bNbe+993bLtc6bb74Zso26deva888/H3i8fPlyF2zS8vr169tpp53mMtzi8a9//ctOOOEEu/76661jx452xx13uGP06KOPFvtaZfANGDDAunXrFvH5v/76y8455xwbN26c1atXL2Lg7sorr7RDDjnEdt99d7vpppvcZ/nqq6/i+gzpiOAZACClJ2geMWaaDRg3x93rcVFiGgSQzCEAHgXIhs03GzTZ7PRn/ffD5hE4AwAAxdptt/hvb7xR8Hr9WctOPDF0u23bFn5dohT8Gj9+fODxc889ZxdccEFMr33ggQfs4IMPdtlRl19+uV122WUue6o4n3/+ubv/8MMPbdWqVSHBu48++sht44MPPrDJkyfHtB+5ubnWu3dvF8T75JNPXPnkbrvt5gJhXvba9OnTXRCuqIDarFmzrGfPniHLtF0tL4qO36JFi2zUqFFR11Ep7Mknn1xo+57DDz/cJkyYYOvXr7f8/HyXEagsQC+wiOgYGAAASKsJmt33alS+hgCE9zIDAABIMeeee66NGDHCli5d6h4r8KTAjYJNxTnppJNc0ExuvPFGe+ihh+zjjz8OZIxF06hRI3ffoEED1+MrmPp9PfPMM1alSpWYP4OCTgo46XUKkHkBLWVu6XP06tXLatSo4fYrKysr6nbUd6xJk9D/DtRjLY/ml19+seHDh7ugnfqdRaLj+fXXX7uyzWheffVV69+/vzsm2o7294033rA99tgjhiOQ3gieAQBSUtInaHpDAMJ7mXlDALwSS28IgJZH7HumIQDNQ4cAAAAAJOivv+J/TfAgy759/duoFFaXFmc1YrGBLGVEqQTS5/O5Pzds2DCm1wb37lLQSoGwNWvWlGh/1KQ/nsCZfPvtt/brr7+6zLNgytxauHCh+7PKIRcsWGDJlJeX50o1b7vtNttrr70irqNy0quvvtpl0mkIQTQ333yz65umbDwdf5WpqgxVQTkdE0RH8AwAkNITNIMDaAlP0Cx2CECGfwhAh5MLhgC4QFtG2GsYAgAAAJKrZs2SvV6JTJGSmUq63Uilm0OHDnV/fuyxx2J+XXgWlwJoygArCWWehdN2FdgLL9UM7id20EEH2UsvvRQ1yy0WCv79/ntomw89Ds+O82zcuNG+/PJLV7bqHT99fu2rssfef/99y8nJcQFF9U4LDrrNmDHD9VLbtm2bKyXVnzWYYN9993Xr7L///i5wpvPx5JNPxvwZ0hHBMwBAhSzJVGaZAmTRssi8CZoq1VTGWYkmaMYzBECll94QgIglnmPoZQYAANKO1xtMQSr1+CptXmaZgkixUABMvdGCSyU3b94ceKzAlEo3GzdubLVr1054v9TsXz3XggcjKGMs2hAAvZcmYwZ7/PHHbdq0aTZx4kQ3GEHBtPB11FOuQ4cOrtQ1MzMz8FkqhaUY6rmSBiPTAcEzAECFoqb/Xi8zZZYpQBZtMqaWq8eZSjWVcVbsIAAFv9TIX/3IVFbpZYclOgRAmWjRtgkAAJBGFKT58ccfA38ubQpyVa9e3aZOnWotW7Z05Yx16tSJuv6xxx7rMrMUxFLATUGn4Kw3TbG877773ITN22+/3W1TPdw0iOCGG25wjzWkYODAgS441qJFi4jvo/LKo48+2g1CUPmqepUpsyx4iqj6w61YscJefPFFF+zq1KlToc+mzxO8PHwdZdept5m3XIE09Ta75JJL7P7773fPqWwznqEJ6YxpmwCACj8EQMtLNEFT/czGdjJ74RSz1wf77/VYy5MxBKDzGf57AmcAACCNKYuqJFlb8VBJ48MPP2xPPfWUNW/e3AW9iqJgVqtWreyoo45yPcauu+4611Dfoz+rDLJ169bWr18/69ixow0ePNj1PPM+k7K7NMUzuNwz0sTLl19+2QXLVDap7DEFsYKDX8qAW7as6Cnx8VIgcMqUKS7D7tRTT3W95BSce+GFF9xQBhQtwxde1JuiVAOsKHN2dvYuu1hLmy5Iffn1RS9qmgeA2HFdlW8zF661AePmFFr+nyGHuQBZQqINAvD6k6n8UhlkCqYVNwRg2DwCZGG4poDk47oC0u+aUoBm8eLFrkSvqIbwQHmRn5/v4jCKv4SXipan6yfWWBGZZwCACjcEIFjCQwBiGgRg/kEAoiEATtgOMAQAAAAASGkEzwAA5YbKL5VdFq0M0xsCoICZlGgIQLyDALwhALWbha6ijDMtZwgAAADALjN69GjbbbfdIt5OPPHEst49pBgGBgAAKtQggKQNAUhkEABDAAAAAMqFSy+91M4888yIz2lQAJBMBM8AAOV2EICCZJGCY1pWbLaZepmpJDM4s0xZYiq/9LLEEhkE4A0BAAAAQJmpX7++uwG7AmWbAIAyt3jtpkDgzJPn87nsshINAQgvyVTDfy33pmgqa0wBtUJ9zIIHAbTwrwcAAAAgLRE8AwCk1iCAWIcAaD1lkTEIAAAAAEARCJ4BAMpcUgcBxDMEQBgEAAAAAKAI9DwDAJR6PzOVZSq7rKhgWMyDAJI9BEAYBAAAAAAgCoJnAIAyn6AZ8yCA0hoCIAwCAAAAKHM//fSTTZo0ya699lqrWrVqWe8O4FC2CQDYpRM0tTwhDAEAAABIaRs3brS+fftau3btKlzgbPr06ZaRkWEbNmwo611BeQmePfbYY9a2bVurVq2aHXroofb5559HXff55593X6Dgm17nyc3NtRtvvNE6d+5sNWvWtObNm9vAgQNt5crQfxzp/cK3M2bMmER2HwBQ0SZoMgQAAACgwjn//PPdv90vvfTSQs9dccUV7jmt4xk0aJBddNFFdtZZZ1m6+O677+yoo45ycZJWrVrZvffeG/Nr161bZy1btiwyaPfZZ59Z5cqVrUuXLiHL8/Ly7Oabb3aByurVq1v79u3tjjvuMJ8v0n9vI+7g2YQJE1z65KhRo+zrr7+2/fff33r37m1r1qyJ+pratWvbqlWrArelS5cGntu8ebPbjk6a7pWeqTTNv/2tcIPm22+/PWQ7V155Zby7DwCoiBM0GQIAAABQISkg9Morr9iWLQXVB1u3brWXX37ZWrcObefhlWuWFQWOduzYscveLycnx3r16mVt2rSxr776yu677z679dZb7emnn47p9YMHD7b99tsv6vMKqCk56bjjjiv03D333GNPPPGEPfroo/bjjz+6xwrcPfLIIyX6TKkq7uDZgw8+aEOGDLELLrjA9tlnH3vyySetRo0a9txzz0V9jaKgTZs2DdyaNCnoM1OnTh374IMP7Mwzz7S9997bDjvsMHfy9MVZtmxZyHZq1aoVsh1lqgEAUmSCprLGFn9iNm+i/16PSzoEYNh8s0GTzU5/1n8/bB6BMwAAgF3owAMPdAE0BcY8+rMCZwcccEDIusccc4wNGzYspAJt9OjRduGFF7p4gF4Ta2BpyZIlLhahwN3hhx/uMrs6depk//vf/wqVWr777rt20EEHuVLRTz/91PLz8+3uu+8OZGUpaWjixIkh258yZYrttdde7vkePXq494vXSy+9ZNu3b3fxlH333ddl3F111VUu7lIcBb4UHLvuuuuirqOMvwEDBli3bt0KPTdz5kw77bTT7OSTT3bH+YwzznCBvKIqC9NZXAMDdFIV1BoxYkRgWaVKlaxnz542a9asqK/766+/XCRVX0BdOPry64sRTXZ2tvsC161bN2S5yjSVRqgLRl+Aa665xqUfRrJt2zZ3C47oemWiuqUC73OkyucBygOuq9isyt5qS9dttjYNNBWzoBQ/XL8uzaxbu3q2bP1ma13fv26kY5uxYLJlvj/SMjYWZJf5ajW3vF6jzdfhFMuo3iCmv7B2VG9gvvDttzys4M95+f4bdhmuKSD5uK6A9LumtG/KitK/qXULtmmT/75GDSWu+P+8fbteY6Z/Lge3DvPWrV5d/5b3tu1fPzPTLKjDUsR146V91k3JN+PHj7ezzz7bLVewSOWaCl55nyv4NcGPH3jgAVeFNnz4cHv99dftsssuc2WOSr4pireN66+/3gWjlPzz0EMP2amnnmoLFy60Bg0aBNbRtpV1tfvuu1u9evVczEKBrccff9z23HNPmzFjhp177rnuNUcffbQtX77c+vXrZ5dffrlLLvryyy/d+3jv6203MzPTnn322ZDS1PAAlj6L4hrea44//niXBaaSTO1LJD/88IM7JorDLFq0qND7io63nnvxxRftrrvuCjkmooDauHHjbMGCBS4I+O2337rA4f3331/oO5YIr/wz/HyWBb2/9kPXkc5JsFiv+7iCZ2vXrnV1scGZY6LHOuCR6AutC0OphAqK6UQo6vv999+72txwSt9UDzRdVCr39Cj6qsBb/fr13RdMATyVbkaLyCpKfNtttxVa/v7777tMuVSizD0AycV1Fd2s3zNswqJK5rMMyzCf9d8937o1Kb43wjoz+ybC8mYbvrCuiyOkh29caZmvn29ftLvSVtU5yHpl1bdquesjjgHQu2/Jqm8fzN9g9v2UxD4YShXXFJB8XFdA+lxTCq6o+kqJKUpqCVavnj/p5Jdfsq1hQ/9/k91/f1W7667qNnDgNvvXvwrKJVu0qGObN2fYt9/mWOvW/oDGE09UtZEjq9sZZ2y3ceMKetPusUdtW7euks2cmWMdOyYW/FBgQmWQass0cuRImz9/fqAP11NPPWUffvihW8dLdtG6+nzeYwU9lKxzzjnnBDKpFABTplizZmHtOcLoWHmljQpIeQk5eq2CYldffbVrIyWKQaifuygJR/GEN954ww455BC3TIEyBfrU/13Zcv/6179cVtott9zinldATolGWq6hB0oyEgXeqlSpEvg84VasWOGSg4Kf9yrsfv3114gBQu2fMtRU3qmEI+8zBL+vgoOKmSg7Ts/rNYrlBL+PgpB//PGHCyoqoKTnb7rpJvdZou1vIrRfZU3fKZUNKwgaXpbrHb+kBs8SoWhmcIqgAmcdO3Z0F4qyyILpolH5piKCSkEMFlz3rECcvoCXXHKJ+1JHmsKhL0rwa3TylSqqNMTgoFxFpuOlH3j9EGRlZZX17gApgeuq+Iyzax6YEWjbrwDaq4sz7fJ+3YvMQIsqP88qPzo8amt/bb/rukm246ybLKO9mb1+gXtvBe08Wkeq/O1BO6nDKYl/OJQKrikg+biugPS7ppRkomyn3XbbLWQAXzCVNXr/1PVWycqqYrVrF/5M2k7hdbNC/q2sarDwdeOlbSrwp4yuk046yZVr6t/7+rOCT3ou+H31WP/W9x4rGKRyyuD9UtBMAZni/l2v/fZKQYPX7dq1qy1evNgt8xJrlP3lraNEHwVUFDALD8AocKb1lNGlllPB21VGmoJn/vPgXx4tycijoFXw5w3eb/9xL/wZ//GPf7hKPmW8ifcZvPdVEExBRgXXlIAkipnovYK3p3JWZfL9+9//dtubO3eui6HovGhwQ0n5fD53nrRf3nepLK8fldd279690PUTa6AwruBZw4YN3QH//ffQ3jN6rCh4LHRh6AunKGqkwJmGCUybNq3YC0FRYUUMVVccKRqrL0ekoJrev7z+ICYqFT8TUNa4riL7LTu70ARNPV6Rvd1aN6wV/wYXz3YZZtG4IFnOCsta+YVZ577+egJN3QwaHpChIQAnjLHK9DIr17imgOTjugLS55pSQEQBCAWTvOwiz84EK6tRo1KgbPOGG8yuuUbBKL2mIHDhzfmrXl3b8f956FCziy/Wf2aFruu18ApeN17aZ2+/lQE2VG9m5jK4tCz4+eDXBD9WcCn8eQVmwo9DOO/58GMW/J7ecgV4vD97mUjvvPOOtWjRImSbijFE2+9o71cUBQI1fDF4fWWDSfPmzSNu5+OPP7Z58+a5wFdweWTjxo3tn//8p2tvpTLSb775xlXwBZct6liqGu/YY4912XYqV1VLLFFfNwVoVTKqMtuSyt9Zqhl+nMqCd84iXeOxXvNxBc90oBX1/eijj6xPnz6BA6LH3kUQy0WvE61Ic3jg7JdffnFfBNURF0dRUR0AfUEAALt2gmZwAK3ICZpq+q8JmGrkv1sTszaHm1XKTHwQgAJkHU4uepsAAABpJNIcvSpV/LdY1lXsIFL8INnz+U444QSXvaUgRu/evW1XmT17tss4EiXgqLyyqPiFyhgVJNMAQ2WTRaJqurfffrvQ+8RLVXoKeCkm4gVxlAWpBKFo/c4UNAueXPrFF1+4gQqffPKJtW/f3iUiKeYSTGWqSlLS0ANllnlBwvCglpKlyro/WXkVd9mm0viUwnfwwQe7+t+xY8fapk2bApFJjUFVdFbllKImdkpn3GOPPdwkCI1eVXbZRRdd5J7Xl0RTHb7++mubPHmyC66tXr3aPaf+ZgrYqQnenDlz3AQLRYT1WNFUNeyL9oUCAMRvVfYWW7x2kwuSRZqK6U3QHDlpvuX5fEVP0Pzh7UJZYuayxO4pmHip4FcsgtdToKzdUfF/OAAAAJQZBWZ+/PHHwJ93FWW5qfeYAl7ql/bnn3+6YFM0ijlogqViDgokHXnkka5/u/q0KTCleIjKIjXIQEMCFNtQQO75558vtK0OHTq42Ejfvn0jvpeyvtSrXVl5ygRTTziVfmo/Peq9prZUXgmoAmThvelFn88buqiposGUdORNG/Wot5kGCajnmso2lammnvJFHZt0FnfwrH///i6NUI3xFOTq0qWLTZ06NTBEQNHZ4OilvpiqxdW6CnQpc00N/xXN9RrkeRFbbSuYstBUn6yor+pxVbOrRneKlOqLHNzTDABQMhO+WGYjJs1zWWXKLlOQrH/X1oXW07LuezWyJWs3u4yzqIGzVwfubOUfJGeVf/mZL/oDaMoaU0BNy8PXdTL8z2s9AAAAVGhl0X9cQwJ0U/WaknoUf1BLqqKoP3ujRo1c4Ev9zRSUUv8wDT0QBZyUAaa4xCOPPOISizShMzzw9NNPP7nAWzR16tRxZZRXXHGFi5VovxRruVh1tDvp9dpOsmm/b775ZjcxVKWjKhNVX3lvCAJCZfi8AtkUpyZw+mLqi5dKAwM0PUMlsOW1Nh+oaNL1ulLG2RFjphUqx/x0eI/IwbGiqFRzbKfQjLNIAbFh8/xZZIFAmwT/lbSz54YXaEOFlK7XFFCauK6A9Lum1PBcTe6VSBJtYABCqT+6jpcyqsITdVD68vPzXRxG8Zey7nlW1PUTa6yobD8BAKBcUKlm+CAAlWUquyxu6kcWNXAm/iEAbj1RYEwBstph48YVYCNwBgAAAKCilW0CANJ8EECyhwAIgwAAAAAQB5VJ6hbJUUcdZU888cQu3yekLoJnAIDYBwGU1hAAYRAAAAAAYqSm/WeeeWbE56pXr+4GGaZJlyrsAgTPACDNJ2jGPAiAIQAAAAAoJ+rXr+9uwK5A8AwAUlisEzQ9CphFDLCpVFMZZxGDYVqWYTZ1uL/0UhlkykRzgbaMyEMAThhDSSYAAACACoGBAQCQwhlnXuBMdK+yTC2PG0MAAAAAysUEQwC7/roh8wwA0nCCZlHlmxExBAAAAKDMVKlSxSpVqmQrV660Ro0auccZGTsz+oFyGrDavn27bd261X13y4J63mkf/vjjD7cPum4SRfAMAFJUXBM0i5uiyRAAAACAMqN/+Ldr185WrVrlAmhAeefz+WzLli1ueENZB3pr1KhhrVu3LlEQj+AZAKToEICYJ2jGMkWTIQAAAABlSlkzCgDs2LHD8vLyynp3gCLl5ubajBkzrHv37paVlWVlJTMz0ypXrlziAB7BMwBI4SEAxU7QjGeKJkMAAAAAypQCAApElGUwAog1aKVAb7Vq1VLi+8rAAABI8SEACph1a98gwSma5p+iqfUYAgAAAAAgDZF5BgDpOgQg3ima6l3GEAAAAAAAaYbgGQCk6xCARKdoMgQAAAAAQBoheAYAFUhShwCUZIomAAAAAKQJgmcAUMGmaCZ1CABTNAEAAACgSATPAKACTtFUwCxqj7NihwBk+IcAqHeZSjCZogkAAAAAUTFtEwAq6BTNpAwBEKZoAgAAAEBUZJ4BQDkQ1xTN0hgCwBRNAAAAAIiI4BkAVKQpmqU5BIApmgAAAABQCGWbAFCOpmgqYCYRp2h6QwDCSzK9IQB6XrwhAF7PsohDAFowBAAAAAAAYkDmGQCUgwmaxU7RZAgAAAAAAJQJgmcAUE4maBY5RTOeIQAqvfSGAEQs8RzDEAAAAAAAiBHBMwDYxRM0lV0WMUBW1CAAhgAAAAAAQJkgeAYA5WGCZnGDABgCAAAAAABlgoEBAFDKEzSDRZ2gWdwgAIYAAAAAAECZIHgGAAmWZM5cuNbdl2iCZrGDAMw/CECUheaEB9AYAgAAAAAApYWyTQAoxSEARU7QjHcQAEMAAAAAAGCXI3gGAKU5BKCoCZqJDAJgCAAAAAAA7FIEzwCgtIYAFDdBUxIZBMAQAAAAAADYZQieAUACQwCCA2gRhwDEMkFTvEEAGg4Qse+ZBgE0ZxAAAAAAAJQRBgYAQBxiGgIQ6wRNL4uMQQAAAAAAUG6ReQYAQVZlb7VfsjPcfeuGWYkNASh2gmaGf4KmepcpKMYgAAAAAAAotwieAUChKZqZ9viPM4qcolnkEIB4Jmh6vcsYBAAAAAAA5RLBMwCId4pmcUMA4p2g6WEQAAAAAACUOwTPACCeKZqxDAFIZIImAAAAAKBcYmAAAARN0QxWaIpmrEMAvAmahQYABE/QbMEETQAAAACoAAieAUDQFE0vgKb7kCmaxQ4BMP8QAK3HBE0AAAAASBkEzwCkPPUzm7lwrbsvioYDTP9Hdxu6T567DxkWEM8QAPEmaNZuFrqaMtK0nAmaAAAAAFAh0PMMQJpM0PRnkxU1QVNZY803fGnH5M205htqmdXvXpAdlsgQACZoAgAAAECFR/AMQMqKa4LmzkEAlXNW2sF6vPSJ0EEAiQ4BYIImAAAAAKRf2eZjjz1mbdu2tWrVqtmhhx5qn3/+edR1n3/+ecvIyAi56XXBfD6f3XLLLdasWTOrXr269ezZ03755ZeQddavX2/nnHOO1a5d2+rWrWuDBw+2v/76K5HdB5AmipqgGSKWQQAMAQAAAACAtBR38GzChAl27bXX2qhRo+zrr7+2/fff33r37m1r1qyJ+hoFvFatWhW4LV26NOT5e++91x5++GF78sknbc6cOVazZk23za1btwbWUeDs+++/tw8++MAmT55sM2bMsIsvvjje3QeQRmKaoBnrIABhCAAAAAAApJ24g2cPPvigDRkyxC644ALbZ599XMCrRo0a9txzz0V9jbLNmjZtGrg1adIkJOts7NixdtNNN9lpp51m++23n7344ou2cuVKe/PNN906P/74o02dOtWeeeYZl+l25JFH2iOPPGKvvPKKWw8AipqgqYCZ6D5kgma8gwAYAgAAAAAAaSeunmfbt2+3r776ykaMGBFYVqlSJVdmOWvWrKivU3llmzZtLD8/3w488EAbPXq07bvvvu65xYsX2+rVq902PHXq1HFBMm3zrLPOcvcq1Tz4YNeJyNH6em9lqvXt27fQe27bts3dPDk5Oe4+NzfX3VKB9zlS5fMA8ViVvdWWrttsbRrUsGZ1QkvBg/Xr0sy6tatny9Zvttb1/esGXzMZ2Sti+iHckb3CfHrdnieate9lGctnBYYA+Fp182eccS0ChfB3FZB8XFdAcnFNAel7XeXGuH9xBc/Wrl1reXl5IZljoscLFiyI+Jq9997bZaUpoyw7O9vuv/9+O/zww10JZsuWLV3gzNtG+Da953TfuHHj0B2vXNnq168fWCfc3Xffbbfddluh5e+//77LlEslKmUF0sms3zNswqJK5rMMyzCf9d8937o18UVJHMu3Bn/9ZNVyN9iyrLr2zW57m2UUJN022LjEjozhPWfPX2Lrlk4JW6oMthyz798r2QcC0gB/VwHJx3UFJBfXFJB+19XmzWH9sMtq2ma3bt3czaPAWceOHe2pp56yO+64o9TeV9lx6s0WnHnWqlUr69Wrl+vBlgoUIdUX8fjjj7esrKyy3h1gl2WcXfPAjECHMgXQXl2caZf3614oAy1jwWTLfH+kZWwsKMv01Wpueb1Gm6/DKf4F+b3N9+gLZhtXuUBcOG1fZZmH/n0Y/cyABPB3FZB8XFdAcnFNAel7XeXsrFJMavCsYcOGlpmZab///nvIcj1WL7NY6KAdcMAB9uuvv7rH3uu0DU3bDN5mly5dAuuEDyTYsWOHm8AZ7X2rVq3qbpHevzyfuESk4mcCovktO7vQBE09XpG93Vo3rFWwUBMyX7+g0CCAjI2rrLKWB3qUZZmdeI9/qqZr/B+8vjLb/IMAsqpGLw0FUDz+rgKSj+sKSC6uKSD9rqusGPctroEBVapUsYMOOsg++uijwDL1MdPj4Oyyoqjsc968eYFAWbt27VwALHibivypl5m3Td1v2LDB9VvzTJs2zb23eqMBSB9JnaCp9YRBAAAAAACAZJVtqhRy0KBBrnn/IYcc4iZlbtq0yU3flIEDB1qLFi1czzG5/fbb7bDDDrM99tjDBcDuu+8+W7p0qV100UWBSZzDhg2zO++80/bcc08XTLv55putefPm1qdPH7eOyjxPOOEEN+VT0z2V/jd06FA3TEDrAUgdq7K32OK1m1yQLGQqZtgEzZGT5luez1fyCZrtjvIvUoCsw8m2Y9EMm/vJe9blqN5WeffulGoCAAAAQJqLO3jWv39/++OPP+yWW25xzfpVWjl16tRAw/9ly5a5KZieP//80wW9tG69evVc5trMmTNtn332Caxzww03uADcxRdf7AJsRx55pNtmtWoFZVIvvfSSC5gdd9xxbvunn366PfzwwyU/AgDKjQlfLLMRk+a5MkxllylI1r9r60Lr9T+ohfWs/rOtW73cGjRtZQ32aRG6gqZgxiJ8vUqZ5mtzpK34Psf2b3MkgTMAAAAAQGIDAxTE0i2S6dOnhzx+6KGH3K0oyj5Thppu0Wiy5ssvv5zI7gKoIBlnXuBMdK/ssu57NQrNKlMvs6k3WoOcldYguLzyhHsKyit3C53eG1Ws6wEAAAAA0lZcPc8AoLSoVDN8EIDKMpes3RwaOFNj//CSzJxV/uV6Xtoc7g+o+dv9R6AJmi386wEAAAAAUASCZwAqxiCAeIYAqNxSmWhOeABt5+MTxlCWCQAAAAAoFsEzAOWCNwhAATMpNAggniEAwgRNAAAAAEBZ9TwDgGRO0IxpEEAiQwB2TtB0ATUtV48zlWqScQYAAAAAiBHBMwDlYoJmsYMAEh0CoEBZu6NK/DkAAAAAAOmJsk0Au3yCppaHiGUQAEMAAAAAAABlgOAZgLKdoBnrIABhCAAAAAAAYBcjeAag7CZoxjsIgCEAAAAAAIBdjJ5nAEqNhgOM6buPvfnm69bQ/rS1Vs/69Dk9dGhAvIMAGAIAAAAAANiFCJ4BKL0Jmj+8bWd+eqOdWSUos+zTZ8122zkEQBIZBMAQAAAAAADALkLwDEDpTND0hgCE9zLzhgB4ZZbeIAAtj9j3TIMAmjMIAAAAAABQJuh5BiD5EzRjHQKg9ZRFxiAAAAAAAEA5RfAMQPInaMYzBEAYBAAAAAAAKKco2wSQ0ATN4ABaoQma8Q4BEAYBAAAAAADKIYJnAJI/QTORIQDCIAAAAAAAQDlD8AxAfFM0Y5mgyRAAAAAAAECKoOcZgJApmkeMmWYDxs1x93occYJmeD8zb4KmnheGAAAAAAAAUgTBMwCxTdGMZ4KmMAQAAAAAAJACKNsEUOwUTVe+Gc8ETa9vGUMAAAAAAAAVHMEzAI56nFXOyLeDMxZYY9tga6yufeXrWDBFM5EJmsIQAAAAAABABUbwDIDTbMUH9l2d66zG1oLg1+ZqTazGivvN6vwt8QmaAAAAAABUYPQ8A9KA+pbNXLi2oH9ZuJ2DAIIDZ1Jj65qCQQDeBM1CAwCCJ2i2YIImAAAAACClEDwD0n2CZqyDAIQJmgAAAACANEPwDEjnCZoSzyAAJmgCAAAAANIMPc+AdJ6gmcggACZoAgAAAADSCMEzIJ0naEoigwCYoAkAAAAASBMEz4B0nqAp3iCAnFVR+p5pEEBzBgEAAAAAANISPc+AdJ6g6WWRMQgAAAAAAICICJ4B6TxBU+sJgwAAAAAAAIiIsk0gRSZodt+rUcEQgHgmaHq9yxgEAAAAAABAIQTPgAo4QdN8+XZYpYIhAJ/ndyjZBE0PgwAAAAAAAAhB8AyoYDr+Od0+q3q9NctYH1i2ylffqv15n5mdkfgETQAAAAAAUAjBM6Ai+eFtqzf5IvNlhPYya5rxp2VMvsisRhV/+SUTNAEAAAAASAoGBgAVZYJm0BCAwjMxw4YAMEETAAAAAICkIHgGVJQJmvEMARAmaAIAAAAAUGKUbQLlgDLN/jnpWzskY4E1zvAPAbhpki90gmYiQwCYoAkAAAAAQIkQPAPKgeyvJ9mMKjdZ86AhACt99S3n6zutWY9zSjYEgAmaAAAAAAAkjLJNoKz98Lbt/b8rrKkVBM5Ej/f63xXueccbAlCoh1nwEIAWDAEAAAAAACCJCJ4BZTkIYOcQADX8rxQWE9Njt4ghAAAAAAAAlBmCZ0BZDgJgCAAAAAAAAKkXPHvsscesbdu2Vq1aNTv00EPt888/j+l1r7zyimVkZFifPn1ClmtZpNt9990XWEfvF/78mDFjEtl9YJdRptmISfMs3+d/rPuRk+YXZKAlOgRg2HyzQZPNTn/Wfz9sHoEzAAAAAADKw8CACRMm2LXXXmtPPvmkC5yNHTvWevfubT/99JM1btw46uuWLFli1113nR11VOHG5atWrQp5/O6779rgwYPt9NNPD1l+++2325AhQwKPa9WqFe/uA7vU4rWbzHz5dlilBdbY/FM0P8/vYEvWbvZP0WQIAAAAAAAAqRU8e/DBB10A64ILLnCPFUR755137LnnnrPhw4dHfE1eXp6dc845dtttt9knn3xiGzZsCHm+adOmIY/feust69Gjh+2+++4hyxUsC18XKM86/jndPqt6vTULmqK5ylffqv2prMozCoYA5CiAvDM9rdAQgOYMAQAAAAAAoCIEz7Zv325fffWVjRgxIrCsUqVK1rNnT5s1a1bU1yljTFlpyiZT8Kwov//+uwvGvfDCC4WeU5nmHXfcYa1bt7YBAwbYNddcY5UrR/4I27ZtczdPTk6Ou8/NzXW3VOB9jlT5PKkmY8Fkqzv5IrOM0KBY04w/zSZfZDuqZpqvwymWcfxoy3xdwegMNzjA49s5BCDv+LvMl5dvphtKHdcVkFxcU0DycV0BycU1BaTvdZUb4/7FFTxbu3atyyJr0iS0hEyPFyxYEPE1n376qT377LM2d+7cmN5DQTNlmPXr1y9k+VVXXWUHHnig1a9f32bOnOkCeCr3VCZcJHfffbfLdAv3/vvvW40aNSyVfPDBB2W9C2lpwzazP7ZmWKNqPqtbNexJX771+v5aywyEwAooQKYQ2fa3r7UPFmpBJWvWbqh1/u0lq55bkKG2JauezW95jq1aVMls0ZRd8plQgOsKSC6uKSD5uK6A5OKaAtLvutq8eXPplG3GY+PGjXbeeefZuHHjrGHDhjG9RuWfKvHUMIJg6rPm2W+//axKlSp2ySWXuCBZ1arhkQtzwbXg1yjzrFWrVtarVy+rXbu2pQJFSPVFPP744y0rK6usdyetvPbVb3bbWz+4AQCVMszuPG0f+/tBLQPPZyz91CrPLQiEhVNArUbueju5U13ztTnSzE4yy7/Jdiyf5R8OsFsTy2rVzQ6olGkH7KLPBD+uKyC5uKaA5OO6ApKLawpI3+sqZ2eVYlKDZwqAZWZmutLKYHocqRfZwoUL3aCAU089NbAsP99feqZySw0ZaN++feA5lXRqmYYSFEfDCnbs2OG2v/feexd6XgG1SEE1nbTyfOISkYqfqTzTpMxb3ppvh2QssMYZ/iEAo97yWY+OTf1DAGTLupi2VVnrBc5dltkePUpvxxEXrisgubimgOTjugKSi2sKSL/rKivGfYsreKZsr4MOOsg++ugj69OnTyAYpsdDhw4ttH6HDh1s3rx5Ictuuukml5H2r3/9y2WCBVN5p7a///77F7svKgNVv7WiJnwCpSH760k2o8pN1jxoCMBKX33L+fpOa9bjHP+CRKdoAgAAAACAciXusk2VQg4aNMgOPvhgO+SQQ2zs2LG2adOmwPTNgQMHWosWLVw5pUovO3XqFPL6unXruvvw5UqVe+211+yBBx4o9J4aRjBnzhw3gVP90PRYwwLOPfdcq1evXrwfAUjcD2/b3v+7YmfXsgJNbb01+98VZk1qme3zN6ZoAgAAAACQrsGz/v372x9//GG33HKLrV692rp06WJTp04NDBFYtmyZywiL1yuvvGI+n8/OPvvsQs+p/FLP33rrrW6CZrt27VzwLLinGVDq8vPMpt7oGv5nhE0BUN8zZ+pwsw4nm1XKNDvhHrNXB+7scBYcQNu58glj/OsBAAAAAIByK6GBASrRjFSmKdOnTy/ytc8//3zE5RdffLG7RaIpm7Nnz05gT4H4+5ktXrvJ2jWsWdC/zLN0plnOyiJe7TPLWeFfr91R/gy0M190AbeQ1ynjTIEzPQ8AAAAAAMq1Up22CVQkr36+2N54c6I1sg32h9W1vn3OsDMPaVewgqZgxiJ4PQXIlImmgNrOKZquVJOMMwAAAAAAKgSCZ4CZ/fnlRDvqnevtzCoFQwBWvfO4/VnpPqt38BklGwKgQJky0QAAAAAAQIUTf3MyINX88LbVnXyRNbGCwJnosZbreccbAuD1LIs4BKAFQwAAAAAAAEghBM+Q3nYOAVC/skDT/0hDALSeNwTACQ+gMQQAAAAAAIBURPAM6W3nEIDouWRBQwDEGwJQu1noispI03KGAAAAAAAAkFLoeYb0nqLJEAAAAAAAAFAEgmdI7ymaDAEAAAAAAABFIHiG9J6i6Q0ByFnl+p5FHgLQnCEAAAAAAACkKXqeIb2naDIEAAAAAAAAFIHgGVJTPFM0GQIAAAAAAACioGwTqSmeKZrqXcYQAAAAAAAAEAHBM1RM+Xm27oePbd3qZdagaWtrsE+P0EBXIlM0GQIAAAAAAADCEDxDxfPD27b57euswdbfrcHORZurNbEaf7u/oMQy0SmaAAAAAAAAQeh5horlh7fN9+pAq7YlNLNMj7XcDQEQb4pmEYWbVrsFUzQBAAAAAECRCJ4hNYcAMEUTAAAAAAAkAcEzpOYQAGGKJgAAAAAAKCF6nqHiSGQIAFM0AQAAAABACRA8Q8WZoJnoEACmaAIAAAAAgAQRPEPFmaDpDQHIWeX6nkUeAtCcIQAAAAAAACBp6HmGijNBkyEAAAAAAABgFyN4hoozQVMYAgAAAAAAAHYhyjZRcSZoen3LGAIAAAAAAAB2EYJnKH3KGosW6EpkgqYwBAAAAAAAAOwCBM9QutSvTGWZOStDSyzVu0wZZIlO0AQAAAAAANgF6HmG0g2cvTrQfMGBM3U307RMbxCAN0GziMJNq92CCZoAAAAAAKBMEDxDqQ4C8JkvwlxMLd05CECYoAkAAAAAAMopgmco+0EATNAEAAAAAADlFD3PUDriHQTABE0AAAAAAFAOETxD8idoSiKDAJigCQAAAAAAyhmCZ0j+BE3xBgFoOIC/w1mEQQDNGQQAAAAAAADKNXqeIfkTNL0sMgYBAAAAAACACo7gGZI/QVPrCYMAAAAAAABABUfZJkpngqbXu4xBAAAAAAAAoAIjeIbYhwDEO0HTwyAAAAAAAABQQRE8Q+xDABKZoAkAAAAAAFCB0fMMsQ8B8CZoFlG4abVbMEETAAAAAACkDIJn6S6eIQBM0AQAAAAAAGmG4Fm6i2cIgDBBEwAAAAAApBF6nqW7RIYAMEETAAAAAACkCYJn6T5FM9EhAEzQBAAAAAAAaYDgWbpP0fSGAGg4gL/DWYQhAM0ZAgAAAAAAANJSQj3PHnvsMWvbtq1Vq1bNDj30UPv8889jet0rr7xiGRkZ1qdPn5Dl559/vlsefDvhhBNC1lm/fr2dc845Vrt2batbt64NHjzY/vrrr0R2P33EMkWTIQAAAAAAAADJC55NmDDBrr32Whs1apR9/fXXtv/++1vv3r1tzZo1Rb5uyZIldt1119lRR0Uu9VOwbNWqVYHbf/7zn5DnFTj7/vvv7YMPPrDJkyfbjBkz7OKLL45399NHPFM0GQIAAAAAAACQnLLNBx980IYMGWIXXHCBe/zkk0/aO++8Y88995wNHz484mvy8vJc8Ou2226zTz75xDZs2FBonapVq1rTpk0jvv7HH3+0qVOn2hdffGEHH3ywW/bII4/YSSedZPfff781b9483o+R+uKZoqneZQwBAAAAAAAAKFnwbPv27fbVV1/ZiBEjAssqVapkPXv2tFmzZkV93e23326NGzd2pZYKnkUyffp0t069evXs2GOPtTvvvNMaNGjgntO2VarpBc5E76n3njNnjvXt27fQ9rZt2+ZunpycHHefm5vrbhVefp7lLf7UWqyfZXkLa5q1OzIk0JWRvSKmk7sje4X5go9Hy8MK/pyX778BacT7fUiJ3wmgHOCaApKP6wpILq4pIH2vq9wY9y+u4NnatWtdFlmTJqGTF/V4wYIFEV/z6aef2rPPPmtz586Nul2VbPbr18/atWtnCxcutJEjR9qJJ57ogmaZmZm2evVqF1gL2fHKla1+/fruuUjuvvtul+kW7v3337caNWpYRdZswxfW+beXrHruenPhxKVP2Jas+jav5Tm2qm5Xt06DjUvsyBi2NXv+Elu3dEpp7zJQ4ahEHEDycE0Bycd1BSQX1xSQftfV5s2by37a5saNG+28886zcePGWcOGDaOud9ZZZwX+3LlzZ9tvv/2sffv2LhvtuOOOS+i9lR2n3mzBmWetWrWyXr16uaEDFVXGgsmW+fqjhSZjVsv907ouftTyTh9vvg6nmOX3Nt+jL5htXOUv0QzjOqHVbm6H/n0YpZlA2P/zoB/4448/3rKyssp6d4AKj2sKSD6uKyC5uKaA9L2ucnZWKSY1eKYAmDLBfv/995DlehypX5myyDQo4NRTTw0sy8/PD2SO/fTTTy5IFm733Xd37/Xrr7+64Jm2HT6QYMeOHW4CZ7Q+aeqhplu4DRuyrGrVLMvY2Qxs+3adVO2PXlOw3qZN/vu6dc2qVPH/ecsWBQTNdN7r1StY19u16tVVxur/s7apbWdmmlWrVrCugpo+n5nid95yVZdmZ/vX3Vmp6qxdq+PlX0/PqVRzx1ujbdtf9a1Shs+qZ20NrLslt5rl+yrZbpPvsBr7/s3tZG7Pe+zP/7vGrduw5rrAuus317Md+ZlW9YT7rfIO/07k5Zlt3WruuAQn5mmZntOy3Xbzjr2mn/rXbdQo+Nj6P7OOl3dtaP913KRmzYJ19Zm1HX02L5apdfWZRdv1zpG+y9oPbdM7FzqGXoBY+xZ+PnUu69QpWPePP/x/1vF1x9LMNKxV24h27oPPp7fd8HOv7Wr7WuZ9Zm1T24527gPnM+x7Enzu163zH3d9Bm/fdAx0LLRP2rfAud8S9j3ZeY50jLVucNz6zz/971mrVsE29P46d+Hn3tuu3l/HKPx7ou16x13fX72fzrF3nr3vSfi5975T0b4n2q533HW9abn2Vfsc/j2J9J2K9j2pX7/gc+gc6xb8PfGuZR2fLVsybfv2LPP5sirWb0TYuY/0PdF17J1n7YO+E+HfE503bSfauec3ovD55Dei6N+I/2/v3mOjqvIAjv+mpbQ82vIwPAryEhLAouBjEMWtAdKilbVCYCWoFVj8Q6oFE9RgKomoBYlKAIPWPzRrfGA3ASyBIIsIuoKAggGLVQIbawGJSp8UKO3Z/M7QmQ70Qgcmztz2+0mGO/fMncvp43d653fPo6amnZw6FSddusS5vo1w+p2ijaCN+CvbCP1az5yJlZoa398qt7cRrek6QtFGuK+N0O97dXU7//Wf29uI1nYdQRvh3jaivLy9VFTESe/ecVHbRrQ4sWdC5PV6TU5Ojn+/vr7e9OnTx+Tn519ybG1trTlw4EDQ44EHHjDjxo2zz8+ePdvs/1FaWmo8Ho9Zv3693S8uLtauU2bv3r3+YzZv3myPKSsra1G9Kyoq7DlEdGta/Fi1KnCO7GxfWY8ewef2eFp+vsbHggWB9y9c6Cvr1Cn4vPHxoZ93euoaY47ssO8vKPCVxcbUGbMoyf9ITgjte6CPceMC9dq6NVDeVJ8+odd3xIjA+3/9NVB+8mSgPDU19PP27Rt4/7lzgfKvvw6Up6WFft7k5OCvOSbGV/7++4GyqVNDP29cXPB5O3Twlb/4YqBs/vzQz3vxz6h7d1/ZnDmBsjfeuLrzNv0ZDRzoK7v//kDZunVXd96DBwPnGDXKV+b1BsqKi6/uvBs3Bs6Rnu4rGzw4+PtzNed1XRsxPfB+fxsRG3xe/T0P9by0Eb4HbcSlP6Nz586ZHj2qbRlthK+MNqL53z/aiLbZRiiuI3xoI3xoIwJoI3xoI9zZRqxeXWfLYmMborqNaMwV6fZyQh62qUMhs7Oz7eT9Xq9Xli9fLjU1Nf7VNx999FHp06ePnXMsISFBUlNTg96vE/+rxvLq6mo7N9mUKVNsLzLtrfbMM8/I4MGDJSMjwx4zbNgwOy+arvKpq3tq97+cnBw73JOVNpuhq2U25YkVyd4QWEVzeaJIoNMaAAAAAAAAHHh8GdDQrFq1SpYtW2Yn6x85cqSsWLFCRo8ebV+75557ZMCAAfLee+81+97HHntMysvLZd26dXa/trZWsrKyZN++fbZck2E6L9nixYuDFibQIZqaMCsqKrKrbGqyTf/fzo1991owjjU5OVkOH66Qnj2T3NlN8n//lfPv/0POnm/vMGzTI53ja6TjP/8tMvDuVtWVurUNt6ArdfR2pdbk/JdfbpaJEzNsF15XtRFteLgFbUT0thEaU4WFn0laWjrDNmkj/HWgjbjWYZt1snnzZhk3LoNhm7QRtBFhGbZZJ1988ZlkZqbb6z+3txGt6TpC0Ua4s404fVqvAf8j6ekTonrYpogvV1RRUXHZ+fGvKnnmRo3Jsyt9Q6JaQ73I8lSRyuOXLBjg41sEQOYdYBEA4CrpB/2NGzfKfffdF9UTWwJuQUwB4UdcAeFFTAFtN64qW5grupCXhCtoQmzi0gs7F1LVfhf2Jy4hcQYAAAAAABAmJM/cZvjfRab9SySpd3C59jjTcn0dAAAAAAAAYRHyggGIApogG5op54/skP1fbpaRd2dIu0F/o8cZAAAAAABAmNHzzK1iYsX0Hytl3cbYLYkzAAAAAACA8CN5BgAAAAAAADggeQYAAAAAAAA4IHkGAAAAAAAAOCB5BgAAAAAAADggeQYAAAAAAAA4IHkGAAAAAAAAOCB5BgAAAAAAADggeQYAAAAAAAA4IHkGAAAAAAAAOCB5BgAAAAAAADggeQYAAAAAAAA4IHkGAAAAAAAAOCB5BgAAAAAAADhoJ22EMcZuKysrpbWoq6uT06dP268pLi4u0tUBWgXiCggvYgoIP+IKCC9iCmi7cVV5IUfUmDOStp48q6qqstvrr78+0lUBAAAAAABAFOWMkpOTHV/3mCul11qJhoYGOXbsmCQmJorH45HWQDOkmgwsLS2VpKSkSFcHaBWIKyC8iCkg/IgrILyIKaDtxpUxxibOUlJSJCbGeWazNtPzTL8Jffv2ldZIfxGj+ZcRcCPiCggvYgoIP+IKCC9iCmibcZV8mR5njVgwAAAAAAAAAHBA8gwAAAAAAABwQPLMxeLj42XRokV2CyA8iCsgvIgpIPyIKyC8iCkg/OJbWVy1mQUDAAAAAAAAgFDR8wwAAAAAAABwQPIMAAAAAAAAcEDyDAAAAAAAAHBA8gwAAAAAAABwQPIMAAAAAAAAcEDyzMXefPNNGTBggCQkJMjo0aNl9+7dka4S4Ar5+fly++23S2JiovTo0UOysrKkpKQk6JgzZ87I3LlzpXv37tK5c2eZMmWK/PbbbxGrM+AmS5YsEY/HI/PmzfOXEVNA6MrKyuThhx+2cdOhQwcZMWKE7N271/+6MUZeeOEF6d27t319woQJ8vPPP0e0zkC0qq+vl7y8PBk4cKCNlxtuuEEWL15s46gRMQVc3o4dO2TSpEmSkpJir/XWrVsX9HpLYujPP/+UGTNmSFJSknTp0kVmz54t1dXVEu1InrnUmjVr5Omnn5ZFixbJd999JzfffLNkZGTIyZMnI101IOpt377dfojftWuXbNmyRerq6iQ9PV1qamr8x8yfP1+KioqksLDQHn/s2DGZPHlyROsNuMGePXvk7bfflptuuimonJgCQnPq1Cm56667JC4uTjZt2iTFxcXy2muvSdeuXf3HvPrqq7JixQp566235JtvvpFOnTrZ60FNVgMItnTpUlm9erWsWrVKDh06ZPc1hlauXOk/hpgCLq+mpsbmHrQjT3NaEkOaOPvhhx/s57ANGzbYhNzjjz8uUc/Albxer5k7d65/v76+3qSkpJj8/PyI1gtwo5MnT+otR7N9+3a7X15ebuLi4kxhYaH/mEOHDtljdu7cGcGaAtGtqqrKDBkyxGzZssWkpaWZ3NxcW05MAaF79tlnzdixYx1fb2hoML169TLLli3zl2msxcfHm48++ugvqiXgHpmZmWbWrFlBZZMnTzYzZsywz4kpIDQiYtauXevfb0kMFRcX2/ft2bPHf8ymTZuMx+MxZWVlJprR88yFzp07J99++63tAtkoJibG7u/cuTOidQPcqKKiwm67detmtxpf2hutaYwNHTpU+vXrR4wBl6E9OjMzM4NiRxFTQOg+/fRTue2222Tq1Kl2ioFRo0bJO++843/96NGjcuLEiaC4Sk5OtlN5EFfApe68807ZunWr/PTTT3b/+++/l6+++kruvfdeu09MAdfmaAtiSLc6VFP/vjXS4zWfoT3Volm7SFcAofv999/tmP2ePXsGlev+jz/+GLF6AW7U0NBg52XSoTGpqam2TBv99u3b24b94hjT1wBc6uOPP7bTCOiwzYsRU0Dojhw5YoeY6TQdCxcutLH11FNP2VjKzs72x05z14PEFXCp5557TiorK+3Nm9jYWPt56uWXX7ZDyBQxBVybEy2IId3qDaGm2rVrZzsxRHuckTwDIG29p8zBgwftnUcAV6e0tFRyc3Pt3BW6iA2A8Nzc0Tvzr7zyit3Xnmf690rnkdHkGYDQfPLJJ/LBBx/Ihx9+KDfeeKPs37/f3kDVic+JKQBXwrBNF7ruuuvs3ZKLVynT/V69ekWsXoDb5OTk2Ekqt23bJn379vWXaxzp8Ojy8vKg44kxoHk6LFMXrLnlllvs3UN96KIAOmGsPtc7jsQUEBpdqWz48OFBZcOGDZNffvnFPm+MHa4HgZZZsGCB7X320EMP2ZVrH3nkEbuYja7Crogp4Nr0akEM6fbiRQ7Pnz9vV+CM9jgjeeZC2l3/1ltvtWP2m96d1P0xY8ZEtG6AG+j8lpo4W7t2rXz++ed2yfKmNL50dbOmMVZSUmI/sBBjwKXGjx8vBw4csHfxGx/aY0aHwjQ+J6aA0Oh0AhonTelcTf3797fP9W+XftBoGlc6JE3njCGugEudPn3azqvUlHZI0M9RipgCrs3AFsSQbvVmqt54baSfxzQOdW60aMawTZfS+S+0e7F+IPF6vbJ8+XK7bOzMmTMjXTXAFUM1tcv++vXrJTEx0T++Xie07NChg93Onj3bxpmOv09KSpInn3zSNvZ33HFHpKsPRB2No8Y5Axvp0uTdu3f3lxNTQGi0R4xOcK7DNqdNmya7d++WgoIC+1Aej8cOOXvppZdkyJAh9kNLXl6eHYKWlZUV6eoDUWfSpEl2jjNdrEaHbe7bt09ef/11mTVrln2dmAKurLq6Wg4fPhy0SIDeKNXrO42tK8WQ9qCeOHGizJkzx05DoAtKaacG7RGqx0W1SC/3iau3cuVK069fP9O+fXvj9XrNrl27Il0lwBW06Wvu8e677/qPqa2tNU888YTp2rWr6dixo3nwwQfN8ePHI1pvwE3S0tJMbm6uf5+YAkJXVFRkUlNTTXx8vBk6dKgpKCgIer2hocHk5eWZnj172mPGjx9vSkpKIlZfIJpVVlbav0v6+SkhIcEMGjTIPP/88+bs2bP+Y4gp4PK2bdvW7Oeo7OzsFsfQH3/8YaZPn246d+5skpKSzMyZM01VVZWJdh79J9IJPAAAAAAAACAaMecZAAAAAAAA4IDkGQAAAAAAAOCA5BkAAAAAAADggOQZAAAAAAAA4IDkGQAAAAAAAOCA5BkAAAAAAADggOQZAAAAAAAA4IDkGQAAAAAAAOCA5BkAAAAAAADggOQZAAAAAAAA4IDkGQAAAAAAACDN+z+pqUwfP3AaewAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Graficamos \n",
    "# Buscamos los máximos y mínimos \n",
    "y_true_max = np.max(y_true)\n",
    "y_true_min = np.min(y_true)\n",
    "\n",
    "y_pred_max = np.max(y_pred)\n",
    "y_pred_min = np.min(y_pred)\n",
    "\n",
    "# Pos z\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(y_true, label='Posiciones Z reales', linestyle='None', marker='.')\n",
    "plt.plot(y_pred, label='Posiciones Z predichas', linestyle = 'None',marker='o')\n",
    "# Dibujamos los max y min\n",
    "plt.axhline(y = y_true_max, color = 'red', linestyle = '-.', label=f'Máx_true: {y_true_max:.3f}')\n",
    "plt.axhline(y = y_pred_max, color = 'red', linestyle = ':', label= f'Máx_pred: {y_pred_max:.3f}')\n",
    "plt.axhline(y = y_true_min, color = 'blue', linestyle ='-.', label=f'Mín_true: {y_true_min:.3f}')\n",
    "plt.axhline(y = y_pred_min, color = 'blue', linestyle = ':',label= f'Mín_pred:{y_pred_min: .3f}')\n",
    "\n",
    "# plt.ylim(-35,-50) ##(-60,-30)\n",
    "plt.title('Comparación de Posiciones Z')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Función de Pérdida durante el entrenamiento\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(history.history['loss'], label = 'Pérdida de Entrenamiento')\n",
    "#plt.plot(history.history['val_loss'], label = 'Pérdida de validación')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.ylim(-0.25,5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Guardado de Modelo.\n",
    "# autoencoder_z.save(\"../modelos_entrenamiento/mod_z_R0/modelo2/modelo2.keras\")\n",
    "\n",
    "# #Guardado de Scaler\n",
    "# import pickle\n",
    "# with open('../modelos_entrenamiento/mod_z_R0/modelo2/scaler_z2.pkl','wb') as f:\n",
    "#   pickle.dump(scaler_z,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
