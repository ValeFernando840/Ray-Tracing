{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Cargamos el Dataset\n",
    "file_path = \"dataset/dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listamos columnas para X y con drop separamos como un filter\n",
    "X_columns = [\n",
    "    'latitude_pos_tx', 'longitude_pos_tx', 'elevation_pos_tx', 'fc', 'elevation', \n",
    "    'azimuth', 'year', 'mmdd', 'UTI', 'hour', 'delay', 'terrestrial_range', \n",
    "    'slant_range', 'final_latitude', 'final_longitude', 'final_elevation'\n",
    "]\n",
    "X = df[X_columns]\n",
    "Y = df.drop(columns=X_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uso drop()\n",
    "***drop()*** es una función incorporada en Pandas que te permite eliminar una o más **filas o columnas** de un Marco de Datos. Devuelve un nuevo Marco de Datos con las filas o columnas especificadas eliminadas y no modifica el Marco de Datos original en su lugar, a menos que establezcas el parámetro inplace en True ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consideramos que las columnas \"final_latitude\", \"final_longitude\", \"final_elevation\"\n",
    "# No corresponden a parametros de entradas X por lo que lo quitamos.\n",
    "X = X.drop(columns=['final_latitude','final_longitude','final_elevation'])\n",
    "# print(X.head())\n",
    "# print(Y.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora vamos a escalar las columnas de elevaciones, que se encuentran en metros se los pasará a Km\n",
    "# y luego se les quitará decimas\n",
    "# print(Y.head())\n",
    "#Nota: En Y tenemos 3 tipos(latitudes, longitudes, elevations)\n",
    "#Generamos los nombres de las columnas. \n",
    "lat_columns = [f'lat_{i}' for i in range(1,101)]\n",
    "long_columns = [f'long_{i}' for i in range(1,101)]\n",
    "elev_columns = [f'elev_{i}' for i in range(1,101)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximo valor por columnas\n",
      " elev_1         967.773438\n",
      "elev_2       11580.748895\n",
      "elev_3       23228.155579\n",
      "elev_4       34941.924124\n",
      "elev_5       46721.758602\n",
      "                ...      \n",
      "elev_96     301178.222656\n",
      "elev_97     302036.621094\n",
      "elev_98     302895.019531\n",
      "elev_99     303753.417969\n",
      "elev_100    304611.816406\n",
      "Length: 100, dtype: float64\n",
      "Maximo valor del conjunto de elevaciones: 304611.8164061997\n"
     ]
    }
   ],
   "source": [
    "#Teniendo los nombres de las columnas las filtro\n",
    "latitudes = Y[lat_columns]\n",
    "longitudes = Y[long_columns]\n",
    "elevations = Y[elev_columns]\n",
    "max_value = Y[elev_columns].max()\n",
    "print(\"maximo valor por columnas\\n\",max_value)\n",
    "print(\"Maximo valor del conjunto de elevaciones:\",max_value.max())\n",
    "# k=1000 # valor a dividir para pasar a Km las elevaciones.\n",
    "# elevations = (elevations/k).round(5)\n",
    "# print(type(elevations))\n",
    "# print(elevations.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel(\"NuevoExcelCompleto_para_ver.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora quito las elevaciones en m y concateno con las elevaciones en km y redondeado\n",
    "Y = Y.drop(columns = elev_columns)\n",
    "Y = pd.concat([Y,elevations],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de filas con elev_1 != 0 es 280\n",
      "Cantidad de filas que no finalizan en cero:  1519\n",
      "[0. 0. 0. ... 1. 1. 1.] cantidad:  5130\n",
      "      elev_101\n",
      "0          0.0\n",
      "1          0.0\n",
      "2          0.0\n",
      "3          0.0\n",
      "4          0.0\n",
      "...        ...\n",
      "5125       1.0\n",
      "5126       1.0\n",
      "5127       1.0\n",
      "5128       1.0\n",
      "5129       1.0\n",
      "\n",
      "[5130 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#Contamos la cantidad de filas que tienen valores distintos de ceros en la columna elev_1\n",
    "count_non_zero =(Y[\"elev_1\"]!=0).sum()\n",
    "print(\"La cantidad de filas con elev_1 != 0 es\",count_non_zero)\n",
    "count_non_zero_elev_100 = (Y[\"elev_100\"]!=0).sum()\n",
    "print(\"Cantidad de filas que no finalizan en cero: \", count_non_zero_elev_100)\n",
    "elev_101 = np.array([])\n",
    "for i in Y[\"elev_100\"]:\n",
    "  if i != 0:\n",
    "    elev_101 = np.append(elev_101,1)\n",
    "  else:\n",
    "    elev_101 = np.append(elev_101,0)\n",
    "print(elev_101,\"cantidad: \", len(elev_101))\n",
    "# Creamos un DataFrame de 0 y 1 para agregar un elev_101 PERO NO ES NECESARIO.\n",
    "elev_101_df = pd.DataFrame()\n",
    "elev_101_df[\"elev_101\"] = elev_101\n",
    "print(elev_101_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### División de los datos en conjuntos de entrenamiento y prueba\n",
    "  `train_test_split` es una función que forma parte de la biblioteca de scikit-learn en el módulo `sklearn.model_selection`.\n",
    "  Se lo usa comunmente para dividir un conjunto de datos en dos subconjuntos (entrenamiento y prueba)\n",
    "#### Sus parámetros\n",
    "* **Datos**(obligatorio): Conjunto de datos que se desea dividir. \n",
    "  ```python\n",
    "    train_test_split(X,Y)\n",
    "* **test_size**(opcional): Define el porcentaje o la cantidad de datos que se reserva para prueba. Si es 0.2 indica un 20% reservado para prueba.\n",
    "  ```python\n",
    "    train_test_split(X,Y, test_size=0.2)\n",
    "* **train_size**(opcional): Especifica el tamaño del conjunto de Entrenamiento.\n",
    "* **random_state**(opcional): Controla la aleatoridad de la división. Si se usa un valor fijo (`random_state=42`), la división siempre es la misma cada vez que se ejecute el código.\n",
    "  ```python\n",
    "    train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "* **shuffle** (opcional): Especificsa si los datos deben ser barajados antes de ser divididos. Por defecto está en `True`. Es decir, los datos se mezclarán aleatoriamente antes de ser divididos.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "Y[\"elev_1\"] = Y[\"elev_1\"].apply(lambda x: 0.0 if x != 0 else x)\n",
    "print(Y[\"elev_1\"].max().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de dato: <class 'pandas.core.frame.DataFrame'> \n",
      "       latitude_pos_tx  longitude_pos_tx  elevation_pos_tx          fc  \\\n",
      "1235           -42.28             -63.4                 0  10000000.0   \n",
      "4047           -42.28             -63.4                 0  20000000.0   \n",
      "949            -42.28             -63.4                 0  10000000.0   \n",
      "4375           -42.28             -63.4                 0  23000000.0   \n",
      "19             -42.28             -63.4                 0  10000000.0   \n",
      "\n",
      "      elevation  azimuth    year  mmdd  UTI  hour     delay  \\\n",
      "1235          5       98  2010.0   725    0    20  0.009413   \n",
      "4047         28       89  2010.0  1215    0    12  0.002455   \n",
      "949           5       98  2010.0   608    0     4  0.009073   \n",
      "4375         34       87  2010.0  1215    0    12  0.001921   \n",
      "19            5       98  2010.0   104    0     4  0.009910   \n",
      "\n",
      "      terrestrial_range   slant_range  \n",
      "1235       2.719923e+06  2.822081e+06  \n",
      "4047       6.188348e+05  7.360000e+05  \n",
      "949        2.570941e+06  2.720000e+06  \n",
      "4375       4.548544e+05  5.760000e+05  \n",
      "19         2.859741e+06  2.970996e+06  \n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=42)\n",
    "\n",
    "print(\"Tipo de dato:\",type(x_train),\"\\n\", x_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de filas que no finalizan en cero de y_train:  1213\n"
     ]
    }
   ],
   "source": [
    "count_non_zero_elev_100 = (y_train[\"elev_100\"]!=0).sum()\n",
    "print(\"Cantidad de filas que no finalizan en cero de y_train: \", count_non_zero_elev_100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304611.8164061997\n",
      "elev_1      0.000000\n",
      "elev_2      0.038018\n",
      "elev_3      0.076255\n",
      "elev_4      0.114710\n",
      "elev_5      0.153381\n",
      "              ...   \n",
      "elev_96     0.988728\n",
      "elev_97     0.991546\n",
      "elev_98     0.994364\n",
      "elev_99     0.997182\n",
      "elev_100    1.000000\n",
      "Length: 100, dtype: float64\n",
      "máximos en el test: 0.9997916149046734\n"
     ]
    }
   ],
   "source": [
    "k = y_train[elev_columns].max().max()\n",
    "print(k)\n",
    "#normalizo al numero máximo de todas las columnas de elevaciones de y_train\n",
    "y_train[elev_columns] = y_train[elev_columns]/k\n",
    "print(y_train[elev_columns].max())\n",
    "\n",
    "# Normalizo al maximo del train en el test\n",
    "y_test[elev_columns] = y_test[elev_columns]/k\n",
    "print(\"máximos en el test:\",y_test[elev_columns].max().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
